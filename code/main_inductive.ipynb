{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f98128",
   "metadata": {},
   "source": [
    "### Train the inductive link prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7a7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'nell_v1'\n",
    "model_id = 'SiaLP_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54797cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#difine the names for saving\n",
    "model_name = 'Model_' + model_id + '_' + data_name\n",
    "one_hop_model_name = 'One_hop_model_' + model_id + '_' + data_name\n",
    "ids_name = 'IDs_' + model_id + '_' + data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba371e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import opensmile\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from sklearn.utils import shuffle\n",
    "from sys import getsizeof\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c098e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadKG:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.x = 'Hello'\n",
    "        \n",
    "    def load_train_data(self, data_path, one_hop, data, s_t_r, entity2id, id2entity,\n",
    "                     relation2id, id2relation):\n",
    "        \n",
    "        data_ = set()\n",
    "    \n",
    "        ####load the train, valid and test set##########\n",
    "        with open (data_path, 'r') as f:\n",
    "            \n",
    "            data_ini = f.readlines()\n",
    "                        \n",
    "            for i in range(len(data_ini)):\n",
    "            \n",
    "                x = data_ini[i].split()\n",
    "                \n",
    "                x_ = tuple(x)\n",
    "                \n",
    "                data_.add(x_)\n",
    "        \n",
    "        ####relation dict#################\n",
    "        index = len(relation2id)\n",
    "     \n",
    "        for key in data_:\n",
    "            \n",
    "            if key[1] not in relation2id:\n",
    "                \n",
    "                relation = key[1]\n",
    "                \n",
    "                relation2id[relation] = index\n",
    "                \n",
    "                id2relation[index] = relation\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "                #the inverse relation\n",
    "                iv_r = '_inverse_' + relation\n",
    "                \n",
    "                relation2id[iv_r] = index\n",
    "                \n",
    "                id2relation[index] = iv_r\n",
    "                \n",
    "                index += 1\n",
    "        \n",
    "        #get the id of the inverse relation, by above definition, initial relation has \n",
    "        #always even id, while inverse relation has always odd id.\n",
    "        def inverse_r(r):\n",
    "            \n",
    "            if r % 2 == 0: #initial relation\n",
    "                \n",
    "                iv_r = r + 1\n",
    "            \n",
    "            else: #inverse relation\n",
    "                \n",
    "                iv_r = r - 1\n",
    "            \n",
    "            return(iv_r)\n",
    "        \n",
    "        ####entity dict###################\n",
    "        index = len(entity2id)\n",
    "        \n",
    "        for key in data_:\n",
    "            \n",
    "            source, target = key[0], key[2]\n",
    "            \n",
    "            if source not in entity2id:\n",
    "                                \n",
    "                entity2id[source] = index\n",
    "                \n",
    "                id2entity[index] = source\n",
    "                \n",
    "                index += 1\n",
    "            \n",
    "            if target not in entity2id:\n",
    "                \n",
    "                entity2id[target] = index\n",
    "                \n",
    "                id2entity[index] = target\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "        #create the set of triples using id instead of string        \n",
    "        for ele in data_:\n",
    "            \n",
    "            s = entity2id[ele[0]]\n",
    "            \n",
    "            r = relation2id[ele[1]]\n",
    "            \n",
    "            t = entity2id[ele[2]]\n",
    "            \n",
    "            if (s,r,t) not in data:\n",
    "                \n",
    "                data.add((s,r,t))\n",
    "            \n",
    "            s_t_r[(s,t)].add(r)\n",
    "            \n",
    "            if s not in one_hop:\n",
    "                \n",
    "                one_hop[s] = set()\n",
    "            \n",
    "            one_hop[s].add((r,t))\n",
    "            \n",
    "            if t not in one_hop:\n",
    "                \n",
    "                one_hop[t] = set()\n",
    "            \n",
    "            r_inv = inverse_r(r)\n",
    "            \n",
    "            s_t_r[(t,s)].add(r_inv)\n",
    "            \n",
    "            one_hop[t].add((r_inv,s))\n",
    "            \n",
    "        #change each set in one_hop to list\n",
    "        for e in one_hop:\n",
    "            \n",
    "            one_hop[e] = list(one_hop[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6cd0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObtainPathsByDynamicProgramming:\n",
    "\n",
    "    def __init__(self, amount_bd=50, size_bd=50, threshold=20000):\n",
    "        \n",
    "        self.amount_bd = amount_bd #how many Tuples we choose in one_hop[node] for next recursion\n",
    "                        \n",
    "        self.size_bd = size_bd #size bound limit the number of paths to a target entity t\n",
    "        \n",
    "        #number of times paths with specific length been performed for recursion\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    '''\n",
    "    Given an entity s, the function will find the paths from s to other entities, using recursion.\n",
    "    \n",
    "    One may refer to LeetCode Problem 797 for details:\n",
    "        https://leetcode.com/problems/all-paths-from-source-to-target/\n",
    "    '''\n",
    "    def obtain_paths(self, mode, s, t_input, lower_bd, upper_bd, one_hop):\n",
    "\n",
    "        if type(lower_bd) != type(1) or lower_bd < 1:\n",
    "            \n",
    "            raise TypeError(\"!!! invalid lower bound setting, must >= 1 !!!\")\n",
    "            \n",
    "        if type(upper_bd) != type(1) or upper_bd < 1:\n",
    "            \n",
    "            raise TypeError(\"!!! invalid upper bound setting, must >= 1 !!!\")\n",
    "            \n",
    "        if lower_bd > upper_bd:\n",
    "            \n",
    "            raise TypeError(\"!!! lower bound must not exced upper bound !!!\")\n",
    "            \n",
    "        if s not in one_hop:\n",
    "            \n",
    "            raise ValueError('!!! entity not in one_hop. Please work on existing entities')\n",
    "\n",
    "        #here is the result dict. Its key is each entity t sharing paths from s\n",
    "        #The value of each t is a set containing the paths from s to t\n",
    "        #These paths can be either the direct connection r, or a multi-hop path\n",
    "        res = defaultdict(set)\n",
    "        \n",
    "        #qualified_t contains the types of t we want to consider,\n",
    "        #that is, what t will be added to the result set.\n",
    "        qualified_t = set()\n",
    "\n",
    "        #under this mode, we will only consider the direct neighbour of s\n",
    "        if mode == 'direct_neighbour':\n",
    "        \n",
    "            for Tuple in one_hop[s]:\n",
    "            \n",
    "                t = Tuple[1]\n",
    "                \n",
    "                qualified_t.add(t)\n",
    "        \n",
    "        #under this mode, we will only consider one specified entity t\n",
    "        elif mode == 'target_specified':\n",
    "            \n",
    "            qualified_t.add(t_input)\n",
    "        \n",
    "        #under this mode, we will consider any entity\n",
    "        elif mode == 'any_target':\n",
    "            \n",
    "            for s_any in one_hop:\n",
    "                \n",
    "                qualified_t.add(s_any)\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            raise ValueError('not a valid mode')\n",
    "        \n",
    "        '''\n",
    "        We use recursion to find the paths\n",
    "        On current node with the path [r1, ..., rk] and on-path entities {s, e1, ..., ek-1, node}\n",
    "        from s to this node, we will further find the direct neighbor t' of this node. \n",
    "        If t' is not an on-path entity (not among s, e1,...ek-1, node), we recursively proceed to t' \n",
    "        '''\n",
    "        def helper(node, path, on_path_en, res, qualified_t, lower_bd, upper_bd, one_hop, count_dict):\n",
    "\n",
    "            #when the current path is within lower_bd and upper_bd, \n",
    "            #and the node is among the qualified t, and it has not been fill of paths w.r.t size_limit,\n",
    "            #we will add this path to the node\n",
    "            if (len(path) >= lower_bd) and (len(path) <= upper_bd) and (\n",
    "                node in qualified_t) and (len(res[node]) < self.size_bd):\n",
    "                \n",
    "                res[node].add(tuple(path))\n",
    "                    \n",
    "            #won't start new recursions if the current path length already reaches upper limit\n",
    "            #or the number of recursions performed on this length has reached the limit\n",
    "            if (len(path) < upper_bd) and (count_dict[len(path)] <= self.threshold):\n",
    "                                \n",
    "                #temp list is the id list for us to go-over one_hop[node]\n",
    "                temp_list = [i for i in range(len(one_hop[node]))]\n",
    "                random.shuffle(temp_list) #so we random-shuffle the list\n",
    "                \n",
    "                #only take 20 recursions if there are too many (r,t)\n",
    "                for i in temp_list[:self.amount_bd]:\n",
    "                    \n",
    "                    #obtain tuple of (r,t)\n",
    "                    Tuple = one_hop[node][i]\n",
    "                    r, t = Tuple[0], Tuple[1]\n",
    "                    \n",
    "                    #add to count_dict even if eventually this step not proceed\n",
    "                    count_dict[len(path)] += 1\n",
    "                    \n",
    "                    #if t not on the path and we not exceed the computation threshold, \n",
    "                    #then finally proceed to next recursion\n",
    "                    if (t not in on_path_en) and (count_dict[len(path)] <= self.threshold):\n",
    "\n",
    "                        helper(t, path + [r], on_path_en.union({t}), res, qualified_t, \n",
    "                               lower_bd, upper_bd, one_hop, count_dict)\n",
    "\n",
    "        length_dict = defaultdict(int)\n",
    "        count_dict = defaultdict(int)\n",
    "        \n",
    "        helper(s, [], {s}, res, qualified_t, lower_bd, upper_bd, one_hop, count_dict)\n",
    "        \n",
    "        return(res, count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecaf24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/' + data_name + '/train.txt'\n",
    "valid_path = '../data/' + data_name + '/valid.txt'\n",
    "test_path = '../data/' + data_name + '/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5718867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the classes\n",
    "Class_1 = LoadKG()\n",
    "Class_2 = ObtainPathsByDynamicProgramming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c472f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the dictionaries and sets for load KG\n",
    "one_hop = dict() \n",
    "data = set()\n",
    "s_t_r = defaultdict(set)\n",
    "\n",
    "#define the dictionaries, which is shared by initail and inductive train/valid/test\n",
    "entity2id = dict()\n",
    "id2entity = dict()\n",
    "relation2id = dict()\n",
    "id2relation = dict()\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(train_path, one_hop, data, s_t_r,\n",
    "                        entity2id, id2entity, relation2id, id2relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c4c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the dictionaries and sets for load KG\n",
    "one_hop_valid = dict() \n",
    "data_valid = set()\n",
    "s_t_r_valid = defaultdict(set)\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(valid_path, one_hop_valid, data_valid, s_t_r_valid,\n",
    "                        entity2id, id2entity, relation2id, id2relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "178bd0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the dictionaries and sets for load KG\n",
    "one_hop_test = dict() \n",
    "data_test = set()\n",
    "s_t_r_test = defaultdict(set)\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(test_path, one_hop_test, data_test, s_t_r_test,\n",
    "                        entity2id, id2entity, relation2id, id2relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8babf",
   "metadata": {},
   "source": [
    "#### Build the path-based siamese neural network structure\n",
    "\n",
    "We use biLSTM to train on the input path embedding sequence to predict the output embedding or the relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68239c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 10:51:08.357900: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Input layer, using integer to represent each relation type\n",
    "#note that inputs_path is the path inputs, while inputs_out_re is the output relation inputs\n",
    "fst_path = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "scd_path = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "thd_path = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "#the relation input layer (for output embedding)\n",
    "id_rela = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Embed each integer in a 300-dimensional vector as input,\n",
    "# note that we add another \"space holder\" embedding, \n",
    "# which hold the spaces if the initial length of paths are not the same\n",
    "in_embd_var = layers.Embedding(len(relation2id)+1, 300)\n",
    "\n",
    "# Obtain the embedding\n",
    "fst_p_embd = in_embd_var(fst_path)\n",
    "scd_p_embd = in_embd_var(scd_path)\n",
    "thd_p_embd = in_embd_var(thd_path)\n",
    "\n",
    "# Embed each integer in a 300-dimensional vector as output\n",
    "rela_embd = layers.Embedding(len(relation2id)+1, 300)(id_rela)\n",
    "\n",
    "#add 2 layer bi-directional LSTM\n",
    "lstm_layer_1 = layers.Bidirectional(layers.LSTM(150, return_sequences=True))\n",
    "lstm_layer_2 = layers.Bidirectional(layers.LSTM(150, return_sequences=True))\n",
    "\n",
    "#first LSTM layer\n",
    "fst_lstm_mid = lstm_layer_1(fst_p_embd)\n",
    "scd_lstm_mid = lstm_layer_1(scd_p_embd)\n",
    "thd_lstm_mid = lstm_layer_1(thd_p_embd)\n",
    "\n",
    "#second LSTM layer\n",
    "fst_lstm_out = lstm_layer_2(fst_lstm_mid)\n",
    "scd_lstm_out = lstm_layer_2(scd_lstm_mid)\n",
    "thd_lstm_out = lstm_layer_2(thd_lstm_mid)\n",
    "\n",
    "#reduce max\n",
    "fst_reduce_max = tf.reduce_max(fst_lstm_out, axis=1)\n",
    "scd_reduce_max = tf.reduce_max(scd_lstm_out, axis=1)\n",
    "thd_reduce_max = tf.reduce_max(thd_lstm_out, axis=1)\n",
    "\n",
    "#concatenate the output vector from both siamese tunnel: (Batch, 900)\n",
    "path_concat = layers.concatenate([fst_reduce_max, scd_reduce_max, thd_reduce_max], axis=-1)\n",
    "\n",
    "#add dropout on top of the concatenation from all channels\n",
    "dropout = layers.Dropout(0.25)(path_concat)\n",
    "\n",
    "#multiply into output embd size by dense layer: (Batch, 300)\n",
    "path_out_vect = layers.Dense(300, activation='tanh')(dropout)\n",
    "\n",
    "#remove the time dimension from the output embd since there is only one step\n",
    "rela_out_embd = tf.reduce_sum(rela_embd, axis=1)\n",
    "\n",
    "# Normalize the vectors to have unit length\n",
    "path_out_vect_norm = tf.math.l2_normalize(path_out_vect, axis=-1)\n",
    "rela_out_embd_norm = tf.math.l2_normalize(rela_out_embd, axis=-1)\n",
    "\n",
    "# Calculate the dot product\n",
    "dot_product = layers.Dot(axes=-1)([path_out_vect_norm, rela_out_embd_norm])\n",
    "\n",
    "#put together the model\n",
    "model = keras.Model([fst_path, scd_path, thd_path, id_rela], dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5cd4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config the Adam optimizer \n",
    "opt = keras.optimizers.Adam(learning_rate=0.0005, decay=1e-6)\n",
    "\n",
    "#compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40033a4",
   "metadata": {},
   "source": [
    "#### Build the subgraph-based siamese neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c407303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each input is an vector with number of relations to be dim:\n",
    "#each dim represent the existence (1) or not (0) of an out-going relation from the entity\n",
    "source_path_1 = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "source_path_2 = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "source_path_3 = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "target_path_1 = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "target_path_2 = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "target_path_3 = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "#the relation input layer (for output embedding)\n",
    "id_rela_ = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Embed each integer in a 300-dimensional vector as input,\n",
    "# note that we add another \"space holder\" embedding, \n",
    "# which hold the spaces if the initial length of paths are not the same\n",
    "in_embd_var_ = layers.Embedding(len(relation2id)+1, 300)\n",
    "\n",
    "# Obtain the source embeddings\n",
    "source_embd_1 = in_embd_var_(source_path_1)\n",
    "source_embd_2 = in_embd_var_(source_path_2)\n",
    "source_embd_3 = in_embd_var_(source_path_3)\n",
    "\n",
    "#Obtain the target embeddings\n",
    "target_embd_1 = in_embd_var_(target_path_1)\n",
    "target_embd_2 = in_embd_var_(target_path_2)\n",
    "target_embd_3 = in_embd_var_(target_path_3)\n",
    "\n",
    "# Embed each integer in a 300-dimensional vector as output\n",
    "rela_embd_ = layers.Embedding(len(relation2id)+1, 300)(id_rela_)\n",
    "\n",
    "#add 2 layer bi-directional LSTM network\n",
    "lstm_1 = layers.Bidirectional(layers.LSTM(150, return_sequences=True))\n",
    "lstm_2 = layers.Bidirectional(layers.LSTM(150, return_sequences=True))\n",
    "\n",
    "###source lstm implimentation########\n",
    "#first LSTM layer\n",
    "source_mid_1 = lstm_1(source_embd_1)\n",
    "source_mid_2 = lstm_1(source_embd_2)\n",
    "source_mid_3 = lstm_1(source_embd_3)\n",
    "\n",
    "#second LSTM layer\n",
    "source_out_1 = lstm_2(source_mid_1)\n",
    "source_out_2 = lstm_2(source_mid_2)\n",
    "source_out_3 = lstm_2(source_mid_3)\n",
    "\n",
    "#reduce max\n",
    "source_max_1 = tf.reduce_max(source_out_1, axis=1)\n",
    "source_max_2 = tf.reduce_max(source_out_2, axis=1)\n",
    "source_max_3 = tf.reduce_max(source_out_3, axis=1)\n",
    "\n",
    "#concatenate the output vector from both siamese tunnel: (Batch, 900)\n",
    "source_concat = layers.concatenate([source_max_1, source_max_2, source_max_3], axis=-1)\n",
    "\n",
    "#add dropout on top of the concatenation from all channels\n",
    "source_dropout = layers.Dropout(0.25)(source_concat)\n",
    "\n",
    "###target lstm implimentation########\n",
    "#first LSTM layer\n",
    "target_mid_1 = lstm_1(target_embd_1)\n",
    "target_mid_2 = lstm_1(target_embd_2)\n",
    "target_mid_3 = lstm_1(target_embd_3)\n",
    "\n",
    "#second LSTM layer\n",
    "target_out_1 = lstm_2(target_mid_1)\n",
    "target_out_2 = lstm_2(target_mid_2)\n",
    "target_out_3 = lstm_2(target_mid_3)\n",
    "\n",
    "#reduce max\n",
    "target_max_1 = tf.reduce_max(target_out_1, axis=1)\n",
    "target_max_2 = tf.reduce_max(target_out_2, axis=1)\n",
    "target_max_3 = tf.reduce_max(target_out_3, axis=1)\n",
    "\n",
    "#concatenate the output vector from both siamese tunnel: (Batch, 900)\n",
    "target_concat = layers.concatenate([target_max_1, target_max_2, target_max_3], axis=-1)\n",
    "\n",
    "#add dropout on top of the concatenation from all channels\n",
    "target_dropout = layers.Dropout(0.25)(target_concat)\n",
    "\n",
    "#further concatenate source and target output embeddings: (Batch, 1800)\n",
    "final_concat = layers.concatenate([source_dropout, target_dropout], axis=-1)\n",
    "\n",
    "#multiply into output embd size by dense layer: (Batch, 300)\n",
    "out_vect = layers.Dense(300, activation='tanh')(final_concat)\n",
    "\n",
    "#remove the time dimension from the output embd since there is only one step\n",
    "rela_out_embd_ = tf.reduce_sum(rela_embd_, axis=1)\n",
    "\n",
    "# Normalize the vectors to have unit length\n",
    "out_vect_norm = tf.math.l2_normalize(out_vect, axis=-1)\n",
    "rela_out_embd_norm_ = tf.math.l2_normalize(rela_out_embd_, axis=-1)\n",
    "\n",
    "# Calculate the dot product\n",
    "dot_product_ = layers.Dot(axes=-1)([out_vect_norm, rela_out_embd_norm_])\n",
    "\n",
    "#put together the model\n",
    "model_2 = keras.Model([source_path_1, source_path_2, source_path_3,\n",
    "                       target_path_1, target_path_2, target_path_3, id_rela_], dot_product_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a1f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config the Adam optimizer \n",
    "opt_ = keras.optimizers.Adam(learning_rate=0.0005, decay=1e-6)\n",
    "\n",
    "#compile the model\n",
    "model_2.compile(loss='binary_crossentropy', optimizer=opt_, metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fd204f",
   "metadata": {},
   "source": [
    "### Build the big-batch for path-based model\n",
    "We will build the big-batch for the path-based model training. That is, we will build three list to store three paths, respectively.\n",
    "\n",
    "In order to reduce computational complexity, we will run the path-finding algorithm for each entity e in the dataset before the training. That is, for each entity e, we will have two dictionaries. Dict 1 stores the paths between e and any other entities in the dataset. Will Dict 2 stores the paths between e and its direct neighbors. The two dicts will be used and invariant throughout the training.\n",
    "\n",
    "* At each step, three different paths between two entities s and t are selected. Each path is append to one of the list. \n",
    "* If this step is for positive samples, the existing relation r will be selected between s and t. If there are more than one relation from s to t, we randomly choose one. Also, the label list will be appended 1.\n",
    "* If this step is for negative samples, one relation that does not exist between s and t will be selected randomly and append to the relation list. Also, the label list will be appended 0.\n",
    "* In practice, the positive step is always fallowed by a negative step. The same paths in the positive step will be used in the next negative step, while the relation is a negative one chosen in the above way.\n",
    "* We do this until the length limit is reached.\n",
    "\n",
    "**For relation prediciton, we will only need to train using (s,r,t) triple. (t,r-1,s) is not necessary and hence not included in training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb3ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build the big batche for path-based training\n",
    "def build_big_batches_path(lower_bd, upper_bd, data, one_hop, s_t_r,\n",
    "                      x_p_list, x_r_list, y_list,\n",
    "                      relation2id, entity2id, id2relation, id2entity):\n",
    "    \n",
    "    #the set of all relation IDs\n",
    "    relation_id_set = set()\n",
    "    \n",
    "    #the set of all initial relations\n",
    "    ini_r_id_set = set()\n",
    "    \n",
    "    for i in range(len(id2relation)):\n",
    "        \n",
    "        if i not in id2relation:\n",
    "            raise ValueError('error when generaing id2relation')\n",
    "        \n",
    "        relation_id_set.add(i)\n",
    "        \n",
    "        if i % 2 == 0: #initial relation id is always an even number\n",
    "            ini_r_id_set.add(i)\n",
    "    \n",
    "    num_r = len(id2relation)\n",
    "    num_ini_r = len(ini_r_id_set)\n",
    "    \n",
    "    if num_ini_r != int(num_r/2):\n",
    "        raise ValueError('error when generating id2relation')\n",
    "    \n",
    "    #in case not all entities in entity2id are in one_hop, \n",
    "    #so we need to find out who are indeed in\n",
    "    existing_ids = set()\n",
    "    \n",
    "    for s_1 in one_hop:\n",
    "        existing_ids.add(s_1)\n",
    "        \n",
    "    existing_ids = list(existing_ids)\n",
    "    random.shuffle(existing_ids)\n",
    "    \n",
    "    count = 0\n",
    "    for s in existing_ids:\n",
    "        \n",
    "        #impliment the path finding algorithm to find paths between s and t\n",
    "        result, length_dict = Class_2.obtain_paths('direct_neighbour', s, 'nb', lower_bd, upper_bd, one_hop)\n",
    "        \n",
    "        for iteration in range(10):\n",
    "\n",
    "            #proceed only if at least three paths are between s and t\n",
    "            for t in result:\n",
    "\n",
    "                if len(s_t_r[(s,t)]) == 0:\n",
    "\n",
    "                    raise ValueError(s,t,id2entity[s], id2entity[t])\n",
    "\n",
    "                #we are only interested in forward link in relation prediciton\n",
    "                ini_r_list = list()\n",
    "\n",
    "                #obtain initial relations between s and t\n",
    "                for r in s_t_r[(s,t)]:\n",
    "                    if r % 2 == 0:#initial relation id is always an even number\n",
    "                        ini_r_list.append(r)\n",
    "\n",
    "                #if there exist more than three paths between s and t, \n",
    "                #and inital connection between s and t exists,\n",
    "                #and not every r in the relation dictionary exists between s and t (although this is rare)\n",
    "                #we then proceed\n",
    "                if len(result[t]) >= 3 and len(ini_r_list) > 0 and len(ini_r_list) < int(num_ini_r):\n",
    "\n",
    "                    #obtain the list form of all the paths from s to t\n",
    "                    temp_path_list = list(result[t])\n",
    "\n",
    "                    temp_pair = random.sample(temp_path_list, 3)\n",
    "\n",
    "                    path_1, path_2, path_3 = temp_pair[0], temp_pair[1], temp_pair[2]\n",
    "\n",
    "                    #####positive#####################\n",
    "                    #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                    x_p_list['1'].append(list(path_1) + [num_r]*abs(len(path_1)-upper_bd))\n",
    "                    x_p_list['2'].append(list(path_2) + [num_r]*abs(len(path_2)-upper_bd))\n",
    "                    x_p_list['3'].append(list(path_3) + [num_r]*abs(len(path_3)-upper_bd))\n",
    "\n",
    "                    #append relation\n",
    "                    r = random.choice(ini_r_list)\n",
    "                    x_r_list.append([r])\n",
    "                    y_list.append(1.)\n",
    "\n",
    "                    #####negative#####################\n",
    "                    #append the paths: note that we add the space holder id at the end\n",
    "                    #of the shorter path\n",
    "                    x_p_list['1'].append(list(path_1) + [num_r]*abs(len(path_1)-upper_bd))\n",
    "                    x_p_list['2'].append(list(path_2) + [num_r]*abs(len(path_2)-upper_bd))\n",
    "                    x_p_list['3'].append(list(path_3) + [num_r]*abs(len(path_3)-upper_bd))\n",
    "\n",
    "                    #append relation\n",
    "                    neg_r_list = list(ini_r_id_set.difference(set(ini_r_list)))\n",
    "                    r_ran = random.choice(neg_r_list)\n",
    "                    x_r_list.append([r_ran])\n",
    "                    y_list.append(0.)\n",
    "        \n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('generating big-batches for path-based model', count, len(existing_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215dcc4",
   "metadata": {},
   "source": [
    "### Build the big-batch for the subgraph-based network training\n",
    "\n",
    "Again, to reduce computational complexity, we store the subgraph of each entity e at the biginning.\n",
    "\n",
    "* At each step, we will select one triple (s,r,t) from the dataset. Then, reaching out paths of s and t is generated respectively according to their out-going relations.\n",
    "* We will select three paths for each of source and target entity. Add them to the corresponding list.\n",
    "* If this is a positive sample step, the id of relation r is appended to the relation list.\n",
    "* If this is a negative sample step, the id of a random relation is appended to the relation lsit.\n",
    "* Similarly, one negative sample step always follows one positive step. The one-hop vectors from the previous positve step is used again for the negative step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c3264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, it is too slow to run the path-finding algorithm again and again on the complete FB15K-237\n",
    "#Instead, we will find the subgraph for each entity once.\n",
    "#then in the subgraph based training, the subgraphs are stored and used for multiple times\n",
    "def store_subgraph_dicts(lower_bd, upper_bd, data, one_hop, s_t_r,\n",
    "                         relation2id, entity2id, id2relation, id2entity):\n",
    "    \n",
    "    #the set of all relation IDs\n",
    "    relation_id_set = set()\n",
    "    \n",
    "    for i in range(len(id2relation)):\n",
    "        \n",
    "        if i not in id2relation:\n",
    "            raise ValueError('error when generaing id2relation')\n",
    "        \n",
    "        relation_id_set.add(i)\n",
    "    \n",
    "    num_r = len(id2relation)\n",
    "    \n",
    "    #in case not all entities in entity2id are in one_hop, \n",
    "    #so we need to find out who are indeed in\n",
    "    existing_ids = set()\n",
    "    \n",
    "    for s_1 in one_hop:\n",
    "        existing_ids.add(s_1)\n",
    "    \n",
    "    #the ids to start path finding\n",
    "    existing_ids = list(existing_ids)\n",
    "    random.shuffle(existing_ids)\n",
    "    \n",
    "    #Dict stores the subgraph for each entity\n",
    "    Dict_1 = dict()\n",
    "    \n",
    "    count = 0\n",
    "    for s in existing_ids:\n",
    "        \n",
    "        path_set = set()\n",
    "            \n",
    "        result, length_dict = Class_2.obtain_paths('any_target', s, 'any', lower_bd, upper_bd, one_hop)\n",
    "\n",
    "        for t_ in result:\n",
    "            for path in result[t_]:\n",
    "                path_set.add(path)\n",
    "\n",
    "        del(result, length_dict)\n",
    "        \n",
    "        path_list = list(path_set)\n",
    "        \n",
    "        path_select = random.sample(path_list, min(len(path_list), 100))\n",
    "            \n",
    "        Dict_1[s] = deepcopy(path_select)\n",
    "        \n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('generating and storing paths for the path-based model', count, len(existing_ids))\n",
    "        \n",
    "    return(Dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1551116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build the big-batch for one-hope neighbor training\n",
    "def build_big_batches_subgraph(lower_bd, upper_bd, data, one_hop, s_t_r,\n",
    "                      x_s_list, x_t_list, x_r_list, y_list, Dict,\n",
    "                      relation2id, entity2id, id2relation, id2entity):\n",
    "    \n",
    "    #the set of all relation IDs\n",
    "    relation_id_set = set()\n",
    "    \n",
    "    #the set of all initial relations\n",
    "    ini_r_id_set = set()\n",
    "    \n",
    "    for i in range(len(id2relation)):\n",
    "        \n",
    "        if i not in id2relation:\n",
    "            raise ValueError('error when generaing id2relation')\n",
    "        \n",
    "        relation_id_set.add(i)\n",
    "        \n",
    "        if i % 2 == 0: #initial relation id is always an even number\n",
    "            ini_r_id_set.add(i)\n",
    "    \n",
    "    num_r = len(id2relation)\n",
    "    num_ini_r = len(ini_r_id_set)\n",
    "    \n",
    "    if num_ini_r != int(num_r/2):\n",
    "        raise ValueError('error when generating id2relation')\n",
    "        \n",
    "    #if an entity has at least three out-stretching paths, it is a qualified one\n",
    "    qualified = set()\n",
    "    for e in Dict:\n",
    "        if len(Dict[e]) >= 3:\n",
    "            qualified.add(e)\n",
    "    qualified = list(qualified)\n",
    "    \n",
    "    data = list(data)\n",
    "    \n",
    "    for iteration in range(10):\n",
    "\n",
    "        data = shuffle(data)\n",
    "\n",
    "        for i_0 in range(len(data)):\n",
    "\n",
    "            triple = data[i_0]\n",
    "\n",
    "            s, r, t = triple[0], triple[1], triple[2] #obtain entities and relation IDs\n",
    "\n",
    "            if s in qualified and t in qualified:\n",
    "\n",
    "                #obtain the path list for true entities\n",
    "                path_s, path_t = list(Dict[s]), list(Dict[t])\n",
    "\n",
    "                #####positive step###########\n",
    "                #randomly obtain three paths for true entities\n",
    "                temp_s = random.sample(path_s, 3)\n",
    "                temp_t = random.sample(path_t, 3)\n",
    "                s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "                t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(1.)\n",
    "\n",
    "                #####negative step for relation###########\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                neg_r_list = list(ini_r_id_set.difference({r}))\n",
    "                r_ran = random.choice(neg_r_list)\n",
    "                x_r_list.append([r_ran])\n",
    "                y_list.append(0.)\n",
    "                \n",
    "                ##############################################\n",
    "                ##############################################\n",
    "                #randomly choose two negative sampled entities\n",
    "                s_ran = random.choice(qualified)\n",
    "                t_ran = random.choice(qualified)\n",
    "\n",
    "                #obtain the path list for random entities\n",
    "                path_s_ran, path_t_ran = list(Dict[s_ran]), list(Dict[t_ran])\n",
    "                \n",
    "                #####positive step#################\n",
    "                #Again: randomly obtain three paths\n",
    "                temp_s = random.sample(path_s, 3)\n",
    "                temp_t = random.sample(path_t, 3)\n",
    "                s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "                t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(1.)\n",
    "\n",
    "                #####negative for source entity###########\n",
    "                #randomly obtain three paths\n",
    "                temp_s = random.sample(path_s_ran, 3)\n",
    "                s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(0.)\n",
    "\n",
    "                #####positive step###########\n",
    "                #Again: randomly obtain three paths\n",
    "                temp_s = random.sample(path_s, 3)\n",
    "                temp_t = random.sample(path_t, 3)\n",
    "                s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "                t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(1.)\n",
    "\n",
    "                #####negative for target entity###########\n",
    "                #randomly obtain three paths\n",
    "                temp_t = random.sample(path_t_ran, 3)\n",
    "                t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(0.)\n",
    "\n",
    "            if i_0 % 200 == 0:\n",
    "                print('generating big-batches for subgraph-based model', i_0, len(data), iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e0ac2",
   "metadata": {},
   "source": [
    "### Start Training: load the KG and call classes\n",
    "\n",
    "Here, we use the validation set to see the training efficiency. That is, we use the validation to check whether the true relation between entities can be predicted by paths.\n",
    "\n",
    "The trick is: in validation, we have to use the same relation ID and entity ID as in the training. But we don't want to use the links in training anymore. That is, in validation, we want to use (and update if necessary) entity2id, id2entity, relation2id and id2relation. But we want to use new one_hop, data, data_ and s_t_r for validation set. Then, path-finding will also be based on new one_hop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28be7a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model_SiaLP_6_nell_v1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8103ea50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One_hop_model_SiaLP_6_nell_v1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hop_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c02a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IDs_SiaLP_6_nell_v1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7f57c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, we save the relation and ids\n",
    "Dict = dict()\n",
    "\n",
    "#save training data\n",
    "Dict['one_hop'] = one_hop\n",
    "Dict['data'] = data\n",
    "Dict['s_t_r'] = s_t_r\n",
    "\n",
    "#save valid data\n",
    "Dict['one_hop_valid'] = one_hop_valid\n",
    "Dict['data_valid'] = data_valid\n",
    "Dict['s_t_r_valid'] = s_t_r_valid\n",
    "\n",
    "#save test data\n",
    "Dict['one_hop_test'] = one_hop_test\n",
    "Dict['data_test'] = data_test\n",
    "Dict['s_t_r_test'] = s_t_r_test\n",
    "\n",
    "#save shared dictionaries\n",
    "Dict['entity2id'] = entity2id\n",
    "Dict['id2entity'] = id2entity\n",
    "Dict['relation2id'] = relation2id\n",
    "Dict['id2relation'] = id2relation\n",
    "\n",
    "with open('../weight_bin/' + ids_name + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(Dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25a5deac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating big-batches for path-based model 100 3103\n",
      "generating big-batches for path-based model 200 3103\n",
      "generating big-batches for path-based model 300 3103\n",
      "generating big-batches for path-based model 400 3103\n",
      "generating big-batches for path-based model 500 3103\n",
      "generating big-batches for path-based model 600 3103\n",
      "generating big-batches for path-based model 700 3103\n",
      "generating big-batches for path-based model 800 3103\n",
      "generating big-batches for path-based model 900 3103\n",
      "generating big-batches for path-based model 1000 3103\n",
      "generating big-batches for path-based model 1100 3103\n",
      "generating big-batches for path-based model 1200 3103\n",
      "generating big-batches for path-based model 1300 3103\n",
      "generating big-batches for path-based model 1400 3103\n",
      "generating big-batches for path-based model 1500 3103\n",
      "generating big-batches for path-based model 1600 3103\n",
      "generating big-batches for path-based model 1700 3103\n",
      "generating big-batches for path-based model 1800 3103\n",
      "generating big-batches for path-based model 1900 3103\n",
      "generating big-batches for path-based model 2000 3103\n",
      "generating big-batches for path-based model 2100 3103\n",
      "generating big-batches for path-based model 2200 3103\n",
      "generating big-batches for path-based model 2300 3103\n",
      "generating big-batches for path-based model 2400 3103\n",
      "generating big-batches for path-based model 2500 3103\n",
      "generating big-batches for path-based model 2600 3103\n",
      "generating big-batches for path-based model 2700 3103\n",
      "generating big-batches for path-based model 2800 3103\n",
      "generating big-batches for path-based model 2900 3103\n",
      "generating big-batches for path-based model 3000 3103\n",
      "generating big-batches for path-based model 3100 3103\n",
      "generating big-batches for path-based model 100 522\n",
      "generating big-batches for path-based model 200 522\n",
      "generating big-batches for path-based model 300 522\n",
      "generating big-batches for path-based model 400 522\n",
      "generating big-batches for path-based model 500 522\n",
      "Epoch 1/10\n",
      "1211/1211 [==============================] - 58s 43ms/step - loss: 0.5115 - binary_accuracy: 0.8414 - val_loss: 0.3953 - val_binary_accuracy: 0.8716\n",
      "Epoch 2/10\n",
      "1211/1211 [==============================] - 50s 41ms/step - loss: 0.3556 - binary_accuracy: 0.9084 - val_loss: 0.2855 - val_binary_accuracy: 0.9181\n",
      "Epoch 3/10\n",
      "1211/1211 [==============================] - 49s 41ms/step - loss: 0.3095 - binary_accuracy: 0.9325 - val_loss: 0.2741 - val_binary_accuracy: 0.9310\n",
      "Epoch 4/10\n",
      "1211/1211 [==============================] - 50s 41ms/step - loss: 0.3492 - binary_accuracy: 0.9229 - val_loss: 0.2836 - val_binary_accuracy: 0.9281\n",
      "Epoch 5/10\n",
      "1211/1211 [==============================] - 50s 41ms/step - loss: 0.2762 - binary_accuracy: 0.9453 - val_loss: 0.2506 - val_binary_accuracy: 0.9418\n",
      "Epoch 6/10\n",
      "1211/1211 [==============================] - 49s 41ms/step - loss: 0.2542 - binary_accuracy: 0.9528 - val_loss: 0.2442 - val_binary_accuracy: 0.9430\n",
      "Epoch 7/10\n",
      "1211/1211 [==============================] - 49s 41ms/step - loss: 0.2530 - binary_accuracy: 0.9533 - val_loss: 0.2423 - val_binary_accuracy: 0.9430\n",
      "Epoch 8/10\n",
      "1211/1211 [==============================] - 49s 41ms/step - loss: 0.2393 - binary_accuracy: 0.9599 - val_loss: 0.2482 - val_binary_accuracy: 0.9405\n",
      "Epoch 9/10\n",
      "1211/1211 [==============================] - 50s 42ms/step - loss: 0.1455 - binary_accuracy: 0.9642 - val_loss: 0.1691 - val_binary_accuracy: 0.9507\n",
      "Epoch 10/10\n",
      "1211/1211 [==============================] - 50s 41ms/step - loss: 0.0860 - binary_accuracy: 0.9730 - val_loss: 0.1721 - val_binary_accuracy: 0.9464\n",
      "Save model\n"
     ]
    }
   ],
   "source": [
    "###train the path-based model\n",
    "lower_bd = 1\n",
    "upper_bd = 10\n",
    "num_epoch = 10\n",
    "batch_size = 32\n",
    "        \n",
    "#define the training lists\n",
    "train_p_list, train_r_list, train_y_list = {'1': [], '2': [], '3': []}, list(), list()\n",
    "\n",
    "#define the validation lists\n",
    "valid_p_list, valid_r_list, valid_y_list = {'1': [], '2': [], '3': []}, list(), list()\n",
    "\n",
    "#######################################\n",
    "###build the big-batches###############      \n",
    "\n",
    "#fill in the training array list\n",
    "build_big_batches_path(lower_bd, upper_bd, data, one_hop, s_t_r,\n",
    "                      train_p_list, train_r_list, train_y_list,\n",
    "                      relation2id, entity2id, id2relation, id2entity)\n",
    "\n",
    "#fill in the validation array list\n",
    "build_big_batches_path(lower_bd, upper_bd, data_valid, one_hop_valid, s_t_r_valid,\n",
    "                      valid_p_list, valid_r_list, valid_y_list,\n",
    "                      relation2id, entity2id, id2relation, id2entity)    \n",
    "\n",
    "#######################################\n",
    "###do the training#####################\n",
    "#sometimes the validation dataset is so small so sparse, \n",
    "#which cannot find three paths between any pair of s and t.\n",
    "#in such a case, we will divide the training big-batch into train and valid\n",
    "if len(valid_y_list) >= 100:\n",
    "    #generate the input arrays\n",
    "    x_train_1 = np.asarray(train_p_list['1'], dtype='int')\n",
    "    x_train_2 = np.asarray(train_p_list['2'], dtype='int')\n",
    "    x_train_3 = np.asarray(train_p_list['3'], dtype='int')\n",
    "    x_train_r = np.asarray(train_r_list, dtype='int')\n",
    "    y_train = np.asarray(train_y_list, dtype='int')\n",
    "\n",
    "    #generate the validation arrays\n",
    "    x_valid_1 = np.asarray(valid_p_list['1'], dtype='int')\n",
    "    x_valid_2 = np.asarray(valid_p_list['2'], dtype='int')\n",
    "    x_valid_3 = np.asarray(valid_p_list['3'], dtype='int')\n",
    "    x_valid_r = np.asarray(valid_r_list, dtype='int')\n",
    "    y_valid = np.asarray(valid_y_list, dtype='int')\n",
    "\n",
    "else:\n",
    "    split = int(len(train_y_list)*0.8)\n",
    "    #generate the input arrays\n",
    "    x_train_1 = np.asarray(train_p_list['1'][:split], dtype='int')\n",
    "    x_train_2 = np.asarray(train_p_list['2'][:split], dtype='int')\n",
    "    x_train_3 = np.asarray(train_p_list['3'][:split], dtype='int')\n",
    "    x_train_r = np.asarray(train_r_list[:split], dtype='int')\n",
    "    y_train = np.asarray(train_y_list[:split], dtype='int')\n",
    "\n",
    "    #generate the validation arrays\n",
    "    x_valid_1 = np.asarray(train_p_list['1'][split:], dtype='int')\n",
    "    x_valid_2 = np.asarray(train_p_list['2'][split:], dtype='int')\n",
    "    x_valid_3 = np.asarray(train_p_list['3'][split:], dtype='int')\n",
    "    x_valid_r = np.asarray(train_r_list[split:], dtype='int')\n",
    "    y_valid = np.asarray(train_y_list[split:], dtype='int')\n",
    "\n",
    "#do the training\n",
    "model.fit([x_train_1, x_train_2, x_train_3, x_train_r], y_train, \n",
    "          validation_data=([x_valid_1, x_valid_2, x_valid_3, x_valid_r], y_valid),\n",
    "          batch_size=batch_size, epochs=num_epoch)   \n",
    "\n",
    "# Save model and weights\n",
    "add_h5 = model_name + '.h5'\n",
    "save_dir = os.path.join(os.getcwd(), '../weight_bin')\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, add_h5)\n",
    "model.save(model_path)\n",
    "print('Save model')\n",
    "del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b89853c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating and storing paths for the path-based model 100 3103\n",
      "generating and storing paths for the path-based model 200 3103\n",
      "generating and storing paths for the path-based model 300 3103\n",
      "generating and storing paths for the path-based model 400 3103\n",
      "generating and storing paths for the path-based model 500 3103\n",
      "generating and storing paths for the path-based model 600 3103\n",
      "generating and storing paths for the path-based model 700 3103\n",
      "generating and storing paths for the path-based model 800 3103\n",
      "generating and storing paths for the path-based model 900 3103\n",
      "generating and storing paths for the path-based model 1000 3103\n",
      "generating and storing paths for the path-based model 1100 3103\n",
      "generating and storing paths for the path-based model 1200 3103\n",
      "generating and storing paths for the path-based model 1300 3103\n",
      "generating and storing paths for the path-based model 1400 3103\n",
      "generating and storing paths for the path-based model 1500 3103\n",
      "generating and storing paths for the path-based model 1600 3103\n",
      "generating and storing paths for the path-based model 1700 3103\n",
      "generating and storing paths for the path-based model 1800 3103\n",
      "generating and storing paths for the path-based model 1900 3103\n",
      "generating and storing paths for the path-based model 2000 3103\n",
      "generating and storing paths for the path-based model 2100 3103\n",
      "generating and storing paths for the path-based model 2200 3103\n",
      "generating and storing paths for the path-based model 2300 3103\n",
      "generating and storing paths for the path-based model 2400 3103\n",
      "generating and storing paths for the path-based model 2500 3103\n",
      "generating and storing paths for the path-based model 2600 3103\n",
      "generating and storing paths for the path-based model 2700 3103\n",
      "generating and storing paths for the path-based model 2800 3103\n",
      "generating and storing paths for the path-based model 2900 3103\n",
      "generating and storing paths for the path-based model 3000 3103\n",
      "generating and storing paths for the path-based model 3100 3103\n",
      "generating and storing paths for the path-based model 100 522\n",
      "generating and storing paths for the path-based model 200 522\n",
      "generating and storing paths for the path-based model 300 522\n",
      "generating and storing paths for the path-based model 400 522\n",
      "generating and storing paths for the path-based model 500 522\n",
      "generating big-batches for subgraph-based model 0 4687 0\n",
      "generating big-batches for subgraph-based model 200 4687 0\n",
      "generating big-batches for subgraph-based model 400 4687 0\n",
      "generating big-batches for subgraph-based model 600 4687 0\n",
      "generating big-batches for subgraph-based model 800 4687 0\n",
      "generating big-batches for subgraph-based model 1000 4687 0\n",
      "generating big-batches for subgraph-based model 1200 4687 0\n",
      "generating big-batches for subgraph-based model 1400 4687 0\n",
      "generating big-batches for subgraph-based model 1600 4687 0\n",
      "generating big-batches for subgraph-based model 1800 4687 0\n",
      "generating big-batches for subgraph-based model 2000 4687 0\n",
      "generating big-batches for subgraph-based model 2200 4687 0\n",
      "generating big-batches for subgraph-based model 2400 4687 0\n",
      "generating big-batches for subgraph-based model 2600 4687 0\n",
      "generating big-batches for subgraph-based model 2800 4687 0\n",
      "generating big-batches for subgraph-based model 3000 4687 0\n",
      "generating big-batches for subgraph-based model 3200 4687 0\n",
      "generating big-batches for subgraph-based model 3400 4687 0\n",
      "generating big-batches for subgraph-based model 3600 4687 0\n",
      "generating big-batches for subgraph-based model 3800 4687 0\n",
      "generating big-batches for subgraph-based model 4000 4687 0\n",
      "generating big-batches for subgraph-based model 4200 4687 0\n",
      "generating big-batches for subgraph-based model 4400 4687 0\n",
      "generating big-batches for subgraph-based model 4600 4687 0\n",
      "generating big-batches for subgraph-based model 0 4687 1\n",
      "generating big-batches for subgraph-based model 200 4687 1\n",
      "generating big-batches for subgraph-based model 400 4687 1\n",
      "generating big-batches for subgraph-based model 600 4687 1\n",
      "generating big-batches for subgraph-based model 800 4687 1\n",
      "generating big-batches for subgraph-based model 1000 4687 1\n",
      "generating big-batches for subgraph-based model 1200 4687 1\n",
      "generating big-batches for subgraph-based model 1400 4687 1\n",
      "generating big-batches for subgraph-based model 1600 4687 1\n",
      "generating big-batches for subgraph-based model 1800 4687 1\n",
      "generating big-batches for subgraph-based model 2000 4687 1\n",
      "generating big-batches for subgraph-based model 2200 4687 1\n",
      "generating big-batches for subgraph-based model 2400 4687 1\n",
      "generating big-batches for subgraph-based model 2600 4687 1\n",
      "generating big-batches for subgraph-based model 2800 4687 1\n",
      "generating big-batches for subgraph-based model 3000 4687 1\n",
      "generating big-batches for subgraph-based model 3200 4687 1\n",
      "generating big-batches for subgraph-based model 3400 4687 1\n",
      "generating big-batches for subgraph-based model 3600 4687 1\n",
      "generating big-batches for subgraph-based model 3800 4687 1\n",
      "generating big-batches for subgraph-based model 4000 4687 1\n",
      "generating big-batches for subgraph-based model 4200 4687 1\n",
      "generating big-batches for subgraph-based model 4400 4687 1\n",
      "generating big-batches for subgraph-based model 4600 4687 1\n",
      "generating big-batches for subgraph-based model 0 4687 2\n",
      "generating big-batches for subgraph-based model 200 4687 2\n",
      "generating big-batches for subgraph-based model 400 4687 2\n",
      "generating big-batches for subgraph-based model 600 4687 2\n",
      "generating big-batches for subgraph-based model 800 4687 2\n",
      "generating big-batches for subgraph-based model 1000 4687 2\n",
      "generating big-batches for subgraph-based model 1200 4687 2\n",
      "generating big-batches for subgraph-based model 1400 4687 2\n",
      "generating big-batches for subgraph-based model 1600 4687 2\n",
      "generating big-batches for subgraph-based model 1800 4687 2\n",
      "generating big-batches for subgraph-based model 2000 4687 2\n",
      "generating big-batches for subgraph-based model 2200 4687 2\n",
      "generating big-batches for subgraph-based model 2400 4687 2\n",
      "generating big-batches for subgraph-based model 2600 4687 2\n",
      "generating big-batches for subgraph-based model 2800 4687 2\n",
      "generating big-batches for subgraph-based model 3000 4687 2\n",
      "generating big-batches for subgraph-based model 3200 4687 2\n",
      "generating big-batches for subgraph-based model 3400 4687 2\n",
      "generating big-batches for subgraph-based model 3600 4687 2\n",
      "generating big-batches for subgraph-based model 3800 4687 2\n",
      "generating big-batches for subgraph-based model 4000 4687 2\n",
      "generating big-batches for subgraph-based model 4200 4687 2\n",
      "generating big-batches for subgraph-based model 4400 4687 2\n",
      "generating big-batches for subgraph-based model 4600 4687 2\n",
      "generating big-batches for subgraph-based model 0 4687 3\n",
      "generating big-batches for subgraph-based model 200 4687 3\n",
      "generating big-batches for subgraph-based model 400 4687 3\n",
      "generating big-batches for subgraph-based model 600 4687 3\n",
      "generating big-batches for subgraph-based model 800 4687 3\n",
      "generating big-batches for subgraph-based model 1000 4687 3\n",
      "generating big-batches for subgraph-based model 1200 4687 3\n",
      "generating big-batches for subgraph-based model 1400 4687 3\n",
      "generating big-batches for subgraph-based model 1600 4687 3\n",
      "generating big-batches for subgraph-based model 1800 4687 3\n",
      "generating big-batches for subgraph-based model 2000 4687 3\n",
      "generating big-batches for subgraph-based model 2200 4687 3\n",
      "generating big-batches for subgraph-based model 2400 4687 3\n",
      "generating big-batches for subgraph-based model 2600 4687 3\n",
      "generating big-batches for subgraph-based model 2800 4687 3\n",
      "generating big-batches for subgraph-based model 3000 4687 3\n",
      "generating big-batches for subgraph-based model 3200 4687 3\n",
      "generating big-batches for subgraph-based model 3400 4687 3\n",
      "generating big-batches for subgraph-based model 3600 4687 3\n",
      "generating big-batches for subgraph-based model 3800 4687 3\n",
      "generating big-batches for subgraph-based model 4000 4687 3\n",
      "generating big-batches for subgraph-based model 4200 4687 3\n",
      "generating big-batches for subgraph-based model 4400 4687 3\n",
      "generating big-batches for subgraph-based model 4600 4687 3\n",
      "generating big-batches for subgraph-based model 0 4687 4\n",
      "generating big-batches for subgraph-based model 200 4687 4\n",
      "generating big-batches for subgraph-based model 400 4687 4\n",
      "generating big-batches for subgraph-based model 600 4687 4\n",
      "generating big-batches for subgraph-based model 800 4687 4\n",
      "generating big-batches for subgraph-based model 1000 4687 4\n",
      "generating big-batches for subgraph-based model 1200 4687 4\n",
      "generating big-batches for subgraph-based model 1400 4687 4\n",
      "generating big-batches for subgraph-based model 1600 4687 4\n",
      "generating big-batches for subgraph-based model 1800 4687 4\n",
      "generating big-batches for subgraph-based model 2000 4687 4\n",
      "generating big-batches for subgraph-based model 2200 4687 4\n",
      "generating big-batches for subgraph-based model 2400 4687 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating big-batches for subgraph-based model 2600 4687 4\n",
      "generating big-batches for subgraph-based model 2800 4687 4\n",
      "generating big-batches for subgraph-based model 3000 4687 4\n",
      "generating big-batches for subgraph-based model 3200 4687 4\n",
      "generating big-batches for subgraph-based model 3400 4687 4\n",
      "generating big-batches for subgraph-based model 3600 4687 4\n",
      "generating big-batches for subgraph-based model 3800 4687 4\n",
      "generating big-batches for subgraph-based model 4000 4687 4\n",
      "generating big-batches for subgraph-based model 4200 4687 4\n",
      "generating big-batches for subgraph-based model 4400 4687 4\n",
      "generating big-batches for subgraph-based model 4600 4687 4\n",
      "generating big-batches for subgraph-based model 0 4687 5\n",
      "generating big-batches for subgraph-based model 200 4687 5\n",
      "generating big-batches for subgraph-based model 400 4687 5\n",
      "generating big-batches for subgraph-based model 600 4687 5\n",
      "generating big-batches for subgraph-based model 800 4687 5\n",
      "generating big-batches for subgraph-based model 1000 4687 5\n",
      "generating big-batches for subgraph-based model 1200 4687 5\n",
      "generating big-batches for subgraph-based model 1400 4687 5\n",
      "generating big-batches for subgraph-based model 1600 4687 5\n",
      "generating big-batches for subgraph-based model 1800 4687 5\n",
      "generating big-batches for subgraph-based model 2000 4687 5\n",
      "generating big-batches for subgraph-based model 2200 4687 5\n",
      "generating big-batches for subgraph-based model 2400 4687 5\n",
      "generating big-batches for subgraph-based model 2600 4687 5\n",
      "generating big-batches for subgraph-based model 2800 4687 5\n",
      "generating big-batches for subgraph-based model 3000 4687 5\n",
      "generating big-batches for subgraph-based model 3200 4687 5\n",
      "generating big-batches for subgraph-based model 3400 4687 5\n",
      "generating big-batches for subgraph-based model 3600 4687 5\n",
      "generating big-batches for subgraph-based model 3800 4687 5\n",
      "generating big-batches for subgraph-based model 4000 4687 5\n",
      "generating big-batches for subgraph-based model 4200 4687 5\n",
      "generating big-batches for subgraph-based model 4400 4687 5\n",
      "generating big-batches for subgraph-based model 4600 4687 5\n",
      "generating big-batches for subgraph-based model 0 4687 6\n",
      "generating big-batches for subgraph-based model 200 4687 6\n",
      "generating big-batches for subgraph-based model 400 4687 6\n",
      "generating big-batches for subgraph-based model 600 4687 6\n",
      "generating big-batches for subgraph-based model 800 4687 6\n",
      "generating big-batches for subgraph-based model 1000 4687 6\n",
      "generating big-batches for subgraph-based model 1200 4687 6\n",
      "generating big-batches for subgraph-based model 1400 4687 6\n",
      "generating big-batches for subgraph-based model 1600 4687 6\n",
      "generating big-batches for subgraph-based model 1800 4687 6\n",
      "generating big-batches for subgraph-based model 2000 4687 6\n",
      "generating big-batches for subgraph-based model 2200 4687 6\n",
      "generating big-batches for subgraph-based model 2400 4687 6\n",
      "generating big-batches for subgraph-based model 2600 4687 6\n",
      "generating big-batches for subgraph-based model 2800 4687 6\n",
      "generating big-batches for subgraph-based model 3000 4687 6\n",
      "generating big-batches for subgraph-based model 3200 4687 6\n",
      "generating big-batches for subgraph-based model 3400 4687 6\n",
      "generating big-batches for subgraph-based model 3600 4687 6\n",
      "generating big-batches for subgraph-based model 3800 4687 6\n",
      "generating big-batches for subgraph-based model 4000 4687 6\n",
      "generating big-batches for subgraph-based model 4200 4687 6\n",
      "generating big-batches for subgraph-based model 4400 4687 6\n",
      "generating big-batches for subgraph-based model 4600 4687 6\n",
      "generating big-batches for subgraph-based model 0 4687 7\n",
      "generating big-batches for subgraph-based model 200 4687 7\n",
      "generating big-batches for subgraph-based model 400 4687 7\n",
      "generating big-batches for subgraph-based model 600 4687 7\n",
      "generating big-batches for subgraph-based model 800 4687 7\n",
      "generating big-batches for subgraph-based model 1000 4687 7\n",
      "generating big-batches for subgraph-based model 1200 4687 7\n",
      "generating big-batches for subgraph-based model 1400 4687 7\n",
      "generating big-batches for subgraph-based model 1600 4687 7\n",
      "generating big-batches for subgraph-based model 1800 4687 7\n",
      "generating big-batches for subgraph-based model 2000 4687 7\n",
      "generating big-batches for subgraph-based model 2200 4687 7\n",
      "generating big-batches for subgraph-based model 2400 4687 7\n",
      "generating big-batches for subgraph-based model 2600 4687 7\n",
      "generating big-batches for subgraph-based model 2800 4687 7\n",
      "generating big-batches for subgraph-based model 3000 4687 7\n",
      "generating big-batches for subgraph-based model 3200 4687 7\n",
      "generating big-batches for subgraph-based model 3400 4687 7\n",
      "generating big-batches for subgraph-based model 3600 4687 7\n",
      "generating big-batches for subgraph-based model 3800 4687 7\n",
      "generating big-batches for subgraph-based model 4000 4687 7\n",
      "generating big-batches for subgraph-based model 4200 4687 7\n",
      "generating big-batches for subgraph-based model 4400 4687 7\n",
      "generating big-batches for subgraph-based model 4600 4687 7\n",
      "generating big-batches for subgraph-based model 0 4687 8\n",
      "generating big-batches for subgraph-based model 200 4687 8\n",
      "generating big-batches for subgraph-based model 400 4687 8\n",
      "generating big-batches for subgraph-based model 600 4687 8\n",
      "generating big-batches for subgraph-based model 800 4687 8\n",
      "generating big-batches for subgraph-based model 1000 4687 8\n",
      "generating big-batches for subgraph-based model 1200 4687 8\n",
      "generating big-batches for subgraph-based model 1400 4687 8\n",
      "generating big-batches for subgraph-based model 1600 4687 8\n",
      "generating big-batches for subgraph-based model 1800 4687 8\n",
      "generating big-batches for subgraph-based model 2000 4687 8\n",
      "generating big-batches for subgraph-based model 2200 4687 8\n",
      "generating big-batches for subgraph-based model 2400 4687 8\n",
      "generating big-batches for subgraph-based model 2600 4687 8\n",
      "generating big-batches for subgraph-based model 2800 4687 8\n",
      "generating big-batches for subgraph-based model 3000 4687 8\n",
      "generating big-batches for subgraph-based model 3200 4687 8\n",
      "generating big-batches for subgraph-based model 3400 4687 8\n",
      "generating big-batches for subgraph-based model 3600 4687 8\n",
      "generating big-batches for subgraph-based model 3800 4687 8\n",
      "generating big-batches for subgraph-based model 4000 4687 8\n",
      "generating big-batches for subgraph-based model 4200 4687 8\n",
      "generating big-batches for subgraph-based model 4400 4687 8\n",
      "generating big-batches for subgraph-based model 4600 4687 8\n",
      "generating big-batches for subgraph-based model 0 4687 9\n",
      "generating big-batches for subgraph-based model 200 4687 9\n",
      "generating big-batches for subgraph-based model 400 4687 9\n",
      "generating big-batches for subgraph-based model 600 4687 9\n",
      "generating big-batches for subgraph-based model 800 4687 9\n",
      "generating big-batches for subgraph-based model 1000 4687 9\n",
      "generating big-batches for subgraph-based model 1200 4687 9\n",
      "generating big-batches for subgraph-based model 1400 4687 9\n",
      "generating big-batches for subgraph-based model 1600 4687 9\n",
      "generating big-batches for subgraph-based model 1800 4687 9\n",
      "generating big-batches for subgraph-based model 2000 4687 9\n",
      "generating big-batches for subgraph-based model 2200 4687 9\n",
      "generating big-batches for subgraph-based model 2400 4687 9\n",
      "generating big-batches for subgraph-based model 2600 4687 9\n",
      "generating big-batches for subgraph-based model 2800 4687 9\n",
      "generating big-batches for subgraph-based model 3000 4687 9\n",
      "generating big-batches for subgraph-based model 3200 4687 9\n",
      "generating big-batches for subgraph-based model 3400 4687 9\n",
      "generating big-batches for subgraph-based model 3600 4687 9\n",
      "generating big-batches for subgraph-based model 3800 4687 9\n",
      "generating big-batches for subgraph-based model 4000 4687 9\n",
      "generating big-batches for subgraph-based model 4200 4687 9\n",
      "generating big-batches for subgraph-based model 4400 4687 9\n",
      "generating big-batches for subgraph-based model 4600 4687 9\n",
      "generating big-batches for subgraph-based model 0 414 0\n",
      "generating big-batches for subgraph-based model 200 414 0\n",
      "generating big-batches for subgraph-based model 400 414 0\n",
      "generating big-batches for subgraph-based model 0 414 1\n",
      "generating big-batches for subgraph-based model 200 414 1\n",
      "generating big-batches for subgraph-based model 400 414 1\n",
      "generating big-batches for subgraph-based model 0 414 2\n",
      "generating big-batches for subgraph-based model 200 414 2\n",
      "generating big-batches for subgraph-based model 400 414 2\n",
      "generating big-batches for subgraph-based model 0 414 3\n",
      "generating big-batches for subgraph-based model 200 414 3\n",
      "generating big-batches for subgraph-based model 400 414 3\n",
      "generating big-batches for subgraph-based model 0 414 4\n",
      "generating big-batches for subgraph-based model 200 414 4\n",
      "generating big-batches for subgraph-based model 400 414 4\n",
      "generating big-batches for subgraph-based model 0 414 5\n",
      "generating big-batches for subgraph-based model 200 414 5\n",
      "generating big-batches for subgraph-based model 400 414 5\n",
      "generating big-batches for subgraph-based model 0 414 6\n",
      "generating big-batches for subgraph-based model 200 414 6\n",
      "generating big-batches for subgraph-based model 400 414 6\n",
      "generating big-batches for subgraph-based model 0 414 7\n",
      "generating big-batches for subgraph-based model 200 414 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating big-batches for subgraph-based model 400 414 7\n",
      "generating big-batches for subgraph-based model 0 414 8\n",
      "generating big-batches for subgraph-based model 200 414 8\n",
      "generating big-batches for subgraph-based model 400 414 8\n",
      "generating big-batches for subgraph-based model 0 414 9\n",
      "generating big-batches for subgraph-based model 200 414 9\n",
      "generating big-batches for subgraph-based model 400 414 9\n",
      "Epoch 1/10\n",
      "8385/8385 [==============================] - 397s 46ms/step - loss: 0.4307 - binary_accuracy: 0.8233 - val_loss: 0.3413 - val_binary_accuracy: 0.8658\n",
      "Epoch 2/10\n",
      "8385/8385 [==============================] - 375s 45ms/step - loss: 0.2871 - binary_accuracy: 0.8945 - val_loss: 0.2780 - val_binary_accuracy: 0.9037\n",
      "Epoch 3/10\n",
      "8385/8385 [==============================] - 5703s 680ms/step - loss: 0.2471 - binary_accuracy: 0.9143 - val_loss: 0.2805 - val_binary_accuracy: 0.8976\n",
      "Epoch 4/10\n",
      "8385/8385 [==============================] - 2122s 253ms/step - loss: 0.2291 - binary_accuracy: 0.9222 - val_loss: 0.2787 - val_binary_accuracy: 0.8943\n",
      "Epoch 5/10\n",
      "8385/8385 [==============================] - 390s 47ms/step - loss: 0.2153 - binary_accuracy: 0.9281 - val_loss: 0.2797 - val_binary_accuracy: 0.8990\n",
      "Epoch 6/10\n",
      "8385/8385 [==============================] - 390s 46ms/step - loss: 0.2050 - binary_accuracy: 0.9324 - val_loss: 0.2774 - val_binary_accuracy: 0.8966\n",
      "Epoch 7/10\n",
      "8385/8385 [==============================] - 388s 46ms/step - loss: 0.1959 - binary_accuracy: 0.9362 - val_loss: 0.2834 - val_binary_accuracy: 0.8947\n",
      "Epoch 8/10\n",
      "8385/8385 [==============================] - 391s 47ms/step - loss: 0.1882 - binary_accuracy: 0.9397 - val_loss: 0.2810 - val_binary_accuracy: 0.8904\n",
      "Epoch 9/10\n",
      "8385/8385 [==============================] - 387s 46ms/step - loss: 0.1822 - binary_accuracy: 0.9419 - val_loss: 0.2889 - val_binary_accuracy: 0.8908\n",
      "Epoch 10/10\n",
      "8385/8385 [==============================] - 390s 47ms/step - loss: 0.1767 - binary_accuracy: 0.9437 - val_loss: 0.2913 - val_binary_accuracy: 0.8836\n",
      "Save model\n"
     ]
    }
   ],
   "source": [
    "###train the subgraph-based model\n",
    "lower_bd = 1\n",
    "upper_bd = 6\n",
    "num_epoch = 10\n",
    "batch_size = 32\n",
    "\n",
    "Dict_train = store_subgraph_dicts(lower_bd, upper_bd, data, one_hop, s_t_r,\n",
    "                         relation2id, entity2id, id2relation, id2entity)\n",
    "\n",
    "Dict_valid = store_subgraph_dicts(lower_bd, upper_bd, data_valid, one_hop_valid, s_t_r_valid,\n",
    "                         relation2id, entity2id, id2relation, id2entity)\n",
    "        \n",
    "#define the training lists\n",
    "train_s_list, train_t_list, train_r_list, train_y_list = {'1': [], '2': [], '3': []}, {'1': [], '2': [], '3': []}, list(), list()\n",
    "\n",
    "#define the validation lists\n",
    "valid_s_list, valid_t_list, valid_r_list, valid_y_list = {'1': [], '2': [], '3': []}, {'1': [], '2': [], '3': []}, list(), list()\n",
    "\n",
    "#######################################\n",
    "###build the big-batches###############      \n",
    "\n",
    "#fill in the training array list\n",
    "build_big_batches_subgraph(lower_bd, upper_bd, data, one_hop, s_t_r,\n",
    "                      train_s_list, train_t_list, train_r_list, train_y_list, Dict_train,\n",
    "                      relation2id, entity2id, id2relation, id2entity)\n",
    "\n",
    "#fill in the validation array list\n",
    "build_big_batches_subgraph(lower_bd, upper_bd, data_valid, one_hop_valid, s_t_r_valid,\n",
    "                      valid_s_list, valid_t_list, valid_r_list, valid_y_list, Dict_valid,\n",
    "                      relation2id, entity2id, id2relation, id2entity)    \n",
    "\n",
    "#######################################\n",
    "###do the training#####################\n",
    "#sometimes the validation dataset is so small so sparse, \n",
    "#which cannot find three paths between any pair of s and t.\n",
    "#in such a case, we will divide the training big-batch into train and valid\n",
    "if len(valid_y_list) >= 100:\n",
    "    #generate the input arrays\n",
    "    x_train_s_1 = np.asarray(train_s_list['1'], dtype='int')\n",
    "    x_train_s_2 = np.asarray(train_s_list['2'], dtype='int')\n",
    "    x_train_s_3 = np.asarray(train_s_list['3'], dtype='int')\n",
    "\n",
    "    x_train_t_1 = np.asarray(train_t_list['1'], dtype='int')\n",
    "    x_train_t_2 = np.asarray(train_t_list['2'], dtype='int')\n",
    "    x_train_t_3 = np.asarray(train_t_list['3'], dtype='int')\n",
    "\n",
    "    x_train_r = np.asarray(train_r_list, dtype='int')\n",
    "    y_train = np.asarray(train_y_list, dtype='int')\n",
    "\n",
    "    #generate the validation arrays\n",
    "    x_valid_s_1 = np.asarray(valid_s_list['1'], dtype='int')\n",
    "    x_valid_s_2 = np.asarray(valid_s_list['2'], dtype='int')\n",
    "    x_valid_s_3 = np.asarray(valid_s_list['3'], dtype='int')\n",
    "\n",
    "    x_valid_t_1 = np.asarray(valid_t_list['1'], dtype='int')\n",
    "    x_valid_t_2 = np.asarray(valid_t_list['2'], dtype='int')\n",
    "    x_valid_t_3 = np.asarray(valid_t_list['3'], dtype='int')\n",
    "\n",
    "    x_valid_r = np.asarray(valid_r_list, dtype='int')\n",
    "    y_valid = np.asarray(valid_y_list, dtype='int')\n",
    "\n",
    "else:\n",
    "    split = int(len(train_y_list)*0.8)\n",
    "    #generate the input arrays\n",
    "    x_train_s_1 = np.asarray(train_s_list['1'][:split], dtype='int')\n",
    "    x_train_s_2 = np.asarray(train_s_list['2'][:split], dtype='int')\n",
    "    x_train_s_3 = np.asarray(train_s_list['3'][:split], dtype='int')\n",
    "\n",
    "    x_train_t_1 = np.asarray(train_t_list['1'][:split], dtype='int')\n",
    "    x_train_t_2 = np.asarray(train_t_list['2'][:split], dtype='int')\n",
    "    x_train_t_3 = np.asarray(train_t_list['3'][:split], dtype='int')\n",
    "\n",
    "    x_train_r = np.asarray(train_r_list[:split], dtype='int')\n",
    "    y_train = np.asarray(train_y_list[:split], dtype='int')\n",
    "\n",
    "    #generate the validation arrays\n",
    "    x_valid_s_1 = np.asarray(train_s_list['1'][split:], dtype='int')\n",
    "    x_valid_s_2 = np.asarray(train_s_list['2'][split:], dtype='int')\n",
    "    x_valid_s_3 = np.asarray(train_s_list['3'][split:], dtype='int')\n",
    "\n",
    "    x_valid_t_1 = np.asarray(train_t_list['1'][split:], dtype='int')\n",
    "    x_valid_t_2 = np.asarray(train_t_list['2'][split:], dtype='int')\n",
    "    x_valid_t_3 = np.asarray(train_t_list['3'][split:], dtype='int')\n",
    "\n",
    "    x_valid_r = np.asarray(train_r_list[split:], dtype='int')\n",
    "    y_valid = np.asarray(train_y_list[split:], dtype='int')\n",
    "\n",
    "#do the training\n",
    "model_2.fit([x_train_s_1, x_train_s_2, x_train_s_3, x_train_t_1, x_train_t_2, x_train_t_3, x_train_r], y_train, \n",
    "          validation_data=([x_valid_s_1, x_valid_s_2, x_valid_s_3, x_valid_t_1, x_valid_t_2, x_valid_t_3, x_valid_r], y_valid),\n",
    "          batch_size=batch_size, epochs=num_epoch)\n",
    "\n",
    "# Save model and weights\n",
    "one_hop_add_h5 = one_hop_model_name + '.h5'\n",
    "one_hop_save_dir = os.path.join(os.getcwd(), '../weight_bin')\n",
    "\n",
    "if not os.path.isdir(one_hop_save_dir):\n",
    "    os.makedirs(one_hop_save_dir)\n",
    "one_hop_model_path = os.path.join(one_hop_save_dir, one_hop_add_h5)\n",
    "model_2.save(one_hop_model_path)\n",
    "print('Save model')\n",
    "del(model_2, Dict_train, Dict_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74957c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178e81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9152c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cbcb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4df421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e4d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f86bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1d82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe787997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da50338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d51f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543feff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea551344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8526f0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef907e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e528e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4eca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729af14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107dff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c689768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14b6bf00",
   "metadata": {},
   "source": [
    "### Result on the testset for inductive link prediction\n",
    "\n",
    "We use the testset for inductive link prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207ef966",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'nell_v1'\n",
    "model_id = 'SiaLP_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e2a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#difine the names for saving\n",
    "model_name = 'Model_' + model_id + '_' + data_name\n",
    "one_hop_model_name = 'One_hop_model_' + model_id + '_' + data_name\n",
    "ids_name = 'IDs_' + model_id + '_' + data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c59ddf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IDs_SiaLP_6_nell_v1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae165f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One_hop_model_SiaLP_6_nell_v1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hop_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f87cc2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model_SiaLP_6_nell_v1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f959af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import opensmile\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c81c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadKG:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.x = 'Hello'\n",
    "        \n",
    "    def load_train_data(self, data_path, one_hop, data, s_t_r, entity2id, id2entity,\n",
    "                     relation2id, id2relation):\n",
    "        \n",
    "        data_ = set()\n",
    "    \n",
    "        ####load the train, valid and test set##########\n",
    "        with open (data_path, 'r') as f:\n",
    "            \n",
    "            data_ini = f.readlines()\n",
    "                        \n",
    "            for i in range(len(data_ini)):\n",
    "            \n",
    "                x = data_ini[i].split()\n",
    "                \n",
    "                x_ = tuple(x)\n",
    "                \n",
    "                data_.add(x_)\n",
    "        \n",
    "        ####relation dict#################\n",
    "        index = len(relation2id)\n",
    "     \n",
    "        for key in data_:\n",
    "            \n",
    "            if key[1] not in relation2id:\n",
    "                \n",
    "                relation = key[1]\n",
    "                \n",
    "                relation2id[relation] = index\n",
    "                \n",
    "                id2relation[index] = relation\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "                #the inverse relation\n",
    "                iv_r = '_inverse_' + relation\n",
    "                \n",
    "                relation2id[iv_r] = index\n",
    "                \n",
    "                id2relation[index] = iv_r\n",
    "                \n",
    "                index += 1\n",
    "        \n",
    "        #get the id of the inverse relation, by above definition, initial relation has \n",
    "        #always even id, while inverse relation has always odd id.\n",
    "        def inverse_r(r):\n",
    "            \n",
    "            if r % 2 == 0: #initial relation\n",
    "                \n",
    "                iv_r = r + 1\n",
    "            \n",
    "            else: #inverse relation\n",
    "                \n",
    "                iv_r = r - 1\n",
    "            \n",
    "            return(iv_r)\n",
    "        \n",
    "        ####entity dict###################\n",
    "        index = len(entity2id)\n",
    "        \n",
    "        for key in data_:\n",
    "            \n",
    "            source, target = key[0], key[2]\n",
    "            \n",
    "            if source not in entity2id:\n",
    "                                \n",
    "                entity2id[source] = index\n",
    "                \n",
    "                id2entity[index] = source\n",
    "                \n",
    "                index += 1\n",
    "            \n",
    "            if target not in entity2id:\n",
    "                \n",
    "                entity2id[target] = index\n",
    "                \n",
    "                id2entity[index] = target\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "        #create the set of triples using id instead of string        \n",
    "        for ele in data_:\n",
    "            \n",
    "            s = entity2id[ele[0]]\n",
    "            \n",
    "            r = relation2id[ele[1]]\n",
    "            \n",
    "            t = entity2id[ele[2]]\n",
    "            \n",
    "            if (s,r,t) not in data:\n",
    "                \n",
    "                data.add((s,r,t))\n",
    "            \n",
    "            s_t_r[(s,t)].add(r)\n",
    "            \n",
    "            if s not in one_hop:\n",
    "                \n",
    "                one_hop[s] = set()\n",
    "            \n",
    "            one_hop[s].add((r,t))\n",
    "            \n",
    "            if t not in one_hop:\n",
    "                \n",
    "                one_hop[t] = set()\n",
    "            \n",
    "            r_inv = inverse_r(r)\n",
    "            \n",
    "            s_t_r[(t,s)].add(r_inv)\n",
    "            \n",
    "            one_hop[t].add((r_inv,s))\n",
    "            \n",
    "        #change each set in one_hop to list\n",
    "        for e in one_hop:\n",
    "            \n",
    "            one_hop[e] = list(one_hop[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a714e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObtainPathsByDynamicProgramming:\n",
    "\n",
    "    def __init__(self, amount_bd=50, size_bd=50, threshold=20000):\n",
    "        \n",
    "        self.amount_bd = amount_bd #how many Tuples we choose in one_hop[node] for next recursion\n",
    "                        \n",
    "        self.size_bd = size_bd #size bound limit the number of paths to a target entity t\n",
    "        \n",
    "        #number of times paths with specific length been performed for recursion\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    '''\n",
    "    Given an entity s, the function will find the paths from s to other entities, using recursion.\n",
    "    \n",
    "    One may refer to LeetCode Problem 797 for details:\n",
    "        https://leetcode.com/problems/all-paths-from-source-to-target/\n",
    "    '''\n",
    "    def obtain_paths(self, mode, s, t_input, lower_bd, upper_bd, one_hop):\n",
    "\n",
    "        if type(lower_bd) != type(1) or lower_bd < 1:\n",
    "            \n",
    "            raise TypeError(\"!!! invalid lower bound setting, must >= 1 !!!\")\n",
    "            \n",
    "        if type(upper_bd) != type(1) or upper_bd < 1:\n",
    "            \n",
    "            raise TypeError(\"!!! invalid upper bound setting, must >= 1 !!!\")\n",
    "            \n",
    "        if lower_bd > upper_bd:\n",
    "            \n",
    "            raise TypeError(\"!!! lower bound must not exced upper bound !!!\")\n",
    "            \n",
    "        if s not in one_hop:\n",
    "            \n",
    "            raise ValueError('!!! entity not in one_hop. Please work on existing entities')\n",
    "\n",
    "        #here is the result dict. Its key is each entity t sharing paths from s\n",
    "        #The value of each t is a set containing the paths from s to t\n",
    "        #These paths can be either the direct connection r, or a multi-hop path\n",
    "        res = defaultdict(set)\n",
    "        \n",
    "        #qualified_t contains the types of t we want to consider,\n",
    "        #that is, what t will be added to the result set.\n",
    "        qualified_t = set()\n",
    "\n",
    "        #under this mode, we will only consider the direct neighbour of s\n",
    "        if mode == 'direct_neighbour':\n",
    "        \n",
    "            for Tuple in one_hop[s]:\n",
    "            \n",
    "                t = Tuple[1]\n",
    "                \n",
    "                qualified_t.add(t)\n",
    "        \n",
    "        #under this mode, we will only consider one specified entity t\n",
    "        elif mode == 'target_specified':\n",
    "            \n",
    "            qualified_t.add(t_input)\n",
    "        \n",
    "        #under this mode, we will consider any entity\n",
    "        elif mode == 'any_target':\n",
    "            \n",
    "            for s_any in one_hop:\n",
    "                \n",
    "                qualified_t.add(s_any)\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            raise ValueError('not a valid mode')\n",
    "        \n",
    "        '''\n",
    "        We use recursion to find the paths\n",
    "        On current node with the path [r1, ..., rk] and on-path entities {s, e1, ..., ek-1, node}\n",
    "        from s to this node, we will further find the direct neighbor t' of this node. \n",
    "        If t' is not an on-path entity (not among s, e1,...ek-1, node), we recursively proceed to t' \n",
    "        '''\n",
    "        def helper(node, path, on_path_en, res, qualified_t, lower_bd, upper_bd, one_hop, count_dict):\n",
    "\n",
    "            #when the current path is within lower_bd and upper_bd, \n",
    "            #and the node is among the qualified t, and it has not been fill of paths w.r.t size_limit,\n",
    "            #we will add this path to the node\n",
    "            if (len(path) >= lower_bd) and (len(path) <= upper_bd) and (\n",
    "                node in qualified_t) and (len(res[node]) < self.size_bd):\n",
    "                \n",
    "                res[node].add(tuple(path))\n",
    "                    \n",
    "            #won't start new recursions if the current path length already reaches upper limit\n",
    "            #or the number of recursions performed on this length has reached the limit\n",
    "            if (len(path) < upper_bd) and (count_dict[len(path)] <= self.threshold):\n",
    "                                \n",
    "                #temp list is the id list for us to go-over one_hop[node]\n",
    "                temp_list = [i for i in range(len(one_hop[node]))]\n",
    "                random.shuffle(temp_list) #so we random-shuffle the list\n",
    "                \n",
    "                #only take 20 recursions if there are too many (r,t)\n",
    "                for i in temp_list[:self.amount_bd]:\n",
    "                    \n",
    "                    #obtain tuple of (r,t)\n",
    "                    Tuple = one_hop[node][i]\n",
    "                    r, t = Tuple[0], Tuple[1]\n",
    "                    \n",
    "                    #add to count_dict even if eventually this step not proceed\n",
    "                    count_dict[len(path)] += 1\n",
    "                    \n",
    "                    #if t not on the path and we not exceed the computation threshold, \n",
    "                    #then finally proceed to next recursion\n",
    "                    if (t not in on_path_en) and (count_dict[len(path)] <= self.threshold):\n",
    "\n",
    "                        helper(t, path + [r], on_path_en.union({t}), res, qualified_t, \n",
    "                               lower_bd, upper_bd, one_hop, count_dict)\n",
    "\n",
    "        length_dict = defaultdict(int)\n",
    "        count_dict = defaultdict(int)\n",
    "        \n",
    "        helper(s, [], {s}, res, qualified_t, lower_bd, upper_bd, one_hop, count_dict)\n",
    "        \n",
    "        return(res, count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0d1f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the classes\n",
    "Class_1 = LoadKG()\n",
    "Class_2 = ObtainPathsByDynamicProgramming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f13661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load ids and relation/entity dicts\n",
    "with open('../weight_bin/' + ids_name + '.pickle', 'rb') as handle:\n",
    "    Dict = pickle.load(handle)\n",
    "    \n",
    "#save training data\n",
    "one_hop = Dict['one_hop']\n",
    "data = Dict['data']\n",
    "s_t_r = Dict['s_t_r']\n",
    "\n",
    "#save valid data\n",
    "one_hop_valid = Dict['one_hop_valid']\n",
    "data_valid = Dict['data_valid']\n",
    "s_t_r_valid = Dict['s_t_r_valid']\n",
    "\n",
    "#save test data\n",
    "one_hop_test = Dict['one_hop_test']\n",
    "data_test = Dict['data_test']\n",
    "s_t_r_test = Dict['s_t_r_test']\n",
    "\n",
    "#save shared dictionaries\n",
    "entity2id = Dict['entity2id']\n",
    "id2entity = Dict['id2entity']\n",
    "relation2id = Dict['relation2id']\n",
    "id2relation = Dict['id2relation']\n",
    "\n",
    "#we want to keep the initial entity/relation dicts before adding new entities\n",
    "entity2id_ini = deepcopy(entity2id)\n",
    "id2entity_ini = deepcopy(id2entity)\n",
    "relation2id_ini = deepcopy(relation2id)\n",
    "id2relation_ini = deepcopy(id2relation)\n",
    "\n",
    "num_r = len(id2relation)\n",
    "num_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74048a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IDs_SiaLP_6_nell_v1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027883e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model_SiaLP_6_nell_v1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50c64cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 14:29:50.195346: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "model = keras.models.load_model('../weight_bin/' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "378e34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the one-hop neighbor model\n",
    "model_2 = keras.models.load_model('../weight_bin/' + one_hop_model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ea521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_path = '../data/' + data_name + '_ind/train.txt'\n",
    "ind_valid_path = '../data/' + data_name + '_ind/valid.txt'\n",
    "ind_test_path = '../data/' + data_name + '_ind/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d2e6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test dataset\n",
    "one_hop_ind = dict() \n",
    "data_ind = set()\n",
    "s_t_r_ind = defaultdict(set)\n",
    "\n",
    "len_0 = len(relation2id)\n",
    "size_0 = len(entity2id)\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(ind_train_path, \n",
    "                        one_hop_ind, data_ind, s_t_r_ind,\n",
    "                        entity2id, id2entity, relation2id, id2relation)\n",
    "\n",
    "len_1 = len(relation2id)\n",
    "size_1 = len(entity2id)\n",
    "\n",
    "if len_0 != len_1:\n",
    "    raise ValueError('unseen relation!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a6dfe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3103 3328 833\n"
     ]
    }
   ],
   "source": [
    "print(size_0, size_1, len(data_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63cec98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test dataset\n",
    "one_hop_ind_test = dict() \n",
    "data_ind_test = set()\n",
    "s_t_r_ind_test = defaultdict(set)\n",
    "\n",
    "len_0 = len(relation2id)\n",
    "size_0 = len(entity2id)\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(ind_test_path, \n",
    "                        one_hop_ind_test, data_ind_test, s_t_r_ind_test,\n",
    "                        entity2id, id2entity, relation2id, id2relation)\n",
    "\n",
    "\n",
    "len_1 = len(relation2id)\n",
    "size_1 = len(entity2id)\n",
    "\n",
    "if len_0 != len_1:\n",
    "    raise ValueError('unseen relation!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d18fee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3328 3328 100\n"
     ]
    }
   ],
   "source": [
    "print(size_0, size_1, len(data_ind_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "757526ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the validation for existing triple removal when ranking\n",
    "one_hop_ind_valid = dict() \n",
    "data_ind_valid = set()\n",
    "s_t_r_ind_valid = defaultdict(set)\n",
    "\n",
    "len_0 = len(relation2id)\n",
    "size_0 = len(entity2id)\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(ind_valid_path, \n",
    "                        one_hop_ind_valid, data_ind_valid, s_t_r_ind_valid,\n",
    "                        entity2id, id2entity, relation2id, id2relation)\n",
    "\n",
    "len_1 = len(relation2id)\n",
    "size_1 = len(entity2id)\n",
    "\n",
    "if len_0 != len_1:\n",
    "    raise ValueError('unseen relation!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2980a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3328 3328 101\n"
     ]
    }
   ],
   "source": [
    "print(size_0, size_1, len(data_ind_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f17ff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3328 3103\n"
     ]
    }
   ],
   "source": [
    "print(len(entity2id), len(entity2id_ini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd1cda6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3103 225 3328\n"
     ]
    }
   ],
   "source": [
    "#obtain all the inital entities and new entities\n",
    "ini_ent_set, new_ent_set, all_ent_set = set(), set(), set()\n",
    "\n",
    "for ID in id2entity:\n",
    "    all_ent_set.add(ID)\n",
    "    if ID in id2entity_ini:\n",
    "        ini_ent_set.add(ID)\n",
    "    else:\n",
    "        new_ent_set.add(ID)\n",
    "        \n",
    "print(len(ini_ent_set), len(new_ent_set), len(all_ent_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "915ad29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to check whether there are overlapping \n",
    "#between the entities of train triples and inductive test and valid triples\n",
    "overlapping = 0\n",
    "\n",
    "for ele in data_ind_test:\n",
    "    \n",
    "    s, r, t = ele[0], ele[1], ele[2]\n",
    "    \n",
    "    if s in id2entity_ini or t in id2entity_ini:\n",
    "        \n",
    "        overlapping += 1\n",
    "        \n",
    "overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80eb1e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlapping = 0\n",
    "\n",
    "for ele in data_ind_valid:\n",
    "    \n",
    "    s, r, t = ele[0], ele[1], ele[2]\n",
    "    \n",
    "    if s in id2entity_ini or t in id2entity_ini:\n",
    "        \n",
    "        overlapping += 1\n",
    "        \n",
    "overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a3c9dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to check whether there are overlapping \n",
    "#between the entities of train triples and inductive test and valid triples\n",
    "overlapping = 0\n",
    "\n",
    "for ele in data_ind:\n",
    "    \n",
    "    s, r, t = ele[0], ele[1], ele[2]\n",
    "    \n",
    "    if s in id2entity_ini or t in id2entity_ini:\n",
    "        \n",
    "        overlapping += 1\n",
    "        \n",
    "overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83ea5533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function to do path-based relation scoring\n",
    "def path_based_relation_scoring(s, t, lower_bd, upper_bd, one_hop, id2relation, model):\n",
    "    \n",
    "    path_holder = set()\n",
    "    \n",
    "    for iteration in range(3):\n",
    "    \n",
    "        result, length_dict = Class_2.obtain_paths('target_specified', \n",
    "                                                   s, t, lower_bd, upper_bd, one_hop)\n",
    "        if t in result:\n",
    "            \n",
    "            for path in result[t]:\n",
    "                \n",
    "                path_holder.add(path)\n",
    "                \n",
    "        del(result, length_dict)\n",
    "    \n",
    "    path_holder = list(path_holder)\n",
    "    random.shuffle(path_holder)\n",
    "    \n",
    "    score_dict = defaultdict(float)\n",
    "    count_dict = defaultdict(int)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    if len(path_holder) >= 3:\n",
    "    \n",
    "        #iterate over path_1\n",
    "        while count < 10:\n",
    "\n",
    "            temp_pair = random.sample(path_holder, 3)\n",
    "\n",
    "            path_1, path_2, path_3 = temp_pair[0], temp_pair[1], temp_pair[2]\n",
    "\n",
    "            list_1 = list()\n",
    "            list_2 = list()\n",
    "            list_3 = list()\n",
    "            list_r = list()\n",
    "\n",
    "            for i in range(len(id2relation)):\n",
    "\n",
    "                if i not in id2relation:\n",
    "\n",
    "                    raise ValueError ('error when generating id2relation')\n",
    "                \n",
    "                #only care about initial relations\n",
    "                if i % 2 == 0:\n",
    "\n",
    "                    list_1.append(list(path_1) + [num_r]*abs(len(path_1)-upper_bd))\n",
    "                    list_2.append(list(path_2) + [num_r]*abs(len(path_2)-upper_bd))\n",
    "                    list_3.append(list(path_3) + [num_r]*abs(len(path_3)-upper_bd))\n",
    "                    list_r.append([i])\n",
    "            \n",
    "            #change to arrays\n",
    "            input_1 = np.array(list_1)\n",
    "            input_2 = np.array(list_2)\n",
    "            input_3 = np.array(list_3)\n",
    "            input_r = np.array(list_r)\n",
    "\n",
    "            pred = model.predict([input_1, input_2, input_3, input_r], verbose = 0)\n",
    "\n",
    "            for i in range(pred.shape[0]):\n",
    "                #need to times 2 to go back to relation id from pred position\n",
    "                score_dict[2*i] += float(pred[i])\n",
    "                count_dict[2*i] += 1\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "    #average the score\n",
    "    for r in score_dict:\n",
    "        score_dict[r] = deepcopy(score_dict[r]/float(count_dict[r]))\n",
    "    \n",
    "    print(len(score_dict), len(path_holder))\n",
    "\n",
    "    return(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1e1b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function to do path-based triple scoring: input one triple\n",
    "def path_based_triple_scoring(s, r, t, lower_bd, upper_bd, one_hop, id2relation, model):\n",
    "    \n",
    "    path_holder = set()\n",
    "    \n",
    "    for iteration in range(3):\n",
    "    \n",
    "        result, length_dict = Class_2.obtain_paths('target_specified', \n",
    "                                                   s, t, lower_bd, upper_bd, one_hop)\n",
    "        if t in result:\n",
    "            \n",
    "            for path in result[t]:\n",
    "                \n",
    "                path_holder.add(path)\n",
    "                \n",
    "        del(result, length_dict)\n",
    "    \n",
    "    path_holder = list(path_holder)\n",
    "    random.shuffle(path_holder)\n",
    "    \n",
    "    score = 0.\n",
    "    count = 0\n",
    "    \n",
    "    if len(path_holder) >= 3:\n",
    "        \n",
    "        list_1 = list()\n",
    "        list_2 = list()\n",
    "        list_3 = list()\n",
    "        list_r = list()\n",
    "    \n",
    "        #iterate over path_1\n",
    "        while count < 10:\n",
    "\n",
    "            temp_pair = random.sample(path_holder, 3)\n",
    "            path_1, path_2, path_3 = temp_pair[0], temp_pair[1], temp_pair[2]\n",
    "\n",
    "            list_1.append(list(path_1) + [num_r]*abs(len(path_1)-upper_bd))\n",
    "            list_2.append(list(path_2) + [num_r]*abs(len(path_2)-upper_bd))\n",
    "            list_3.append(list(path_3) + [num_r]*abs(len(path_3)-upper_bd))\n",
    "            list_r.append([r])\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "        #change to arrays\n",
    "        input_1 = np.array(list_1)\n",
    "        input_2 = np.array(list_2)\n",
    "        input_3 = np.array(list_3)\n",
    "        input_r = np.array(list_r)\n",
    "\n",
    "        pred = model.predict([input_1, input_2, input_3, input_r], verbose = 0)\n",
    "\n",
    "        for i in range(pred.shape[0]):\n",
    "            score += float(pred[i])\n",
    "            \n",
    "        #average the score\n",
    "        score = score/float(count)\n",
    "\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8512335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subgraph based relation scoring\n",
    "def subgraph_relation_scoring(s, t, lower_bd, upper_bd, one_hop, id2relation, model_2):\n",
    "    \n",
    "    path_s, path_t = set(), set() #sets holding all the paths from s or t\n",
    "    \n",
    "    for iteration in range(3):\n",
    "    \n",
    "        #obtain the paths out from s or t by \"any target\" mode. That is, \n",
    "        result_s, length_dict_s = Class_2.obtain_paths('any_target', s, 'any', lower_bd, upper_bd, one_hop)\n",
    "        result_t, length_dict_t = Class_2.obtain_paths('any_target', t, 'any', lower_bd, upper_bd, one_hop)\n",
    "\n",
    "        #add paths to the source/target path_set\n",
    "        for e in result_s:\n",
    "            for path in result_s[e]:\n",
    "                path_s.add(path)\n",
    "        for e in result_t:\n",
    "            for path in result_t[e]:\n",
    "                path_t.add(path)\n",
    "                \n",
    "        del(result_s, length_dict_s, result_t, length_dict_t)\n",
    "    \n",
    "    #final output: the score dict\n",
    "    score_dict = defaultdict(float)\n",
    "    count_dict = defaultdict(int)\n",
    "    \n",
    "    #see if both path_s and path_t have at least three paths\n",
    "    if len(path_s) >= 3 and len(path_t) >= 3:\n",
    "\n",
    "        #change to lists\n",
    "        path_s, path_t = list(path_s), list(path_t)\n",
    "        \n",
    "        count = 0\n",
    "        while count < 10:\n",
    "            \n",
    "            #lists holding the input to the network\n",
    "            list_s_1 = list()\n",
    "            list_s_2 = list()\n",
    "            list_s_3 = list()\n",
    "            list_t_1 = list()\n",
    "            list_t_2 = list()\n",
    "            list_t_3 = list()\n",
    "            list_r = list()\n",
    "\n",
    "            #randomly obtain three paths\n",
    "            temp_s = random.sample(path_s, 3)\n",
    "            temp_t = random.sample(path_t, 3)\n",
    "            s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "            t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "            \n",
    "            #add all forward (initial relation)\n",
    "            for i in range(len(id2relation)):\n",
    "\n",
    "                if i not in id2relation:\n",
    "\n",
    "                    raise ValueError ('error when generating id2relation')\n",
    "                    \n",
    "                if i % 2 == 0:\n",
    "\n",
    "                    #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                    list_s_1.append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                    list_s_2.append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                    list_s_3.append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "                    \n",
    "                    list_t_1.append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                    list_t_2.append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                    list_t_3.append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "                    \n",
    "                    list_r.append([i])\n",
    "                \n",
    "            #change to arrays\n",
    "            input_s_1 = np.array(list_s_1)\n",
    "            input_s_2 = np.array(list_s_2)\n",
    "            input_s_3 = np.array(list_s_3)\n",
    "            input_t_1 = np.array(list_t_1)\n",
    "            input_t_2 = np.array(list_t_2)\n",
    "            input_t_3 = np.array(list_t_3)\n",
    "            input_r = np.array(list_r)\n",
    "            \n",
    "            pred = model_2.predict([input_s_1, input_s_2, input_s_3,\n",
    "                                    input_t_1, input_t_2, input_t_3, input_r], verbose = 0)\n",
    "\n",
    "            for i in range(pred.shape[0]):\n",
    "                #need to times 2 to go back to relation id from pred position\n",
    "                score_dict[2*i] += float(pred[i])\n",
    "                count_dict[2*i] += 1\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "    #average the score\n",
    "    for r in score_dict:\n",
    "        score_dict[r] = deepcopy(score_dict[r]/float(count_dict[r]))\n",
    "            \n",
    "    print(len(score_dict), len(path_s), len(path_t))\n",
    "        \n",
    "    return(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26015662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subgraph based triple scoring\n",
    "def subgraph_triple_scoring(s, r, t, lower_bd, upper_bd, one_hop, id2relation, model_2):\n",
    "    \n",
    "    path_s, path_t = set(), set() #sets holding all the paths from s or t\n",
    "    \n",
    "    for iteration in range(3):\n",
    "    \n",
    "        #obtain the paths out from s or t by \"any target\" mode. That is, \n",
    "        result_s, length_dict_s = Class_2.obtain_paths('any_target', s, 'any', lower_bd, upper_bd, one_hop)\n",
    "        result_t, length_dict_t = Class_2.obtain_paths('any_target', t, 'any', lower_bd, upper_bd, one_hop)\n",
    "\n",
    "        #add paths to the source/target path_set\n",
    "        for e in result_s:\n",
    "            for path in result_s[e]:\n",
    "                path_s.add(path)\n",
    "        for e in result_t:\n",
    "            for path in result_t[e]:\n",
    "                path_t.add(path)\n",
    "                \n",
    "        del(result_s, length_dict_s, result_t, length_dict_t)\n",
    "    \n",
    "    #final output: the score dict\n",
    "    score = 0.\n",
    "    \n",
    "    #see if both path_s and path_t have at least three paths\n",
    "    if len(path_s) >= 3 and len(path_t) >= 3:\n",
    "\n",
    "        #change to lists\n",
    "        path_s, path_t = list(path_s), list(path_t)\n",
    "        \n",
    "        #lists holding the input to the network\n",
    "        list_s_1 = list()\n",
    "        list_s_2 = list()\n",
    "        list_s_3 = list()\n",
    "        list_t_1 = list()\n",
    "        list_t_2 = list()\n",
    "        list_t_3 = list()\n",
    "        list_r = list()\n",
    "        \n",
    "        count = 0\n",
    "        while count < 10:\n",
    "\n",
    "            #randomly obtain three paths\n",
    "            temp_s = random.sample(path_s, 3)\n",
    "            temp_t = random.sample(path_t, 3)\n",
    "            s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "            t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "\n",
    "            #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "            list_s_1.append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "            list_s_2.append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "            list_s_3.append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "            list_t_1.append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "            list_t_2.append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "            list_t_3.append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "            list_r.append([r])\n",
    "            count += 1\n",
    "                \n",
    "        #change to arrays\n",
    "        input_s_1 = np.array(list_s_1)\n",
    "        input_s_2 = np.array(list_s_2)\n",
    "        input_s_3 = np.array(list_s_3)\n",
    "        input_t_1 = np.array(list_t_1)\n",
    "        input_t_2 = np.array(list_t_2)\n",
    "        input_t_3 = np.array(list_t_3)\n",
    "        input_r = np.array(list_r)\n",
    "\n",
    "        pred = model_2.predict([input_s_1, input_s_2, input_s_3,\n",
    "                                input_t_1, input_t_2, input_t_3, input_r], verbose = 0)\n",
    "\n",
    "        for i in range(pred.shape[0]):\n",
    "            score += float(pred[i])\n",
    "\n",
    "        #average the score\n",
    "        score = score/float(count)\n",
    "        \n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b602d8d",
   "metadata": {},
   "source": [
    "#### Not fine tuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb84dd20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 12\n",
      "14 239 45\n",
      "checkcorrect 8 8 real score 0.778481868840754 Hits@1 1.0 Hits@3 1.0 Hits@10 1.0 MRR 1.0 cur_rank 0 abs_cur_rank 2 total_num 0 100\n",
      "14 14\n",
      "14 292 59\n",
      "checkcorrect 0 0 real score 1.083507376164198 Hits@1 1.0 Hits@3 1.0 Hits@10 1.0 MRR 1.0 cur_rank 0 abs_cur_rank 0 total_num 1 100\n",
      "14 10\n",
      "14 201 46\n",
      "checkcorrect 8 8 real score 0.6344845103099943 Hits@1 1.0 Hits@3 1.0 Hits@10 1.0 MRR 1.0 cur_rank 0 abs_cur_rank 2 total_num 2 100\n",
      "14 8\n",
      "14 51 185\n",
      "checkcorrect 18 18 real score 0.3995233681052923 Hits@1 0.75 Hits@3 1.0 Hits@10 1.0 MRR 0.8333333333333334 cur_rank 2 abs_cur_rank 2 total_num 3 100\n",
      "14 3\n",
      "14 165 56\n",
      "checkcorrect 12 12 real score 0.5447167612612247 Hits@1 0.8 Hits@3 1.0 Hits@10 1.0 MRR 0.8666666666666668 cur_rank 0 abs_cur_rank 2 total_num 4 100\n",
      "14 13\n",
      "14 313 51\n",
      "checkcorrect 0 0 real score 0.875854199565947 Hits@1 0.8333333333333334 Hits@3 1.0 Hits@10 1.0 MRR 0.888888888888889 cur_rank 0 abs_cur_rank 1 total_num 5 100\n",
      "14 8\n",
      "14 55 283\n",
      "checkcorrect 6 6 real score 1.6857486993074418 Hits@1 0.8571428571428571 Hits@3 1.0 Hits@10 1.0 MRR 0.9047619047619049 cur_rank 0 abs_cur_rank 0 total_num 6 100\n",
      "0 1\n",
      "14 50 45\n",
      "checkcorrect 8 8 real score 0.42334859669208524 Hits@1 0.875 Hits@3 1.0 Hits@10 1.0 MRR 0.9166666666666667 cur_rank 0 abs_cur_rank 2 total_num 7 100\n",
      "14 3\n",
      "14 141 50\n",
      "checkcorrect 0 0 real score 0.8695382133126259 Hits@1 0.8888888888888888 Hits@3 1.0 Hits@10 1.0 MRR 0.925925925925926 cur_rank 0 abs_cur_rank 2 total_num 8 100\n",
      "14 9\n",
      "14 51 204\n",
      "checkcorrect 6 6 real score 1.389312944561243 Hits@1 0.9 Hits@3 1.0 Hits@10 1.0 MRR 0.9333333333333333 cur_rank 0 abs_cur_rank 0 total_num 9 100\n",
      "14 12\n",
      "14 302 49\n",
      "checkcorrect 8 8 real score 0.6810784306377173 Hits@1 0.9090909090909091 Hits@3 1.0 Hits@10 1.0 MRR 0.9393939393939394 cur_rank 0 abs_cur_rank 2 total_num 10 100\n",
      "14 27\n",
      "14 166 157\n",
      "checkcorrect 10 10 real score 1.2619249820709229 Hits@1 0.8333333333333334 Hits@3 1.0 Hits@10 1.0 MRR 0.9027777777777778 cur_rank 1 abs_cur_rank 1 total_num 11 100\n",
      "0 1\n",
      "14 49 168\n",
      "checkcorrect 6 6 real score 0.5780126191675663 Hits@1 0.8461538461538461 Hits@3 1.0 Hits@10 1.0 MRR 0.9102564102564104 cur_rank 0 abs_cur_rank 0 total_num 12 100\n",
      "14 15\n",
      "14 271 46\n",
      "checkcorrect 12 12 real score 0.4399742010049522 Hits@1 0.8571428571428571 Hits@3 1.0 Hits@10 1.0 MRR 0.9166666666666667 cur_rank 0 abs_cur_rank 2 total_num 13 100\n",
      "14 14\n",
      "14 276 45\n",
      "checkcorrect 8 8 real score 0.7201443901518361 Hits@1 0.8666666666666667 Hits@3 1.0 Hits@10 1.0 MRR 0.9222222222222223 cur_rank 0 abs_cur_rank 1 total_num 14 100\n",
      "14 15\n",
      "14 298 54\n",
      "checkcorrect 8 8 real score 0.490324376616627 Hits@1 0.875 Hits@3 1.0 Hits@10 1.0 MRR 0.9270833333333334 cur_rank 0 abs_cur_rank 2 total_num 15 100\n",
      "14 11\n",
      "14 253 53\n",
      "checkcorrect 12 12 real score 0.49987114486284556 Hits@1 0.8823529411764706 Hits@3 1.0 Hits@10 1.0 MRR 0.9313725490196079 cur_rank 0 abs_cur_rank 2 total_num 16 100\n",
      "14 14\n",
      "14 247 57\n",
      "checkcorrect 8 8 real score 0.5582063581794501 Hits@1 0.8888888888888888 Hits@3 1.0 Hits@10 1.0 MRR 0.9351851851851853 cur_rank 0 abs_cur_rank 2 total_num 17 100\n",
      "14 14\n",
      "14 290 46\n",
      "checkcorrect 12 12 real score 0.45355913788080215 Hits@1 0.8947368421052632 Hits@3 1.0 Hits@10 1.0 MRR 0.9385964912280703 cur_rank 0 abs_cur_rank 2 total_num 18 100\n",
      "14 12\n",
      "14 285 49\n",
      "checkcorrect 8 8 real score 0.6132257230579853 Hits@1 0.9 Hits@3 1.0 Hits@10 1.0 MRR 0.9416666666666668 cur_rank 0 abs_cur_rank 1 total_num 19 100\n",
      "0 1\n",
      "14 58 56\n",
      "checkcorrect 0 0 real score 0.5157317101955414 Hits@1 0.9047619047619048 Hits@3 1.0 Hits@10 1.0 MRR 0.9444444444444445 cur_rank 0 abs_cur_rank 1 total_num 20 100\n",
      "0 2\n",
      "14 111 45\n",
      "checkcorrect 12 12 real score 0.29455982744693754 Hits@1 0.9090909090909091 Hits@3 1.0 Hits@10 1.0 MRR 0.9469696969696971 cur_rank 0 abs_cur_rank 2 total_num 21 100\n",
      "14 13\n",
      "14 248 59\n",
      "checkcorrect 8 8 real score 0.3706898493226618 Hits@1 0.9130434782608695 Hits@3 1.0 Hits@10 1.0 MRR 0.9492753623188407 cur_rank 0 abs_cur_rank 2 total_num 22 100\n",
      "14 12\n",
      "14 282 52\n",
      "checkcorrect 0 0 real score 1.1290554251521825 Hits@1 0.9166666666666666 Hits@3 1.0 Hits@10 1.0 MRR 0.951388888888889 cur_rank 0 abs_cur_rank 0 total_num 23 100\n",
      "0 1\n",
      "14 57 100\n",
      "checkcorrect 6 6 real score 0.3366772413253784 Hits@1 0.92 Hits@3 1.0 Hits@10 1.0 MRR 0.9533333333333335 cur_rank 0 abs_cur_rank 0 total_num 24 100\n",
      "0 2\n",
      "14 98 46\n",
      "checkcorrect 12 12 real score 0.3494236275553703 Hits@1 0.9230769230769231 Hits@3 1.0 Hits@10 1.0 MRR 0.9551282051282052 cur_rank 0 abs_cur_rank 1 total_num 25 100\n",
      "14 9\n",
      "14 55 313\n",
      "checkcorrect 6 6 real score 1.5644555717706679 Hits@1 0.9259259259259259 Hits@3 1.0 Hits@10 1.0 MRR 0.9567901234567903 cur_rank 0 abs_cur_rank 0 total_num 26 100\n",
      "14 14\n",
      "14 240 53\n",
      "checkcorrect 12 12 real score 0.46987092271447184 Hits@1 0.9285714285714286 Hits@3 1.0 Hits@10 1.0 MRR 0.9583333333333334 cur_rank 0 abs_cur_rank 1 total_num 27 100\n",
      "14 11\n",
      "14 243 50\n",
      "checkcorrect 12 12 real score 0.5026389330625534 Hits@1 0.9310344827586207 Hits@3 1.0 Hits@10 1.0 MRR 0.9597701149425288 cur_rank 0 abs_cur_rank 2 total_num 28 100\n",
      "0 2\n",
      "14 101 50\n",
      "checkcorrect 8 8 real score 0.43848841078579426 Hits@1 0.9 Hits@3 1.0 Hits@10 1.0 MRR 0.9444444444444445 cur_rank 1 abs_cur_rank 2 total_num 29 100\n",
      "0 2\n",
      "14 116 53\n",
      "checkcorrect 8 8 real score 0.37930671200156213 Hits@1 0.9032258064516129 Hits@3 1.0 Hits@10 1.0 MRR 0.946236559139785 cur_rank 0 abs_cur_rank 2 total_num 30 100\n",
      "14 8\n",
      "14 50 167\n",
      "checkcorrect 6 6 real score 1.5600352169247345 Hits@1 0.90625 Hits@3 1.0 Hits@10 1.0 MRR 0.9479166666666667 cur_rank 0 abs_cur_rank 0 total_num 31 100\n",
      "0 0\n",
      "14 53 104\n",
      "checkcorrect 6 6 real score 0.5549055069684983 Hits@1 0.9090909090909091 Hits@3 1.0 Hits@10 1.0 MRR 0.9494949494949496 cur_rank 0 abs_cur_rank 0 total_num 32 100\n",
      "14 14\n",
      "14 241 55\n",
      "checkcorrect 12 12 real score 0.44945682771503925 Hits@1 0.8823529411764706 Hits@3 1.0 Hits@10 1.0 MRR 0.9362745098039217 cur_rank 1 abs_cur_rank 3 total_num 33 100\n",
      "14 3\n",
      "14 150 52\n",
      "checkcorrect 0 0 real score 0.8252041675150394 Hits@1 0.8857142857142857 Hits@3 1.0 Hits@10 1.0 MRR 0.9380952380952382 cur_rank 0 abs_cur_rank 2 total_num 34 100\n",
      "14 13\n",
      "14 260 55\n",
      "checkcorrect 8 8 real score 0.4306941837072372 Hits@1 0.8888888888888888 Hits@3 1.0 Hits@10 1.0 MRR 0.9398148148148149 cur_rank 0 abs_cur_rank 2 total_num 35 100\n",
      "14 11\n",
      "14 272 46\n",
      "checkcorrect 12 12 real score 0.47396955266594887 Hits@1 0.8918918918918919 Hits@3 1.0 Hits@10 1.0 MRR 0.9414414414414415 cur_rank 0 abs_cur_rank 2 total_num 36 100\n",
      "14 3\n",
      "14 161 52\n",
      "checkcorrect 12 12 real score 0.553642475605011 Hits@1 0.8947368421052632 Hits@3 1.0 Hits@10 1.0 MRR 0.9429824561403509 cur_rank 0 abs_cur_rank 2 total_num 37 100\n",
      "14 13\n",
      "14 265 52\n",
      "checkcorrect 8 8 real score 0.5192031804472208 Hits@1 0.8974358974358975 Hits@3 1.0 Hits@10 1.0 MRR 0.9444444444444445 cur_rank 0 abs_cur_rank 2 total_num 38 100\n",
      "14 9\n",
      "14 44 292\n",
      "checkcorrect 6 6 real score 1.41061439961195 Hits@1 0.9 Hits@3 1.0 Hits@10 1.0 MRR 0.9458333333333334 cur_rank 0 abs_cur_rank 0 total_num 39 100\n",
      "14 12\n",
      "14 277 49\n",
      "checkcorrect 8 8 real score 0.32546955607831474 Hits@1 0.9024390243902439 Hits@3 1.0 Hits@10 1.0 MRR 0.9471544715447155 cur_rank 0 abs_cur_rank 2 total_num 40 100\n",
      "14 34\n",
      "14 206 138\n",
      "checkcorrect 10 10 real score 1.3375608682632447 Hits@1 0.8809523809523809 Hits@3 1.0 Hits@10 1.0 MRR 0.9365079365079365 cur_rank 1 abs_cur_rank 1 total_num 41 100\n",
      "14 14\n",
      "14 301 58\n",
      "checkcorrect 0 0 real score 0.8934346219524741 Hits@1 0.8837209302325582 Hits@3 1.0 Hits@10 1.0 MRR 0.937984496124031 cur_rank 0 abs_cur_rank 1 total_num 42 100\n",
      "14 12\n",
      "14 293 56\n",
      "checkcorrect 8 8 real score 0.5575069110840559 Hits@1 0.8863636363636364 Hits@3 1.0 Hits@10 1.0 MRR 0.9393939393939394 cur_rank 0 abs_cur_rank 2 total_num 43 100\n",
      "14 41\n",
      "14 219 143\n",
      "checkcorrect 16 16 real score 1.3208416879177094 Hits@1 0.8888888888888888 Hits@3 1.0 Hits@10 1.0 MRR 0.9407407407407408 cur_rank 0 abs_cur_rank 0 total_num 44 100\n",
      "14 9\n",
      "14 66 238\n",
      "checkcorrect 6 6 real score 1.6041727256029845 Hits@1 0.8913043478260869 Hits@3 1.0 Hits@10 1.0 MRR 0.9420289855072465 cur_rank 0 abs_cur_rank 0 total_num 45 100\n",
      "14 13\n",
      "14 244 55\n",
      "checkcorrect 12 12 real score 0.2780287641566247 Hits@1 0.8936170212765957 Hits@3 1.0 Hits@10 1.0 MRR 0.9432624113475178 cur_rank 0 abs_cur_rank 2 total_num 46 100\n",
      "14 12\n",
      "14 255 52\n",
      "checkcorrect 8 8 real score 0.4300347055192105 Hits@1 0.8958333333333334 Hits@3 1.0 Hits@10 1.0 MRR 0.9444444444444445 cur_rank 0 abs_cur_rank 1 total_num 47 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 13\n",
      "14 304 51\n",
      "checkcorrect 12 12 real score 0.4499542944133282 Hits@1 0.8979591836734694 Hits@3 1.0 Hits@10 1.0 MRR 0.9455782312925171 cur_rank 0 abs_cur_rank 2 total_num 48 100\n",
      "14 36\n",
      "14 224 166\n",
      "checkcorrect 16 16 real score 1.3714989989995956 Hits@1 0.9 Hits@3 1.0 Hits@10 1.0 MRR 0.9466666666666668 cur_rank 0 abs_cur_rank 0 total_num 49 100\n",
      "14 27\n",
      "14 154 155\n",
      "checkcorrect 10 10 real score 1.2544062793254853 Hits@1 0.8823529411764706 Hits@3 1.0 Hits@10 1.0 MRR 0.9379084967320261 cur_rank 1 abs_cur_rank 1 total_num 50 100\n",
      "14 11\n",
      "14 205 51\n",
      "checkcorrect 0 0 real score 0.9072980418801309 Hits@1 0.8846153846153846 Hits@3 1.0 Hits@10 1.0 MRR 0.9391025641025641 cur_rank 0 abs_cur_rank 0 total_num 51 100\n",
      "14 9\n",
      "14 51 290\n",
      "checkcorrect 6 6 real score 1.4740194402635098 Hits@1 0.8867924528301887 Hits@3 1.0 Hits@10 1.0 MRR 0.940251572327044 cur_rank 0 abs_cur_rank 0 total_num 52 100\n",
      "0 1\n",
      "14 47 48\n",
      "checkcorrect 8 8 real score 0.33845696300268174 Hits@1 0.8888888888888888 Hits@3 1.0 Hits@10 1.0 MRR 0.9413580246913581 cur_rank 0 abs_cur_rank 2 total_num 53 100\n",
      "14 3\n",
      "14 147 55\n",
      "checkcorrect 0 0 real score 0.9966732919216156 Hits@1 0.8909090909090909 Hits@3 1.0 Hits@10 1.0 MRR 0.9424242424242425 cur_rank 0 abs_cur_rank 1 total_num 54 100\n",
      "14 9\n",
      "14 59 230\n",
      "checkcorrect 6 6 real score 1.3886837087571622 Hits@1 0.8928571428571429 Hits@3 1.0 Hits@10 1.0 MRR 0.943452380952381 cur_rank 0 abs_cur_rank 0 total_num 55 100\n",
      "14 14\n",
      "14 295 45\n",
      "checkcorrect 8 8 real score 0.6847417287528514 Hits@1 0.8947368421052632 Hits@3 1.0 Hits@10 1.0 MRR 0.9444444444444445 cur_rank 0 abs_cur_rank 2 total_num 56 100\n",
      "14 3\n",
      "14 148 47\n",
      "checkcorrect 0 0 real score 0.9952307343482971 Hits@1 0.896551724137931 Hits@3 1.0 Hits@10 1.0 MRR 0.9454022988505748 cur_rank 0 abs_cur_rank 2 total_num 57 100\n",
      "14 13\n",
      "14 253 55\n",
      "checkcorrect 8 8 real score 0.5359200476435944 Hits@1 0.8983050847457628 Hits@3 1.0 Hits@10 1.0 MRR 0.9463276836158192 cur_rank 0 abs_cur_rank 1 total_num 58 100\n",
      "14 26\n",
      "14 163 136\n",
      "checkcorrect 16 16 real score 1.4292639076709746 Hits@1 0.9 Hits@3 1.0 Hits@10 1.0 MRR 0.9472222222222223 cur_rank 0 abs_cur_rank 0 total_num 59 100\n",
      "14 3\n",
      "14 153 46\n",
      "checkcorrect 8 8 real score 0.40232722237706187 Hits@1 0.9016393442622951 Hits@3 1.0 Hits@10 1.0 MRR 0.9480874316939891 cur_rank 0 abs_cur_rank 2 total_num 60 100\n",
      "14 9\n",
      "14 46 234\n",
      "checkcorrect 6 6 real score 1.6373847752809525 Hits@1 0.9032258064516129 Hits@3 1.0 Hits@10 1.0 MRR 0.9489247311827957 cur_rank 0 abs_cur_rank 0 total_num 61 100\n",
      "14 37\n",
      "14 205 146\n",
      "checkcorrect 16 16 real score 1.4974795266985894 Hits@1 0.9047619047619048 Hits@3 1.0 Hits@10 1.0 MRR 0.9497354497354498 cur_rank 0 abs_cur_rank 0 total_num 62 100\n",
      "14 11\n",
      "14 253 43\n",
      "checkcorrect 12 12 real score 0.4215222805738449 Hits@1 0.90625 Hits@3 1.0 Hits@10 1.0 MRR 0.9505208333333334 cur_rank 0 abs_cur_rank 2 total_num 63 100\n",
      "14 26\n",
      "14 145 161\n",
      "checkcorrect 16 16 real score 1.5271727696061133 Hits@1 0.9076923076923077 Hits@3 1.0 Hits@10 1.0 MRR 0.9512820512820513 cur_rank 0 abs_cur_rank 0 total_num 64 100\n",
      "14 12\n",
      "14 291 55\n",
      "checkcorrect 12 12 real score 0.4838739581406117 Hits@1 0.8939393939393939 Hits@3 1.0 Hits@10 1.0 MRR 0.9444444444444445 cur_rank 1 abs_cur_rank 3 total_num 65 100\n",
      "0 2\n",
      "14 108 46\n",
      "checkcorrect 12 12 real score 0.2844591874629259 Hits@1 0.8955223880597015 Hits@3 1.0 Hits@10 1.0 MRR 0.945273631840796 cur_rank 0 abs_cur_rank 2 total_num 66 100\n",
      "14 10\n",
      "14 56 144\n",
      "checkcorrect 16 16 real score 1.0390331637114287 Hits@1 0.8823529411764706 Hits@3 1.0 Hits@10 1.0 MRR 0.9387254901960784 cur_rank 1 abs_cur_rank 1 total_num 67 100\n",
      "14 10\n",
      "14 56 240\n",
      "checkcorrect 6 6 real score 1.4901263006031513 Hits@1 0.8840579710144928 Hits@3 1.0 Hits@10 1.0 MRR 0.9396135265700485 cur_rank 0 abs_cur_rank 0 total_num 68 100\n",
      "14 10\n",
      "14 228 45\n",
      "checkcorrect 0 0 real score 1.157877797074616 Hits@1 0.8857142857142857 Hits@3 1.0 Hits@10 1.0 MRR 0.9404761904761906 cur_rank 0 abs_cur_rank 0 total_num 69 100\n",
      "14 35\n",
      "14 199 146\n",
      "checkcorrect 16 16 real score 1.4145691126585007 Hits@1 0.8873239436619719 Hits@3 1.0 Hits@10 1.0 MRR 0.9413145539906105 cur_rank 0 abs_cur_rank 0 total_num 70 100\n",
      "14 20\n",
      "14 102 172\n",
      "checkcorrect 16 16 real score 1.3565028429031372 Hits@1 0.875 Hits@3 1.0 Hits@10 1.0 MRR 0.9351851851851853 cur_rank 1 abs_cur_rank 1 total_num 71 100\n",
      "14 11\n",
      "14 295 52\n",
      "checkcorrect 8 8 real score 0.48084482178092003 Hits@1 0.8767123287671232 Hits@3 1.0 Hits@10 1.0 MRR 0.9360730593607307 cur_rank 0 abs_cur_rank 2 total_num 72 100\n",
      "14 9\n",
      "14 49 291\n",
      "checkcorrect 6 6 real score 1.5511279821395876 Hits@1 0.8783783783783784 Hits@3 1.0 Hits@10 1.0 MRR 0.936936936936937 cur_rank 0 abs_cur_rank 0 total_num 73 100\n",
      "14 11\n",
      "14 298 50\n",
      "checkcorrect 12 12 real score 0.3304556544870138 Hits@1 0.88 Hits@3 1.0 Hits@10 1.0 MRR 0.9377777777777779 cur_rank 0 abs_cur_rank 2 total_num 74 100\n",
      "14 13\n",
      "14 301 47\n",
      "checkcorrect 12 12 real score 0.5220068097114563 Hits@1 0.881578947368421 Hits@3 1.0 Hits@10 1.0 MRR 0.9385964912280703 cur_rank 0 abs_cur_rank 2 total_num 75 100\n",
      "14 27\n",
      "14 159 164\n",
      "checkcorrect 16 16 real score 1.28884207457304 Hits@1 0.8831168831168831 Hits@3 1.0 Hits@10 1.0 MRR 0.9393939393939396 cur_rank 0 abs_cur_rank 0 total_num 76 100\n",
      "14 35\n",
      "14 208 172\n",
      "checkcorrect 16 16 real score 1.365588013827801 Hits@1 0.8846153846153846 Hits@3 1.0 Hits@10 1.0 MRR 0.9401709401709403 cur_rank 0 abs_cur_rank 0 total_num 77 100\n",
      "0 1\n",
      "14 51 55\n",
      "checkcorrect 8 8 real score 0.39142629206180574 Hits@1 0.8860759493670886 Hits@3 1.0 Hits@10 1.0 MRR 0.9409282700421943 cur_rank 0 abs_cur_rank 2 total_num 78 100\n",
      "14 30\n",
      "14 159 165\n",
      "checkcorrect 10 10 real score 1.310534265637398 Hits@1 0.8875 Hits@3 1.0 Hits@10 1.0 MRR 0.9416666666666668 cur_rank 0 abs_cur_rank 0 total_num 79 100\n",
      "14 8\n",
      "14 56 285\n",
      "checkcorrect 6 6 real score 1.6072440445423126 Hits@1 0.8888888888888888 Hits@3 1.0 Hits@10 1.0 MRR 0.9423868312757203 cur_rank 0 abs_cur_rank 0 total_num 80 100\n",
      "14 13\n",
      "14 249 45\n",
      "checkcorrect 0 0 real score 1.2648759543895722 Hits@1 0.8902439024390244 Hits@3 1.0 Hits@10 1.0 MRR 0.9430894308943091 cur_rank 0 abs_cur_rank 0 total_num 81 100\n",
      "14 14\n",
      "14 246 45\n",
      "checkcorrect 8 8 real score 0.495559602836147 Hits@1 0.891566265060241 Hits@3 1.0 Hits@10 1.0 MRR 0.9437751004016065 cur_rank 0 abs_cur_rank 2 total_num 82 100\n",
      "14 36\n",
      "14 192 144\n",
      "checkcorrect 10 10 real score 1.2879866063594818 Hits@1 0.8928571428571429 Hits@3 1.0 Hits@10 1.0 MRR 0.9444444444444445 cur_rank 0 abs_cur_rank 0 total_num 83 100\n",
      "14 13\n",
      "14 248 46\n",
      "checkcorrect 0 0 real score 1.1669452212750913 Hits@1 0.8941176470588236 Hits@3 1.0 Hits@10 1.0 MRR 0.9450980392156864 cur_rank 0 abs_cur_rank 0 total_num 84 100\n",
      "14 9\n",
      "14 52 278\n",
      "checkcorrect 6 6 real score 1.530609495192766 Hits@1 0.8953488372093024 Hits@3 1.0 Hits@10 1.0 MRR 0.9457364341085273 cur_rank 0 abs_cur_rank 0 total_num 85 100\n",
      "14 14\n",
      "14 297 48\n",
      "checkcorrect 8 8 real score 0.6328342471271753 Hits@1 0.896551724137931 Hits@3 1.0 Hits@10 1.0 MRR 0.9463601532567051 cur_rank 0 abs_cur_rank 1 total_num 86 100\n",
      "0 1\n",
      "14 53 152\n",
      "checkcorrect 6 6 real score 0.6637728780508041 Hits@1 0.8977272727272727 Hits@3 1.0 Hits@10 1.0 MRR 0.9469696969696971 cur_rank 0 abs_cur_rank 0 total_num 87 100\n",
      "14 9\n",
      "14 58 295\n",
      "checkcorrect 6 6 real score 1.4830925423651933 Hits@1 0.898876404494382 Hits@3 1.0 Hits@10 1.0 MRR 0.9475655430711611 cur_rank 0 abs_cur_rank 0 total_num 88 100\n",
      "14 15\n",
      "14 285 51\n",
      "checkcorrect 12 12 real score 0.571351614035666 Hits@1 0.8888888888888888 Hits@3 1.0 Hits@10 1.0 MRR 0.9425925925925926 cur_rank 1 abs_cur_rank 3 total_num 89 100\n",
      "0 2\n",
      "14 105 55\n",
      "checkcorrect 12 12 real score 0.25468230694532396 Hits@1 0.8901098901098901 Hits@3 1.0 Hits@10 1.0 MRR 0.9432234432234433 cur_rank 0 abs_cur_rank 2 total_num 90 100\n",
      "14 14\n",
      "14 304 52\n",
      "checkcorrect 12 12 real score 0.5413753010332585 Hits@1 0.8913043478260869 Hits@3 1.0 Hits@10 1.0 MRR 0.943840579710145 cur_rank 0 abs_cur_rank 2 total_num 91 100\n",
      "14 17\n",
      "14 101 159\n",
      "checkcorrect 10 10 real score 1.1478514403104783 Hits@1 0.8817204301075269 Hits@3 1.0 Hits@10 1.0 MRR 0.939068100358423 cur_rank 1 abs_cur_rank 1 total_num 92 100\n",
      "14 13\n",
      "14 282 46\n",
      "checkcorrect 12 12 real score 0.47535680793225765 Hits@1 0.8829787234042553 Hits@3 1.0 Hits@10 1.0 MRR 0.9397163120567377 cur_rank 0 abs_cur_rank 2 total_num 93 100\n",
      "0 1\n",
      "14 56 49\n",
      "checkcorrect 0 0 real score 0.4838526099920273 Hits@1 0.8842105263157894 Hits@3 1.0 Hits@10 1.0 MRR 0.9403508771929826 cur_rank 0 abs_cur_rank 1 total_num 94 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 9\n",
      "14 53 295\n",
      "checkcorrect 6 6 real score 1.2689859211444854 Hits@1 0.8854166666666666 Hits@3 1.0 Hits@10 1.0 MRR 0.9409722222222223 cur_rank 0 abs_cur_rank 0 total_num 95 100\n",
      "14 3\n",
      "14 148 47\n",
      "checkcorrect 8 8 real score 0.4203361073508859 Hits@1 0.8865979381443299 Hits@3 1.0 Hits@10 1.0 MRR 0.9415807560137458 cur_rank 0 abs_cur_rank 2 total_num 96 100\n",
      "14 36\n",
      "14 203 154\n",
      "checkcorrect 16 16 real score 1.3217142328619955 Hits@1 0.8877551020408163 Hits@3 1.0 Hits@10 1.0 MRR 0.9421768707482994 cur_rank 0 abs_cur_rank 0 total_num 97 100\n",
      "0 2\n",
      "14 113 54\n",
      "checkcorrect 0 0 real score 0.1886755634099245 Hits@1 0.8888888888888888 Hits@3 1.0 Hits@10 1.0 MRR 0.9427609427609429 cur_rank 0 abs_cur_rank 1 total_num 98 100\n",
      "14 8\n",
      "14 46 152\n",
      "checkcorrect 16 16 real score 1.5401622503995895 Hits@1 0.89 Hits@3 1.0 Hits@10 1.0 MRR 0.9433333333333335 cur_rank 0 abs_cur_rank 0 total_num 99 100\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "#obtain the Hits@N for relation prediction##############\n",
    "\n",
    "#we select all the triples in the inductive test set\n",
    "selected = list(data_ind_test)\n",
    "\n",
    "###Hit at 1#############################\n",
    "#generate the negative samples by randomly replace relation with all the other relaiton\n",
    "Hits_at_1 = 0\n",
    "Hits_at_3 = 0\n",
    "Hits_at_10 = 0\n",
    "MRR_raw = 0.\n",
    "\n",
    "for i in range(len(selected)):\n",
    "    \n",
    "    s_true, r_true, t_true = selected[i][0], selected[i][1], selected[i][2]\n",
    "    \n",
    "    #run the path-based scoring\n",
    "    score_dict_path = path_based_relation_scoring(s_true, t_true, 1, 10, one_hop_ind, id2relation, model)\n",
    "    \n",
    "    #run the one-hop neighbour based scoring\n",
    "    score_dict_subg = subgraph_relation_scoring(s_true, t_true, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "    \n",
    "    #final score dict\n",
    "    score_dict = defaultdict(float)\n",
    "    \n",
    "    for r in score_dict_path:\n",
    "        score_dict[r] += score_dict_path[r]\n",
    "    for r in score_dict_subg:\n",
    "        score_dict[r] += score_dict_subg[r]\n",
    "    \n",
    "    #[... [score, r], ...]\n",
    "    temp_list = list()\n",
    "    \n",
    "    for r in id2relation:\n",
    "        \n",
    "        #again, we only care about initial relation prediciton\n",
    "        if r % 2 == 0:\n",
    "        \n",
    "            if r in score_dict:\n",
    "\n",
    "                temp_list.append([score_dict[r], r])\n",
    "\n",
    "            else:\n",
    "\n",
    "                temp_list.append([0.0, r])\n",
    "        \n",
    "    sorted_list = sorted(temp_list, key = lambda x: x[0], reverse=True)\n",
    "    \n",
    "    p = 0\n",
    "    exist_tri = 0\n",
    "    \n",
    "    while p < len(sorted_list) and sorted_list[p][1] != r_true:\n",
    "        \n",
    "        #moreover, we want to remove existing triples\n",
    "        if ((s_true, sorted_list[p][1], t_true) in data_test) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data_valid) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data_ind) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data_ind_valid) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data_ind_test):\n",
    "            \n",
    "            exist_tri += 1\n",
    "            \n",
    "        p += 1\n",
    "    \n",
    "    if p - exist_tri == 0:\n",
    "        \n",
    "        Hits_at_1 += 1\n",
    "        \n",
    "    if p - exist_tri < 3:\n",
    "        \n",
    "        Hits_at_3 += 1\n",
    "        \n",
    "    if p - exist_tri < 10:\n",
    "        \n",
    "        Hits_at_10 += 1\n",
    "        \n",
    "    MRR_raw += 1./float(p - exist_tri + 1.) \n",
    "        \n",
    "    print('checkcorrect', r_true, sorted_list[p][1],\n",
    "          'real score', sorted_list[p][0],\n",
    "          'Hits@1', Hits_at_1/(i+1),\n",
    "          'Hits@3', Hits_at_3/(i+1),\n",
    "          'Hits@10', Hits_at_10/(i+1),\n",
    "          'MRR', MRR_raw/(i+1),\n",
    "          'cur_rank', p - exist_tri,\n",
    "          'abs_cur_rank', p,\n",
    "          'total_num', i, len(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1f0b73c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating scores 20 200\n",
      "AUC-PR is: 0.6392518939393939\n",
      "evaluating scores 40 200\n",
      "AUC-PR is: 0.7024665607216254\n",
      "evaluating scores 60 200\n",
      "AUC-PR is: 0.6621802486927588\n",
      "evaluating scores 80 200\n",
      "AUC-PR is: 0.6793962327758866\n",
      "evaluating scores 100 200\n",
      "AUC-PR is: 0.6465067968869497\n",
      "evaluating scores 120 200\n",
      "AUC-PR is: 0.6363682542250972\n",
      "evaluating scores 140 200\n",
      "AUC-PR is: 0.658451759444874\n",
      "evaluating scores 160 200\n",
      "AUC-PR is: 0.6585528464849241\n",
      "evaluating scores 180 200\n",
      "AUC-PR is: 0.6467834883496786\n",
      "AUC-PR is: 0.6434534135977351\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "##obtain the AUC-PR for the test triples###\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#we select all the triples in the inductive test set\n",
    "pos_triples = list(data_ind_test)\n",
    "\n",
    "#we build the negative samples by randomly replace head or tail entity in the triple.\n",
    "neg_triples = list()\n",
    "\n",
    "for i in range(len(pos_triples)):\n",
    "    \n",
    "    s_pos, r_pos, t_pos = pos_triples[i][0], pos_triples[i][1], pos_triples[i][2]\n",
    "    \n",
    "    #decide to replace the head or tail entity\n",
    "    number_0 = random.uniform(0, 1)\n",
    "    \n",
    "    if number_0 < 0.5: #replace head entity\n",
    "        s_neg = random.choice(list(new_ent_set))\n",
    "        neg_triples.append((s_neg, r_pos, t_pos))\n",
    "    else: #replace tail entity\n",
    "        t_neg = random.choice(list(new_ent_set))\n",
    "        neg_triples.append((s_pos, r_pos, t_neg))\n",
    "\n",
    "if len(pos_triples) != len(neg_triples):\n",
    "    raise ValueError('error when generating negative triples')\n",
    "        \n",
    "#combine all triples\n",
    "all_triples = pos_triples + neg_triples\n",
    "\n",
    "#obtain the label array\n",
    "arr1 = np.ones((len(pos_triples),))\n",
    "arr2 = np.zeros((len(neg_triples),))\n",
    "y_test = np.concatenate((arr1, arr2))\n",
    "\n",
    "#shuffle positive and negative triples (optional)\n",
    "all_triples, y_test = shuffle(all_triples, y_test)\n",
    "\n",
    "#obtain the score aray\n",
    "y_score = np.zeros((len(y_test),))\n",
    "\n",
    "#implement the scoring\n",
    "for i in range(len(all_triples)):\n",
    "    \n",
    "    s, r, t = all_triples[i][0], all_triples[i][1], all_triples[i][2]\n",
    "    \n",
    "    #path_score = path_based_triple_scoring(s, r, t, 1, 10, one_hop_ind, id2relation, model)\n",
    "    \n",
    "    subg_score = subgraph_triple_scoring(s, r, t, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "    \n",
    "    #ave_score = (path_score + subg_score)/float(2)\n",
    "    \n",
    "    #y_score[i] = ave_score\n",
    "    y_score[i] = subg_score\n",
    "    \n",
    "    if i % 20 == 0 and i > 0:\n",
    "        print('evaluating scores', i, len(all_triples))\n",
    "        \n",
    "        # Data to plot precision - recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test[:i], y_score[:i])\n",
    "        # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "        auc_precision_recall = auc(recall, precision)\n",
    "        print('AUC-PR is:', auc_precision_recall)\n",
    "        \n",
    "        \n",
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print('AUC-PR is:', auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6403a2e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkcorrect (3250, 8, 3104) (3250, 8, 3104) real score 0.2920574526069686 Hits@1 0.0 Hits@3 0.0 Hits@10 0.0 MRR 0.0625 rank 15 total_num 0 100\n",
      "checkcorrect (3183, 0, 3104) (3183, 0, 3104) real score 0.4401113033294678 Hits@1 0.0 Hits@3 0.0 Hits@10 0.0 MRR 0.05208333333333333 rank 23 total_num 1 100\n",
      "checkcorrect (3273, 8, 3104) (3273, 8, 3104) real score 0.21059984788298608 Hits@1 0.0 Hits@3 0.0 Hits@10 0.0 MRR 0.05059523809523809 rank 20 total_num 2 100\n",
      "checkcorrect (3104, 18, 3327) (3104, 18, 3327) real score 0.2939481571316719 Hits@1 0.25 Hits@3 0.25 Hits@10 0.25 MRR 0.28794642857142855 rank 0 total_num 3 100\n",
      "checkcorrect (3285, 12, 3104) (3285, 12, 3104) real score 0.3175746347755194 Hits@1 0.2 Hits@3 0.2 Hits@10 0.2 MRR 0.2457417582417582 rank 12 total_num 4 100\n",
      "checkcorrect (3165, 0, 3104) (3165, 0, 3104) real score 0.3680883826687932 Hits@1 0.16666666666666666 Hits@3 0.16666666666666666 Hits@10 0.16666666666666666 MRR 0.21119505494505494 rank 25 total_num 5 100\n",
      "checkcorrect (3104, 6, 3215) (3104, 6, 3215) real score 0.5625643044710159 Hits@1 0.14285714285714285 Hits@3 0.14285714285714285 Hits@10 0.14285714285714285 MRR 0.18816718995290424 rank 19 total_num 6 100\n",
      "checkcorrect (3321, 8, 3104) (3321, 8, 3104) real score 0.45436323806643486 Hits@1 0.25 Hits@3 0.25 Hits@10 0.25 MRR 0.2896462912087912 rank 0 total_num 7 100\n",
      "checkcorrect (3105, 0, 3104) (3105, 0, 3104) real score 0.6261285305023193 Hits@1 0.2222222222222222 Hits@3 0.3333333333333333 Hits@10 0.3333333333333333 MRR 0.3130189255189255 rank 1 total_num 8 100\n",
      "checkcorrect (3104, 6, 3318) (3104, 6, 3318) real score 0.6438703000545501 Hits@1 0.2 Hits@3 0.3 Hits@10 0.3 MRR 0.290807942057942 rank 10 total_num 9 100\n",
      "checkcorrect (3243, 8, 3104) (3243, 8, 3104) real score 0.328279953636229 Hits@1 0.18181818181818182 Hits@3 0.2727272727272727 Hits@10 0.2727272727272727 MRR 0.27136386340931795 rank 12 total_num 10 100\n",
      "checkcorrect (3171, 10, 3116) (3171, 10, 3116) real score 0.5171654015779495 Hits@1 0.16666666666666666 Hits@3 0.25 Hits@10 0.3333333333333333 MRR 0.25708354145854145 rank 9 total_num 11 100\n",
      "checkcorrect (3104, 6, 3238) (3104, 6, 3238) real score 0.4556687895208597 Hits@1 0.15384615384615385 Hits@3 0.23076923076923078 Hits@10 0.3076923076923077 MRR 0.24080438791977254 rank 21 total_num 12 100\n",
      "checkcorrect (3108, 12, 3104) (3108, 12, 3104) real score 0.30605392456054686 Hits@1 0.14285714285714285 Hits@3 0.21428571428571427 Hits@10 0.2857142857142857 MRR 0.23009758099043814 rank 10 total_num 13 100\n",
      "checkcorrect (3286, 8, 3104) (3286, 8, 3104) real score 0.41181579008698466 Hits@1 0.13333333333333333 Hits@3 0.26666666666666666 Hits@10 0.3333333333333333 MRR 0.2480910755910756 rank 1 total_num 14 100\n",
      "checkcorrect (3152, 8, 3104) (3152, 8, 3104) real score 0.3441018365323544 Hits@1 0.125 Hits@3 0.25 Hits@10 0.375 MRR 0.2415139547952048 rank 6 total_num 15 100\n",
      "checkcorrect (3179, 12, 3104) (3179, 12, 3104) real score 0.3819692626595497 Hits@1 0.11764705882352941 Hits@3 0.23529411764705882 Hits@10 0.4117647058823529 MRR 0.23711117314058489 rank 5 total_num 16 100\n",
      "checkcorrect (3287, 8, 3104) (3287, 8, 3104) real score 0.3281403576955199 Hits@1 0.1111111111111111 Hits@3 0.2222222222222222 Hits@10 0.4444444444444444 MRR 0.230111169694503 rank 8 total_num 17 100\n",
      "checkcorrect (3167, 12, 3104) (3167, 12, 3104) real score 0.30528906285762786 Hits@1 0.10526315789473684 Hits@3 0.21052631578947367 Hits@10 0.42105263157894735 MRR 0.22278474449527078 rank 10 total_num 18 100\n",
      "checkcorrect (3211, 8, 3104) (3211, 8, 3104) real score 0.22370787381660193 Hits@1 0.1 Hits@3 0.2 Hits@10 0.4 MRR 0.21477050727050723 rank 15 total_num 19 100\n",
      "checkcorrect (3321, 0, 3104) (3321, 0, 3104) real score 0.4963518649339676 Hits@1 0.09523809523809523 Hits@3 0.19047619047619047 Hits@10 0.38095238095238093 MRR 0.20794470080184363 rank 13 total_num 20 100\n",
      "checkcorrect (3277, 12, 3104) (3277, 12, 3104) real score 0.30555019676685335 Hits@1 0.09090909090909091 Hits@3 0.18181818181818182 Hits@10 0.36363636363636365 MRR 0.2017394221939676 rank 13 total_num 21 100\n",
      "checkcorrect (3297, 8, 3104) (3297, 8, 3104) real score 0.2729139722883701 Hits@1 0.08695652173913043 Hits@3 0.17391304347826086 Hits@10 0.391304347826087 MRR 0.19731596905509943 rank 9 total_num 22 100\n",
      "checkcorrect (3205, 0, 3104) (3205, 0, 3104) real score 0.5649938717484474 Hits@1 0.08333333333333333 Hits@3 0.16666666666666666 Hits@10 0.4166666666666667 MRR 0.19504685129685126 rank 6 total_num 23 100\n",
      "checkcorrect (3104, 6, 3322) (3104, 6, 3322) real score 0.5353878924623132 Hits@1 0.08 Hits@3 0.16 Hits@10 0.4 MRR 0.18959791842144777 rank 16 total_num 24 100\n",
      "checkcorrect (3308, 12, 3104) (3308, 12, 3104) real score 0.32051065266132356 Hits@1 0.07692307692307693 Hits@3 0.15384615384615385 Hits@10 0.38461538461538464 MRR 0.18551081899498184 rank 11 total_num 25 100\n",
      "checkcorrect (3104, 6, 3224) (3104, 6, 3224) real score 0.555025863647461 Hits@1 0.07407407407407407 Hits@3 0.14814814814814814 Hits@10 0.37037037037037035 MRR 0.17996279924384492 rank 27 total_num 26 100\n",
      "checkcorrect (3144, 12, 3104) (3144, 12, 3104) real score 0.24918826967477797 Hits@1 0.07142857142857142 Hits@3 0.14285714285714285 Hits@10 0.35714285714285715 MRR 0.17515893303708424 rank 21 total_num 27 100\n",
      "checkcorrect (3150, 12, 3104) (3150, 12, 3104) real score 0.13918949142098427 Hits@1 0.06896551724137931 Hits@3 0.13793103448275862 Hits@10 0.3448275862068966 MRR 0.17068636794803121 rank 21 total_num 28 100\n",
      "checkcorrect (3247, 8, 3104) (3247, 8, 3104) real score 0.3095918640494347 Hits@1 0.06666666666666667 Hits@3 0.13333333333333333 Hits@10 0.36666666666666664 MRR 0.1683301556830968 rank 9 total_num 29 100\n",
      "checkcorrect (3196, 8, 3104) (3196, 8, 3104) real score 0.22007295340299607 Hits@1 0.06451612903225806 Hits@3 0.12903225806451613 Hits@10 0.3548387096774194 MRR 0.16443624897135328 rank 20 total_num 30 100\n",
      "checkcorrect (3104, 6, 3306) (3104, 6, 3306) real score 0.5239591967314482 Hits@1 0.0625 Hits@3 0.125 Hits@10 0.34375 MRR 0.1610337273021096 rank 17 total_num 31 100\n",
      "checkcorrect (3104, 6, 3196) (3104, 6, 3196) real score 0.5801221525296569 Hits@1 0.06060606060606061 Hits@3 0.12121212121212122 Hits@10 0.3333333333333333 MRR 0.15753132785218343 rank 21 total_num 32 100\n",
      "checkcorrect (3112, 12, 3104) (3112, 12, 3104) real score 0.27857017815113067 Hits@1 0.058823529411764705 Hits@3 0.11764705882352941 Hits@10 0.3235294117647059 MRR 0.15453204043169436 rank 17 total_num 33 100\n",
      "checkcorrect (3198, 0, 3104) (3198, 0, 3104) real score 0.4133445782586932 Hits@1 0.05714285714285714 Hits@3 0.11428571428571428 Hits@10 0.3142857142857143 MRR 0.15162059867499933 rank 18 total_num 34 100\n",
      "checkcorrect (3177, 8, 3104) (3177, 8, 3104) real score 0.08552847392857074 Hits@1 0.05555555555555555 Hits@3 0.1111111111111111 Hits@10 0.3055555555555556 MRR 0.14843772196283372 rank 26 total_num 35 100\n",
      "checkcorrect (3305, 12, 3104) (3305, 12, 3104) real score 0.27205128893256186 Hits@1 0.05405405405405406 Hits@3 0.10810810810810811 Hits@10 0.2972972972972973 MRR 0.14577724299086522 rank 19 total_num 36 100\n",
      "checkcorrect (3171, 12, 3104) (3171, 12, 3104) real score 0.14556243903934957 Hits@1 0.05263157894736842 Hits@3 0.10526315789473684 Hits@10 0.2894736842105263 MRR 0.14319413258634373 rank 20 total_num 37 100\n",
      "checkcorrect (3180, 8, 3104) (3180, 8, 3104) real score 0.11321502355858684 Hits@1 0.05128205128205128 Hits@3 0.10256410256410256 Hits@10 0.28205128205128205 MRR 0.14050868145493844 rank 25 total_num 38 100\n",
      "checkcorrect (3104, 6, 3189) (3104, 6, 3189) real score 0.5497988566756249 Hits@1 0.05 Hits@3 0.1 Hits@10 0.275 MRR 0.13813232805492864 rank 21 total_num 39 100\n",
      "checkcorrect (3230, 8, 3104) (3230, 8, 3104) real score 0.141220816061832 Hits@1 0.04878048780487805 Hits@3 0.0975609756097561 Hits@10 0.2682926829268293 MRR 0.13592468706868763 rank 20 total_num 40 100\n",
      "checkcorrect (3128, 10, 3116) (3128, 10, 3116) real score 0.5479563564062119 Hits@1 0.047619047619047616 Hits@3 0.09523809523809523 Hits@10 0.2619047619047619 MRR 0.1342756865829252 rank 14 total_num 41 100\n",
      "checkcorrect (3316, 0, 3104) (3316, 0, 3104) real score 0.37645485186949373 Hits@1 0.046511627906976744 Hits@3 0.09302325581395349 Hits@10 0.2558139534883721 MRR 0.13216411854307963 rank 22 total_num 42 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkcorrect (3248, 8, 3104) (3248, 8, 3104) real score 0.2644237584900111 Hits@1 0.045454545454545456 Hits@3 0.09090909090909091 Hits@10 0.25 MRR 0.13067554009134297 rank 14 total_num 43 100\n",
      "checkcorrect (3324, 16, 3116) (3324, 16, 3116) real score 0.7031190752983093 Hits@1 0.044444444444444446 Hits@3 0.08888888888888889 Hits@10 0.26666666666666666 MRR 0.12999386142264646 rank 9 total_num 44 100\n",
      "checkcorrect (3104, 6, 3182) (3104, 6, 3182) real score 0.7069007955491543 Hits@1 0.043478260869565216 Hits@3 0.08695652173913043 Hits@10 0.2826086956521739 MRR 0.13151573400041502 rank 4 total_num 45 100\n",
      "checkcorrect (3151, 12, 3104) (3151, 12, 3104) real score 0.24322526529431343 Hits@1 0.0425531914893617 Hits@3 0.0851063829787234 Hits@10 0.2765957446808511 MRR 0.12989955999094993 rank 17 total_num 46 100\n",
      "checkcorrect (3144, 8, 3104) (3144, 8, 3104) real score 0.17664008401334286 Hits@1 0.041666666666666664 Hits@3 0.08333333333333333 Hits@10 0.2708333333333333 MRR 0.1280991162592544 rank 22 total_num 47 100\n",
      "checkcorrect (3154, 12, 3104) (3154, 12, 3104) real score 0.19154086336493492 Hits@1 0.04081632653061224 Hits@3 0.08163265306122448 Hits@10 0.2653061224489796 MRR 0.12645666587884202 rank 20 total_num 48 100\n",
      "checkcorrect (3274, 16, 3116) (3274, 16, 3116) real score 0.6408144563436509 Hits@1 0.04 Hits@3 0.08 Hits@10 0.26 MRR 0.12559419922793183 rank 11 total_num 49 100\n",
      "checkcorrect (3245, 10, 3116) (3245, 10, 3116) real score 0.56556256711483 Hits@1 0.0392156862745098 Hits@3 0.0784313725490196 Hits@10 0.2549019607843137 MRR 0.12476555479862599 rank 11 total_num 50 100\n",
      "checkcorrect (3240, 0, 3104) (3240, 0, 3104) real score 0.5138719186186791 Hits@1 0.038461538461538464 Hits@3 0.07692307692307693 Hits@10 0.25 MRR 0.12396878130890882 rank 11 total_num 51 100\n",
      "checkcorrect (3104, 6, 3276) (3104, 6, 3276) real score 0.4570516929030418 Hits@1 0.03773584905660377 Hits@3 0.07547169811320754 Hits@10 0.24528301886792453 MRR 0.12235543710424145 rank 25 total_num 52 100\n",
      "checkcorrect (3203, 8, 3104) (3203, 8, 3104) real score 0.42738804817199705 Hits@1 0.037037037037037035 Hits@3 0.09259259259259259 Hits@10 0.25925925925925924 MRR 0.12934885493564438 rank 1 total_num 53 100\n",
      "checkcorrect (3302, 0, 3104) (3302, 0, 3104) real score 0.43399926722049714 Hits@1 0.03636363636363636 Hits@3 0.09090909090909091 Hits@10 0.2545454545454545 MRR 0.12790614848226903 rank 19 total_num 54 100\n",
      "checkcorrect (3104, 6, 3175) (3104, 6, 3175) real score 0.44940990060567854 Hits@1 0.03571428571428571 Hits@3 0.08928571428571429 Hits@10 0.25 MRR 0.12639850763204216 rank 22 total_num 55 100\n",
      "checkcorrect (3259, 8, 3104) (3259, 8, 3104) real score 0.24428593702614307 Hits@1 0.03508771929824561 Hits@3 0.08771929824561403 Hits@10 0.24561403508771928 MRR 0.1256429782583806 rank 11 total_num 56 100\n",
      "checkcorrect (3299, 0, 3104) (3299, 0, 3104) real score 0.45742067098617556 Hits@1 0.034482758620689655 Hits@3 0.08620689655172414 Hits@10 0.2413793103448276 MRR 0.12429773807494383 rank 20 total_num 57 100\n",
      "checkcorrect (3282, 8, 3104) (3282, 8, 3104) real score 0.1896385178435594 Hits@1 0.03389830508474576 Hits@3 0.0847457627118644 Hits@10 0.23728813559322035 MRR 0.12318800572472045 rank 16 total_num 58 100\n",
      "checkcorrect (3198, 16, 3116) (3198, 16, 3116) real score 0.6677624166011811 Hits@1 0.03333333333333333 Hits@3 0.08333333333333333 Hits@10 0.23333333333333334 MRR 0.12241692357802639 rank 12 total_num 59 100\n",
      "checkcorrect (3107, 8, 3104) (3107, 8, 3104) real score 0.36362209245562555 Hits@1 0.03278688524590164 Hits@3 0.08196721311475409 Hits@10 0.22950819672131148 MRR 0.12190040173099466 rank 10 total_num 60 100\n",
      "checkcorrect (3104, 6, 3312) (3104, 6, 3312) real score 0.6603790491819381 Hits@1 0.03225806451612903 Hits@3 0.08064516129032258 Hits@10 0.24193548387096775 MRR 0.12195039525146249 rank 7 total_num 61 100\n",
      "checkcorrect (3186, 16, 3116) (3186, 16, 3116) real score 0.7351603507995605 Hits@1 0.031746031746031744 Hits@3 0.07936507936507936 Hits@10 0.23809523809523808 MRR 0.12100673818397896 rank 15 total_num 62 100\n",
      "checkcorrect (3282, 12, 3104) (3282, 12, 3104) real score 0.25504911970347166 Hits@1 0.03125 Hits@3 0.078125 Hits@10 0.234375 MRR 0.11976704956652096 rank 23 total_num 63 100\n",
      "checkcorrect (3285, 16, 3116) (3285, 16, 3116) real score 0.6739103049039841 Hits@1 0.03076923076923077 Hits@3 0.07692307692307693 Hits@10 0.23076923076923078 MRR 0.11851619554952122 rank 25 total_num 64 100\n",
      "checkcorrect (3281, 12, 3104) (3281, 12, 3104) real score 0.36182561740279195 Hits@1 0.030303030303030304 Hits@3 0.07575757575757576 Hits@10 0.24242424242424243 MRR 0.1184039973004544 rank 8 total_num 65 100\n",
      "checkcorrect (3119, 12, 3104) (3119, 12, 3104) real score 0.17910548113286495 Hits@1 0.029850746268656716 Hits@3 0.07462686567164178 Hits@10 0.23880597014925373 MRR 0.11734750551416474 rank 20 total_num 66 100\n",
      "checkcorrect (3321, 16, 3116) (3321, 16, 3116) real score 0.4231085777282715 Hits@1 0.029411764705882353 Hits@3 0.07352941176470588 Hits@10 0.23529411764705882 MRR 0.11618741776339082 rank 25 total_num 67 100\n",
      "checkcorrect (3104, 6, 3177) (3104, 6, 3177) real score 0.505462096631527 Hits@1 0.028985507246376812 Hits@3 0.07246376811594203 Hits@10 0.2318840579710145 MRR 0.11519367326854527 rank 20 total_num 68 100\n",
      "checkcorrect (3297, 0, 3104) (3297, 0, 3104) real score 0.5562529176473617 Hits@1 0.02857142857142857 Hits@3 0.07142857142857142 Hits@10 0.22857142857142856 MRR 0.11484675066341021 rank 10 total_num 69 100\n",
      "checkcorrect (3303, 16, 3116) (3303, 16, 3116) real score 0.7276384562253952 Hits@1 0.028169014084507043 Hits@3 0.07042253521126761 Hits@10 0.23943661971830985 MRR 0.11479413602182853 rank 8 total_num 70 100\n",
      "checkcorrect (3196, 16, 3116) (3196, 16, 3116) real score 0.5591445684432983 Hits@1 0.027777777777777776 Hits@3 0.06944444444444445 Hits@10 0.2361111111111111 MRR 0.11389421746596981 rank 19 total_num 71 100\n",
      "checkcorrect (3202, 8, 3104) (3202, 8, 3104) real score 0.46322830114513636 Hits@1 0.0273972602739726 Hits@3 0.0821917808219178 Hits@10 0.2465753424657534 MRR 0.11918333777465516 rank 1 total_num 72 100\n",
      "checkcorrect (3104, 6, 3143) (3104, 6, 3143) real score 0.6093707010149956 Hits@1 0.02702702702702703 Hits@3 0.08108108108108109 Hits@10 0.24324324324324326 MRR 0.11828398968239452 rank 18 total_num 73 100\n",
      "checkcorrect (3133, 12, 3104) (3133, 12, 3104) real score 0.2571088336408138 Hits@1 0.02666666666666667 Hits@3 0.08 Hits@10 0.24 MRR 0.11726242537551815 rank 23 total_num 74 100\n",
      "checkcorrect (3163, 12, 3104) (3163, 12, 3104) real score 0.4109304040670395 Hits@1 0.02631578947368421 Hits@3 0.07894736842105263 Hits@10 0.25 MRR 0.11759919797396057 rank 6 total_num 75 100\n",
      "checkcorrect (3314, 16, 3116) (3314, 16, 3116) real score 0.5909868158400059 Hits@1 0.025974025974025976 Hits@3 0.07792207792207792 Hits@10 0.24675324675324675 MRR 0.11683587760302296 rank 16 total_num 76 100\n",
      "checkcorrect (3121, 16, 3116) (3121, 16, 3116) real score 0.6432090252637863 Hits@1 0.02564102564102564 Hits@3 0.07692307692307693 Hits@10 0.24358974358974358 MRR 0.11632417503020313 rank 12 total_num 77 100\n",
      "checkcorrect (3223, 8, 3104) (3223, 8, 3104) real score 0.3661236561834812 Hits@1 0.02531645569620253 Hits@3 0.08860759493670886 Hits@10 0.25316455696202533 MRR 0.11907112640112884 rank 2 total_num 78 100\n",
      "checkcorrect (3310, 10, 3116) (3310, 10, 3116) real score 0.6068129420280457 Hits@1 0.025 Hits@3 0.0875 Hits@10 0.2625 MRR 0.11883273732111473 rank 9 total_num 79 100\n",
      "checkcorrect (3104, 6, 3136) (3104, 6, 3136) real score 0.8038505554199219 Hits@1 0.024691358024691357 Hits@3 0.09876543209876543 Hits@10 0.2716049382716049 MRR 0.12353850599616269 rank 1 total_num 80 100\n",
      "checkcorrect (3305, 0, 3104) (3305, 0, 3104) real score 0.2786500469781458 Hits@1 0.024390243902439025 Hits@3 0.0975609756097561 Hits@10 0.2682926829268293 MRR 0.12258626257492344 rank 21 total_num 81 100\n",
      "checkcorrect (3251, 8, 3104) (3251, 8, 3104) real score 0.2872571752406657 Hits@1 0.024096385542168676 Hits@3 0.0963855421686747 Hits@10 0.26506024096385544 MRR 0.12203610371164819 rank 12 total_num 82 100\n",
      "checkcorrect (3225, 10, 3116) (3225, 10, 3116) real score 0.6082006990909576 Hits@1 0.023809523809523808 Hits@3 0.09523809523809523 Hits@10 0.27380952380952384 MRR 0.12207138819127142 rank 7 total_num 83 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkcorrect (3179, 0, 3104) (3179, 0, 3104) real score 0.6128452308475971 Hits@1 0.023529411764705882 Hits@3 0.09411764705882353 Hits@10 0.2823529411764706 MRR 0.12357643068313881 rank 3 total_num 84 100\n",
      "checkcorrect (3104, 6, 3184) (3104, 6, 3184) real score 0.7208112940192223 Hits@1 0.023255813953488372 Hits@3 0.09302325581395349 Hits@10 0.29069767441860467 MRR 0.12504647218682324 rank 3 total_num 85 100\n",
      "checkcorrect (3193, 8, 3104) (3193, 8, 3104) real score 0.31818424817174673 Hits@1 0.022988505747126436 Hits@3 0.09195402298850575 Hits@10 0.28735632183908044 MRR 0.12465408849397576 rank 10 total_num 86 100\n",
      "checkcorrect (3104, 6, 3138) (3104, 6, 3138) real score 0.5259215146303177 Hits@1 0.022727272727272728 Hits@3 0.09090909090909091 Hits@10 0.2840909090909091 MRR 0.12373163590733473 rank 22 total_num 87 100\n",
      "checkcorrect (3104, 6, 3147) (3104, 6, 3147) real score 0.5320713806897401 Hits@1 0.02247191011235955 Hits@3 0.0898876404494382 Hits@10 0.2808988764044944 MRR 0.12300233133996877 rank 16 total_num 88 100\n",
      "checkcorrect (3266, 12, 3104) (3266, 12, 3104) real score 0.23661954756826162 Hits@1 0.022222222222222223 Hits@3 0.08888888888888889 Hits@10 0.2777777777777778 MRR 0.12209860173248763 rank 23 total_num 89 100\n",
      "checkcorrect (3322, 12, 3104) (3322, 12, 3104) real score 0.2650240555405617 Hits@1 0.02197802197802198 Hits@3 0.08791208791208792 Hits@10 0.27472527472527475 MRR 0.12136735946680705 rank 17 total_num 90 100\n",
      "checkcorrect (3141, 12, 3104) (3141, 12, 3104) real score 0.36501750648021697 Hits@1 0.021739130434782608 Hits@3 0.08695652173913043 Hits@10 0.2826086956521739 MRR 0.12140684468999394 rank 7 total_num 91 100\n",
      "checkcorrect (3322, 10, 3116) (3322, 10, 3116) real score 0.5989022076129913 Hits@1 0.021505376344086023 Hits@3 0.08602150537634409 Hits@10 0.27956989247311825 MRR 0.12099745209476102 rank 11 total_num 92 100\n",
      "checkcorrect (3216, 12, 3104) (3216, 12, 3104) real score 0.24658313319087027 Hits@1 0.02127659574468085 Hits@3 0.0851063829787234 Hits@10 0.2765957446808511 MRR 0.12033602738536744 rank 16 total_num 93 100\n",
      "checkcorrect (3223, 0, 3104) (3223, 0, 3104) real score 0.46917044520378115 Hits@1 0.021052631578947368 Hits@3 0.08421052631578947 Hits@10 0.2736842105263158 MRR 0.11965412768189575 rank 17 total_num 94 100\n",
      "checkcorrect (3104, 6, 3149) (3104, 6, 3149) real score 0.525828443467617 Hits@1 0.020833333333333332 Hits@3 0.08333333333333333 Hits@10 0.2708333333333333 MRR 0.11875495274076488 rank 29 total_num 95 100\n",
      "checkcorrect (3310, 8, 3104) (3310, 8, 3104) real score 0.25418798066675663 Hits@1 0.020618556701030927 Hits@3 0.08247422680412371 Hits@10 0.26804123711340205 MRR 0.11804613879498381 rank 19 total_num 96 100\n",
      "checkcorrect (3103, 16, 3116) (3103, 16, 3116) real score 0.8331052780151367 Hits@1 0.02040816326530612 Hits@3 0.08163265306122448 Hits@10 0.2755102040816326 MRR 0.11829931230582216 rank 6 total_num 97 100\n",
      "checkcorrect (3119, 0, 3104) (3119, 0, 3104) real score 0.5585315436124801 Hits@1 0.020202020202020204 Hits@3 0.08080808080808081 Hits@10 0.2828282828282828 MRR 0.11836699601990476 rank 7 total_num 98 100\n",
      "checkcorrect (3217, 16, 3116) (3217, 16, 3116) real score 0.7951494574546814 Hits@1 0.02 Hits@3 0.08 Hits@10 0.28 MRR 0.11809241696879663 rank 10 total_num 99 100\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#obtain the Hits@N for entity prediction##############\n",
    "\n",
    "#we select all the triples in the inductive test set\n",
    "selected = list(data_ind_test)\n",
    "\n",
    "###Hit at 1#############################\n",
    "#generate the negative samples by randomly replace relation with all the other relaiton\n",
    "Hits_at_1 = 0\n",
    "Hits_at_3 = 0\n",
    "Hits_at_10 = 0\n",
    "MRR_raw = 0.\n",
    "\n",
    "for i in range(len(selected)):\n",
    "    \n",
    "    triple_list = list()\n",
    "    \n",
    "    #score the true triple\n",
    "    s_pos, r_pos, t_pos = selected[i][0], selected[i][1], selected[i][2]\n",
    "\n",
    "    #path_score = path_based_triple_scoring(s_pos, r_pos, t_pos, 1, 10, one_hop_ind, id2relation, model)\n",
    "\n",
    "    subg_score = subgraph_triple_scoring(s_pos, r_pos, t_pos, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "    \n",
    "    #ave_score = (path_score + subg_score)/float(2)\n",
    "    \n",
    "    triple_list.append([(s_pos, r_pos, t_pos), subg_score])\n",
    "    \n",
    "    #generate the 50 random samples\n",
    "    for sub_i in range(50):\n",
    "        \n",
    "        #decide to replace the head or tail entity\n",
    "        number_0 = random.uniform(0, 1)\n",
    "\n",
    "        if number_0 < 0.5: #replace head entity\n",
    "            \n",
    "            s_neg = random.choice(list(new_ent_set))\n",
    "            \n",
    "            #path_score = path_based_triple_scoring(s_neg, r_pos, t_pos, 1, 10, one_hop_ind, id2relation, model)\n",
    "\n",
    "            subg_score = subgraph_triple_scoring(s_neg, r_pos, t_pos, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "\n",
    "            #ave_score = (path_score + subg_score)/float(2)\n",
    "\n",
    "            triple_list.append([(s_neg, r_pos, t_pos), subg_score])\n",
    "            \n",
    "        else: #replace tail entity\n",
    "\n",
    "            t_neg = random.choice(list(new_ent_set))\n",
    "            \n",
    "            #path_score = path_based_triple_scoring(s_pos, r_pos, t_neg, 1, 10, one_hop_ind, id2relation, model)\n",
    "\n",
    "            subg_score = subgraph_triple_scoring(s_pos, r_pos, t_neg, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "\n",
    "            #ave_score = (path_score + subg_score)/float(2)\n",
    "\n",
    "            triple_list.append([(s_pos, r_pos, t_neg), subg_score])\n",
    "            \n",
    "    #random shuffle!\n",
    "    random.shuffle(triple_list)\n",
    "    \n",
    "    #sort\n",
    "    sorted_list = sorted(triple_list, key = lambda x: x[-1], reverse=True)\n",
    "    \n",
    "    p = 0\n",
    "    \n",
    "    while p < len(sorted_list) and sorted_list[p][0] != (s_pos, r_pos, t_pos):\n",
    "            \n",
    "        p += 1\n",
    "    \n",
    "    if p == 0:\n",
    "        \n",
    "        Hits_at_1 += 1\n",
    "        \n",
    "    if p < 3:\n",
    "        \n",
    "        Hits_at_3 += 1\n",
    "        \n",
    "    if p < 10:\n",
    "        \n",
    "        Hits_at_10 += 1\n",
    "        \n",
    "    MRR_raw += 1./float(p + 1.) \n",
    "        \n",
    "    print('checkcorrect', (s_pos, r_pos, t_pos), sorted_list[p][0],\n",
    "          'real score', sorted_list[p][-1],\n",
    "          'Hits@1', Hits_at_1/(i+1),\n",
    "          'Hits@3', Hits_at_3/(i+1),\n",
    "          'Hits@10', Hits_at_10/(i+1),\n",
    "          'MRR', MRR_raw/(i+1),\n",
    "          'rank', p,\n",
    "          'total_num', i, len(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcec14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b1482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23edb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10052e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5bc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44b53285",
   "metadata": {},
   "source": [
    "#### Fine tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "864a4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build the big batche for path-based training\n",
    "def build_big_batches_path(lower_bd, upper_bd, data, one_hop, s_t_r,\n",
    "                      x_p_list, x_r_list, y_list,\n",
    "                      relation2id, entity2id, id2relation, id2entity):\n",
    "    \n",
    "    #the set of all relation IDs\n",
    "    relation_id_set = set()\n",
    "    \n",
    "    #the set of all initial relations\n",
    "    ini_r_id_set = set()\n",
    "    \n",
    "    for i in range(len(id2relation)):\n",
    "        \n",
    "        if i not in id2relation:\n",
    "            raise ValueError('error when generaing id2relation')\n",
    "        \n",
    "        relation_id_set.add(i)\n",
    "        \n",
    "        if i % 2 == 0: #initial relation id is always an even number\n",
    "            ini_r_id_set.add(i)\n",
    "    \n",
    "    num_r = len(id2relation)\n",
    "    num_ini_r = len(ini_r_id_set)\n",
    "    \n",
    "    if num_ini_r != int(num_r/2):\n",
    "        raise ValueError('error when generating id2relation')\n",
    "    \n",
    "    #in case not all entities in entity2id are in one_hop, \n",
    "    #so we need to find out who are indeed in\n",
    "    existing_ids = set()\n",
    "    \n",
    "    for s_1 in one_hop:\n",
    "        existing_ids.add(s_1)\n",
    "        \n",
    "    existing_ids = list(existing_ids)\n",
    "    random.shuffle(existing_ids)\n",
    "    \n",
    "    count = 0\n",
    "    for s in existing_ids:\n",
    "        \n",
    "        #impliment the path finding algorithm to find paths between s and t\n",
    "        result, length_dict = Class_2.obtain_paths('direct_neighbour', s, 'nb', lower_bd, upper_bd, one_hop)\n",
    "        \n",
    "        for iteration in range(2):\n",
    "\n",
    "            #proceed only if at least three paths are between s and t\n",
    "            for t in result:\n",
    "\n",
    "                if len(s_t_r[(s,t)]) == 0:\n",
    "\n",
    "                    raise ValueError(s,t,id2entity[s], id2entity[t])\n",
    "\n",
    "                #we are only interested in forward link in relation prediciton\n",
    "                ini_r_list = list()\n",
    "\n",
    "                #obtain initial relations between s and t\n",
    "                for r in s_t_r[(s,t)]:\n",
    "                    if r % 2 == 0:#initial relation id is always an even number\n",
    "                        ini_r_list.append(r)\n",
    "\n",
    "                #if there exist more than three paths between s and t, \n",
    "                #and inital connection between s and t exists,\n",
    "                #and not every r in the relation dictionary exists between s and t (although this is rare)\n",
    "                #we then proceed\n",
    "                if len(result[t]) >= 3 and len(ini_r_list) > 0 and len(ini_r_list) < int(num_ini_r):\n",
    "\n",
    "                    #obtain the list form of all the paths from s to t\n",
    "                    temp_path_list = list(result[t])\n",
    "\n",
    "                    temp_pair = random.sample(temp_path_list, 3)\n",
    "\n",
    "                    path_1, path_2, path_3 = temp_pair[0], temp_pair[1], temp_pair[2]\n",
    "\n",
    "                    #####positive#####################\n",
    "                    #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                    x_p_list['1'].append(list(path_1) + [num_r]*abs(len(path_1)-upper_bd))\n",
    "                    x_p_list['2'].append(list(path_2) + [num_r]*abs(len(path_2)-upper_bd))\n",
    "                    x_p_list['3'].append(list(path_3) + [num_r]*abs(len(path_3)-upper_bd))\n",
    "\n",
    "                    #append relation\n",
    "                    r = random.choice(ini_r_list)\n",
    "                    x_r_list.append([r])\n",
    "                    y_list.append(1.)\n",
    "\n",
    "                    #####negative#####################\n",
    "                    #append the paths: note that we add the space holder id at the end\n",
    "                    #of the shorter path\n",
    "                    x_p_list['1'].append(list(path_1) + [num_r]*abs(len(path_1)-upper_bd))\n",
    "                    x_p_list['2'].append(list(path_2) + [num_r]*abs(len(path_2)-upper_bd))\n",
    "                    x_p_list['3'].append(list(path_3) + [num_r]*abs(len(path_3)-upper_bd))\n",
    "\n",
    "                    #append relation\n",
    "                    neg_r_list = list(ini_r_id_set.difference(set(ini_r_list)))\n",
    "                    r_ran = random.choice(neg_r_list)\n",
    "                    x_r_list.append([r_ran])\n",
    "                    y_list.append(0.)\n",
    "        \n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('generating big-batches for path-based model', count, len(existing_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc82bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, it is too slow to run the path-finding algorithm again and again on the complete FB15K-237\n",
    "#Instead, we will find the subgraph for each entity once.\n",
    "#then in the subgraph based training, the subgraphs are stored and used for multiple times\n",
    "def store_subgraph_dicts(lower_bd, upper_bd, data, one_hop, s_t_r,\n",
    "                         relation2id, entity2id, id2relation, id2entity):\n",
    "    \n",
    "    #the set of all relation IDs\n",
    "    relation_id_set = set()\n",
    "    \n",
    "    for i in range(len(id2relation)):\n",
    "        \n",
    "        if i not in id2relation:\n",
    "            raise ValueError('error when generaing id2relation')\n",
    "        \n",
    "        relation_id_set.add(i)\n",
    "    \n",
    "    num_r = len(id2relation)\n",
    "    \n",
    "    #in case not all entities in entity2id are in one_hop, \n",
    "    #so we need to find out who are indeed in\n",
    "    existing_ids = set()\n",
    "    \n",
    "    for s_1 in one_hop:\n",
    "        existing_ids.add(s_1)\n",
    "    \n",
    "    #the ids to start path finding\n",
    "    existing_ids = list(existing_ids)\n",
    "    random.shuffle(existing_ids)\n",
    "    \n",
    "    #Dict stores the subgraph for each entity\n",
    "    Dict_1 = dict()\n",
    "    \n",
    "    count = 0\n",
    "    for s in existing_ids:\n",
    "        \n",
    "        path_set = set()\n",
    "            \n",
    "        result, length_dict = Class_2.obtain_paths('any_target', s, 'any', lower_bd, upper_bd, one_hop)\n",
    "\n",
    "        for t_ in result:\n",
    "            for path in result[t_]:\n",
    "                path_set.add(path)\n",
    "\n",
    "        del(result, length_dict)\n",
    "        \n",
    "        path_list = list(path_set)\n",
    "        \n",
    "        path_select = random.sample(path_list, min(len(path_list), 100))\n",
    "            \n",
    "        Dict_1[s] = deepcopy(path_select)\n",
    "        \n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('generating and storing paths for the path-based model', count, len(existing_ids))\n",
    "        \n",
    "    return(Dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee3bf172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build the big-batch for one-hope neighbor training\n",
    "def build_big_batches_subgraph(lower_bd, upper_bd, data, one_hop, s_t_r,\n",
    "                      x_s_list, x_t_list, x_r_list, y_list, Dict,\n",
    "                      relation2id, entity2id, id2relation, id2entity):\n",
    "    \n",
    "    #the set of all relation IDs\n",
    "    relation_id_set = set()\n",
    "    \n",
    "    #the set of all initial relations\n",
    "    ini_r_id_set = set()\n",
    "    \n",
    "    for i in range(len(id2relation)):\n",
    "        \n",
    "        if i not in id2relation:\n",
    "            raise ValueError('error when generaing id2relation')\n",
    "        \n",
    "        relation_id_set.add(i)\n",
    "        \n",
    "        if i % 2 == 0: #initial relation id is always an even number\n",
    "            ini_r_id_set.add(i)\n",
    "    \n",
    "    num_r = len(id2relation)\n",
    "    num_ini_r = len(ini_r_id_set)\n",
    "    \n",
    "    if num_ini_r != int(num_r/2):\n",
    "        raise ValueError('error when generating id2relation')\n",
    "        \n",
    "    #if an entity has at least three out-stretching paths, it is a qualified one\n",
    "    qualified = set()\n",
    "    for e in Dict:\n",
    "        if len(Dict[e]) >= 3:\n",
    "            qualified.add(e)\n",
    "    qualified = list(qualified)\n",
    "    \n",
    "    data = list(data)\n",
    "    \n",
    "    for iteration in range(2):\n",
    "\n",
    "        data = shuffle(data)\n",
    "\n",
    "        for i_0 in range(len(data)):\n",
    "\n",
    "            triple = data[i_0]\n",
    "\n",
    "            s, r, t = triple[0], triple[1], triple[2] #obtain entities and relation IDs\n",
    "\n",
    "            if s in qualified and t in qualified:\n",
    "\n",
    "                #obtain the path list for true entities\n",
    "                path_s, path_t = list(Dict[s]), list(Dict[t])\n",
    "\n",
    "                #####positive step###########\n",
    "                #randomly obtain three paths for true entities\n",
    "                temp_s = random.sample(path_s, 3)\n",
    "                temp_t = random.sample(path_t, 3)\n",
    "                s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "                t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(1.)\n",
    "\n",
    "                #####negative step for relation###########\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                neg_r_list = list(ini_r_id_set.difference({r}))\n",
    "                r_ran = random.choice(neg_r_list)\n",
    "                x_r_list.append([r_ran])\n",
    "                y_list.append(0.)\n",
    "                \n",
    "                ##############################################\n",
    "                ##############################################\n",
    "                #randomly choose two negative sampled entities\n",
    "                s_ran = random.choice(qualified)\n",
    "                t_ran = random.choice(qualified)\n",
    "\n",
    "                #obtain the path list for random entities\n",
    "                path_s_ran, path_t_ran = list(Dict[s_ran]), list(Dict[t_ran])\n",
    "                \n",
    "                #####positive step#################\n",
    "                #Again: randomly obtain three paths\n",
    "                temp_s = random.sample(path_s, 3)\n",
    "                temp_t = random.sample(path_t, 3)\n",
    "                s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "                t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(1.)\n",
    "\n",
    "                #####negative for source entity###########\n",
    "                #randomly obtain three paths\n",
    "                temp_s = random.sample(path_s_ran, 3)\n",
    "                s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(0.)\n",
    "\n",
    "                #####positive step###########\n",
    "                #Again: randomly obtain three paths\n",
    "                temp_s = random.sample(path_s, 3)\n",
    "                temp_t = random.sample(path_t, 3)\n",
    "                s_p_1, s_p_2, s_p_3 = temp_s[0], temp_s[1], temp_s[2]\n",
    "                t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(1.)\n",
    "\n",
    "                #####negative for target entity###########\n",
    "                #randomly obtain three paths\n",
    "                temp_t = random.sample(path_t_ran, 3)\n",
    "                t_p_1, t_p_2, t_p_3 = temp_t[0], temp_t[1], temp_t[2]\n",
    "\n",
    "                #append the paths: note that we add the space holder id at the end of the shorter path\n",
    "                x_s_list['1'].append(list(s_p_1) + [num_r]*abs(len(s_p_1)-upper_bd))\n",
    "                x_s_list['2'].append(list(s_p_2) + [num_r]*abs(len(s_p_2)-upper_bd))\n",
    "                x_s_list['3'].append(list(s_p_3) + [num_r]*abs(len(s_p_3)-upper_bd))\n",
    "\n",
    "                x_t_list['1'].append(list(t_p_1) + [num_r]*abs(len(t_p_1)-upper_bd))\n",
    "                x_t_list['2'].append(list(t_p_2) + [num_r]*abs(len(t_p_2)-upper_bd))\n",
    "                x_t_list['3'].append(list(t_p_3) + [num_r]*abs(len(t_p_3)-upper_bd))\n",
    "\n",
    "                #append relation\n",
    "                x_r_list.append([r])\n",
    "                y_list.append(0.)\n",
    "\n",
    "            if i_0 % 200 == 0:\n",
    "                print('generating big-batches for subgraph-based model', i_0, len(data), iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45513dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating big-batches for path-based model 100 922\n",
      "generating big-batches for path-based model 200 922\n",
      "generating big-batches for path-based model 300 922\n",
      "generating big-batches for path-based model 400 922\n",
      "generating big-batches for path-based model 500 922\n",
      "generating big-batches for path-based model 600 922\n",
      "generating big-batches for path-based model 700 922\n",
      "generating big-batches for path-based model 800 922\n",
      "generating big-batches for path-based model 900 922\n",
      "Epoch 1/2\n",
      "110/110 [==============================] - 16s 73ms/step - loss: 0.2073 - binary_accuracy: 0.9459\n",
      "Epoch 2/2\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.1328 - binary_accuracy: 0.9648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2daab26a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###fine tune the path-based model\n",
    "lower_bd = 1\n",
    "upper_bd = 10\n",
    "batch_size = 32\n",
    "\n",
    "#define the training lists\n",
    "train_p_list, train_r_list, train_y_list = {'1': [], '2': [], '3': []}, list(), list()\n",
    "\n",
    "#######################################\n",
    "###build the big-batches###############      \n",
    "\n",
    "#fill in the training array list\n",
    "build_big_batches_path(lower_bd, upper_bd, data_ind, one_hop_ind, s_t_r_ind,\n",
    "                      train_p_list, train_r_list, train_y_list,\n",
    "                      relation2id, entity2id, id2relation, id2entity)   \n",
    "\n",
    "#######################################\n",
    "###do the training#####################\n",
    "\n",
    "#generate the input arrays\n",
    "x_train_1 = np.asarray(train_p_list['1'], dtype='int')\n",
    "x_train_2 = np.asarray(train_p_list['2'], dtype='int')\n",
    "x_train_3 = np.asarray(train_p_list['3'], dtype='int')\n",
    "x_train_r = np.asarray(train_r_list, dtype='int')\n",
    "y_train = np.asarray(train_y_list, dtype='int')\n",
    "\n",
    "model.fit([x_train_1, x_train_2, x_train_3, x_train_r], y_train,\n",
    "           batch_size=batch_size, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcc46d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating and storing paths for the path-based model 100 922\n",
      "generating and storing paths for the path-based model 200 922\n",
      "generating and storing paths for the path-based model 300 922\n",
      "generating and storing paths for the path-based model 400 922\n",
      "generating and storing paths for the path-based model 500 922\n",
      "generating and storing paths for the path-based model 600 922\n",
      "generating and storing paths for the path-based model 700 922\n",
      "generating and storing paths for the path-based model 800 922\n",
      "generating and storing paths for the path-based model 900 922\n",
      "generating big-batches for subgraph-based model 0 1618 0\n",
      "generating big-batches for subgraph-based model 200 1618 0\n",
      "generating big-batches for subgraph-based model 400 1618 0\n",
      "generating big-batches for subgraph-based model 600 1618 0\n",
      "generating big-batches for subgraph-based model 800 1618 0\n",
      "generating big-batches for subgraph-based model 1000 1618 0\n",
      "generating big-batches for subgraph-based model 1200 1618 0\n",
      "generating big-batches for subgraph-based model 1400 1618 0\n",
      "generating big-batches for subgraph-based model 1600 1618 0\n",
      "generating big-batches for subgraph-based model 0 1618 1\n",
      "generating big-batches for subgraph-based model 200 1618 1\n",
      "generating big-batches for subgraph-based model 400 1618 1\n",
      "generating big-batches for subgraph-based model 600 1618 1\n",
      "generating big-batches for subgraph-based model 800 1618 1\n",
      "generating big-batches for subgraph-based model 1000 1618 1\n",
      "generating big-batches for subgraph-based model 1200 1618 1\n",
      "generating big-batches for subgraph-based model 1400 1618 1\n",
      "generating big-batches for subgraph-based model 1600 1618 1\n",
      "Epoch 1/2\n",
      "601/601 [==============================] - 42s 44ms/step - loss: 0.4792 - binary_accuracy: 0.7667\n",
      "Epoch 2/2\n",
      "601/601 [==============================] - 26s 44ms/step - loss: 0.4609 - binary_accuracy: 0.7747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff290652df0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###fine tune the subgraph model\n",
    "lower_bd = 1\n",
    "upper_bd = 6\n",
    "batch_size = 32\n",
    "\n",
    "Dict_train_ind = store_subgraph_dicts(lower_bd, upper_bd, data_ind, one_hop_ind, s_t_r_ind,\n",
    "                         relation2id, entity2id, id2relation, id2entity)\n",
    "\n",
    "#define the training lists\n",
    "train_s_list, train_t_list, train_r_list, train_y_list = {'1': [], '2': [], '3': []}, {'1': [], '2': [], '3': []}, list(), list()\n",
    "\n",
    "#######################################\n",
    "###build the big-batches###############      \n",
    "\n",
    "#fill in the training array list\n",
    "build_big_batches_subgraph(lower_bd, upper_bd, data_ind, one_hop_ind, s_t_r_ind,\n",
    "                      train_s_list, train_t_list, train_r_list, train_y_list, Dict_train_ind,\n",
    "                      relation2id, entity2id, id2relation, id2entity)\n",
    "\n",
    "#######################################\n",
    "###do the training#####################\n",
    "\n",
    "#generate the input arrays\n",
    "x_train_s_1 = np.asarray(train_s_list['1'], dtype='int')\n",
    "x_train_s_2 = np.asarray(train_s_list['2'], dtype='int')\n",
    "x_train_s_3 = np.asarray(train_s_list['3'], dtype='int')\n",
    "\n",
    "x_train_t_1 = np.asarray(train_t_list['1'], dtype='int')\n",
    "x_train_t_2 = np.asarray(train_t_list['2'], dtype='int')\n",
    "x_train_t_3 = np.asarray(train_t_list['3'], dtype='int')\n",
    "\n",
    "x_train_r = np.asarray(train_r_list, dtype='int')\n",
    "y_train = np.asarray(train_y_list, dtype='int')\n",
    "\n",
    "model_2.fit([x_train_s_1, x_train_s_2, x_train_s_3, \n",
    "             x_train_t_1, x_train_t_2, x_train_t_3, x_train_r], y_train,\n",
    "             batch_size=batch_size, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9f6be50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "9 10 10\n",
      "checkcorrect 0 0 real score 0.3973050579428673 Hits@1 0.0 Hits@3 1.0 Hits@10 1.0 MRR 0.5 cur_rank 1 abs_cur_rank 1 total_num 0 188\n",
      "0 1\n",
      "9 11 31\n",
      "checkcorrect 0 0 real score 0.7147584974765777 Hits@1 0.5 Hits@3 1.0 Hits@10 1.0 MRR 0.75 cur_rank 0 abs_cur_rank 0 total_num 1 188\n",
      "0 1\n",
      "9 34 10\n",
      "checkcorrect 0 0 real score 0.7171109318733215 Hits@1 0.6666666666666666 Hits@3 1.0 Hits@10 1.0 MRR 0.8333333333333334 cur_rank 0 abs_cur_rank 0 total_num 2 188\n",
      "9 61\n",
      "9 13 22\n",
      "checkcorrect 0 0 real score 1.6940622508525849 Hits@1 0.75 Hits@3 1.0 Hits@10 1.0 MRR 0.875 cur_rank 0 abs_cur_rank 0 total_num 3 188\n",
      "9 11\n",
      "9 47 31\n",
      "checkcorrect 0 0 real score 1.4414083257317545 Hits@1 0.8 Hits@3 1.0 Hits@10 1.0 MRR 0.9 cur_rank 0 abs_cur_rank 0 total_num 4 188\n",
      "0 2\n",
      "9 14 58\n",
      "checkcorrect 8 8 real score 0.2447445958852768 Hits@1 0.6666666666666666 Hits@3 1.0 Hits@10 1.0 MRR 0.8333333333333334 cur_rank 1 abs_cur_rank 1 total_num 5 188\n",
      "9 30\n",
      "9 22 9\n",
      "checkcorrect 8 8 real score 0.5786192186176777 Hits@1 0.5714285714285714 Hits@3 1.0 Hits@10 1.0 MRR 0.7857142857142857 cur_rank 1 abs_cur_rank 1 total_num 6 188\n",
      "0 1\n",
      "9 17 66\n",
      "checkcorrect 0 0 real score 0.7117045938968658 Hits@1 0.625 Hits@3 1.0 Hits@10 1.0 MRR 0.8125 cur_rank 0 abs_cur_rank 0 total_num 7 188\n",
      "9 54\n",
      "9 30 7\n",
      "checkcorrect 8 8 real score 0.45192593112587925 Hits@1 0.5555555555555556 Hits@3 1.0 Hits@10 1.0 MRR 0.7777777777777778 cur_rank 1 abs_cur_rank 1 total_num 8 188\n",
      "0 1\n",
      "9 24 7\n",
      "checkcorrect 0 0 real score 0.6424512058496475 Hits@1 0.6 Hits@3 1.0 Hits@10 1.0 MRR 0.8 cur_rank 0 abs_cur_rank 0 total_num 9 188\n",
      "0 1\n",
      "9 16 12\n",
      "checkcorrect 0 0 real score 0.6802263587713242 Hits@1 0.6363636363636364 Hits@3 1.0 Hits@10 1.0 MRR 0.8181818181818182 cur_rank 0 abs_cur_rank 0 total_num 10 188\n",
      "0 0\n",
      "0 5 2\n",
      "checkcorrect 0 0 real score 0.0 Hits@1 0.6666666666666666 Hits@3 1.0 Hits@10 1.0 MRR 0.8333333333333334 cur_rank 0 abs_cur_rank 0 total_num 11 188\n",
      "9 12\n",
      "9 25 58\n",
      "checkcorrect 0 0 real score 1.527194932103157 Hits@1 0.6923076923076923 Hits@3 1.0 Hits@10 1.0 MRR 0.8461538461538461 cur_rank 0 abs_cur_rank 0 total_num 12 188\n",
      "0 1\n",
      "9 31 17\n",
      "checkcorrect 0 0 real score 0.733286690711975 Hits@1 0.7142857142857143 Hits@3 1.0 Hits@10 1.0 MRR 0.8571428571428571 cur_rank 0 abs_cur_rank 0 total_num 13 188\n",
      "0 1\n",
      "9 10 26\n",
      "checkcorrect 0 0 real score 0.7176901489496231 Hits@1 0.7333333333333333 Hits@3 1.0 Hits@10 1.0 MRR 0.8666666666666667 cur_rank 0 abs_cur_rank 0 total_num 14 188\n",
      "9 102\n",
      "9 26 20\n",
      "checkcorrect 8 8 real score 1.0736517921090125 Hits@1 0.6875 Hits@3 1.0 Hits@10 1.0 MRR 0.84375 cur_rank 1 abs_cur_rank 1 total_num 15 188\n",
      "9 150\n",
      "9 60 53\n",
      "checkcorrect 8 8 real score 1.231460502743721 Hits@1 0.7058823529411765 Hits@3 1.0 Hits@10 1.0 MRR 0.8529411764705882 cur_rank 0 abs_cur_rank 0 total_num 16 188\n",
      "9 91\n",
      "9 41 27\n",
      "checkcorrect 0 0 real score 1.5162324219942094 Hits@1 0.7222222222222222 Hits@3 1.0 Hits@10 1.0 MRR 0.8611111111111112 cur_rank 0 abs_cur_rank 0 total_num 17 188\n",
      "9 150\n",
      "9 34 36\n",
      "checkcorrect 8 8 real score 1.1822226032614709 Hits@1 0.7368421052631579 Hits@3 1.0 Hits@10 1.0 MRR 0.868421052631579 cur_rank 0 abs_cur_rank 0 total_num 18 188\n",
      "0 1\n",
      "9 14 38\n",
      "checkcorrect 0 0 real score 0.6698615938425064 Hits@1 0.75 Hits@3 1.0 Hits@10 1.0 MRR 0.875 cur_rank 0 abs_cur_rank 0 total_num 19 188\n",
      "9 22\n",
      "9 50 18\n",
      "checkcorrect 8 8 real score 1.6379692256450653 Hits@1 0.7619047619047619 Hits@3 1.0 Hits@10 1.0 MRR 0.8809523809523809 cur_rank 0 abs_cur_rank 0 total_num 20 188\n",
      "9 17\n",
      "9 26 26\n",
      "checkcorrect 6 6 real score 0.12897290382534266 Hits@1 0.7272727272727273 Hits@3 1.0 Hits@10 1.0 MRR 0.856060606060606 cur_rank 2 abs_cur_rank 2 total_num 21 188\n",
      "0 1\n",
      "9 9 24\n",
      "checkcorrect 0 0 real score 0.6215266160666942 Hits@1 0.7391304347826086 Hits@3 1.0 Hits@10 1.0 MRR 0.8623188405797101 cur_rank 0 abs_cur_rank 0 total_num 22 188\n",
      "0 1\n",
      "9 8 20\n",
      "checkcorrect 0 0 real score 0.6231523931026459 Hits@1 0.75 Hits@3 1.0 Hits@10 1.0 MRR 0.8680555555555555 cur_rank 0 abs_cur_rank 0 total_num 23 188\n",
      "9 34\n",
      "9 64 37\n",
      "checkcorrect 0 0 real score 1.5489821434020996 Hits@1 0.76 Hits@3 1.0 Hits@10 1.0 MRR 0.8733333333333333 cur_rank 0 abs_cur_rank 0 total_num 24 188\n",
      "9 150\n",
      "9 83 80\n",
      "checkcorrect 0 0 real score 1.4192194283008575 Hits@1 0.7692307692307693 Hits@3 1.0 Hits@10 1.0 MRR 0.8782051282051282 cur_rank 0 abs_cur_rank 0 total_num 25 188\n",
      "9 72\n",
      "9 23 36\n",
      "checkcorrect 0 0 real score 1.6360277116298676 Hits@1 0.7777777777777778 Hits@3 1.0 Hits@10 1.0 MRR 0.882716049382716 cur_rank 0 abs_cur_rank 0 total_num 26 188\n",
      "9 9\n",
      "9 21 16\n",
      "checkcorrect 0 0 real score 1.464030572772026 Hits@1 0.7857142857142857 Hits@3 1.0 Hits@10 1.0 MRR 0.8869047619047619 cur_rank 0 abs_cur_rank 0 total_num 27 188\n",
      "9 19\n",
      "9 21 39\n",
      "checkcorrect 0 0 real score 1.576208087801933 Hits@1 0.7931034482758621 Hits@3 1.0 Hits@10 1.0 MRR 0.8908045977011494 cur_rank 0 abs_cur_rank 0 total_num 28 188\n",
      "9 4\n",
      "9 28 20\n",
      "checkcorrect 8 8 real score 0.870386077463627 Hits@1 0.7666666666666667 Hits@3 1.0 Hits@10 1.0 MRR 0.8777777777777778 cur_rank 1 abs_cur_rank 1 total_num 29 188\n",
      "0 0\n",
      "9 5 7\n",
      "checkcorrect 8 8 real score 0.3972837895154953 Hits@1 0.7741935483870968 Hits@3 1.0 Hits@10 1.0 MRR 0.8817204301075269 cur_rank 0 abs_cur_rank 0 total_num 30 188\n",
      "0 0\n",
      "0 33 2\n",
      "checkcorrect 0 0 real score 0.0 Hits@1 0.78125 Hits@3 1.0 Hits@10 1.0 MRR 0.8854166666666666 cur_rank 0 abs_cur_rank 0 total_num 31 188\n",
      "9 106\n",
      "9 58 32\n",
      "checkcorrect 0 0 real score 1.6077230393886566 Hits@1 0.7878787878787878 Hits@3 1.0 Hits@10 1.0 MRR 0.8888888888888888 cur_rank 0 abs_cur_rank 0 total_num 32 188\n",
      "9 38\n",
      "9 16 21\n",
      "checkcorrect 0 0 real score 1.8088001310825348 Hits@1 0.7941176470588235 Hits@3 1.0 Hits@10 1.0 MRR 0.892156862745098 cur_rank 0 abs_cur_rank 0 total_num 33 188\n",
      "9 150\n",
      "9 11 47\n",
      "checkcorrect 8 8 real score 1.174575650691986 Hits@1 0.7714285714285715 Hits@3 1.0 Hits@10 1.0 MRR 0.8809523809523809 cur_rank 1 abs_cur_rank 1 total_num 34 188\n",
      "9 54\n",
      "9 16 36\n",
      "checkcorrect 0 0 real score 1.4637016028165817 Hits@1 0.7777777777777778 Hits@3 1.0 Hits@10 1.0 MRR 0.8842592592592592 cur_rank 0 abs_cur_rank 0 total_num 35 188\n",
      "0 1\n",
      "9 32 14\n",
      "checkcorrect 0 0 real score 0.6509495288133621 Hits@1 0.7837837837837838 Hits@3 1.0 Hits@10 1.0 MRR 0.8873873873873872 cur_rank 0 abs_cur_rank 0 total_num 36 188\n",
      "0 0\n",
      "9 14 4\n",
      "checkcorrect 8 8 real score 0.1564189985394478 Hits@1 0.7631578947368421 Hits@3 1.0 Hits@10 1.0 MRR 0.8771929824561402 cur_rank 1 abs_cur_rank 1 total_num 37 188\n",
      "9 11\n",
      "9 23 36\n",
      "checkcorrect 0 0 real score 1.5317259728908539 Hits@1 0.7692307692307693 Hits@3 1.0 Hits@10 1.0 MRR 0.8803418803418802 cur_rank 0 abs_cur_rank 0 total_num 38 188\n",
      "0 1\n",
      "9 9 10\n",
      "checkcorrect 0 0 real score 0.6562988728284835 Hits@1 0.775 Hits@3 1.0 Hits@10 1.0 MRR 0.8833333333333332 cur_rank 0 abs_cur_rank 0 total_num 39 188\n",
      "0 1\n",
      "9 7 11\n",
      "checkcorrect 0 0 real score 0.5082248747348785 Hits@1 0.7804878048780488 Hits@3 1.0 Hits@10 1.0 MRR 0.8861788617886178 cur_rank 0 abs_cur_rank 0 total_num 40 188\n",
      "9 13\n",
      "9 26 25\n",
      "checkcorrect 0 0 real score 1.6496676683425902 Hits@1 0.7857142857142857 Hits@3 1.0 Hits@10 1.0 MRR 0.8888888888888887 cur_rank 0 abs_cur_rank 0 total_num 41 188\n",
      "9 101\n",
      "9 45 49\n",
      "checkcorrect 0 0 real score 1.6840933144092558 Hits@1 0.7906976744186046 Hits@3 1.0 Hits@10 1.0 MRR 0.8914728682170542 cur_rank 0 abs_cur_rank 0 total_num 42 188\n",
      "9 70\n",
      "9 24 23\n",
      "checkcorrect 0 0 real score 1.7566312789916991 Hits@1 0.7954545454545454 Hits@3 1.0 Hits@10 1.0 MRR 0.8939393939393938 cur_rank 0 abs_cur_rank 0 total_num 43 188\n",
      "9 38\n",
      "9 21 16\n",
      "checkcorrect 0 0 real score 1.6892922282218934 Hits@1 0.8 Hits@3 1.0 Hits@10 1.0 MRR 0.8962962962962961 cur_rank 0 abs_cur_rank 0 total_num 44 188\n",
      "9 130\n",
      "9 98 69\n",
      "checkcorrect 0 0 real score 1.6714318215847015 Hits@1 0.8043478260869565 Hits@3 1.0 Hits@10 1.0 MRR 0.898550724637681 cur_rank 0 abs_cur_rank 0 total_num 45 188\n",
      "0 1\n",
      "9 49 25\n",
      "checkcorrect 0 0 real score 0.7471290588378906 Hits@1 0.8085106382978723 Hits@3 1.0 Hits@10 1.0 MRR 0.9007092198581559 cur_rank 0 abs_cur_rank 0 total_num 46 188\n",
      "9 57\n",
      "9 19 13\n",
      "checkcorrect 0 0 real score 1.6239097625017167 Hits@1 0.8125 Hits@3 1.0 Hits@10 1.0 MRR 0.9027777777777777 cur_rank 0 abs_cur_rank 0 total_num 47 188\n",
      "9 122\n",
      "9 38 57\n",
      "checkcorrect 8 8 real score 1.1189105004072188 Hits@1 0.7959183673469388 Hits@3 1.0 Hits@10 1.0 MRR 0.8945578231292516 cur_rank 1 abs_cur_rank 1 total_num 48 188\n",
      "0 0\n",
      "0 2 2\n",
      "checkcorrect 8 8 real score 0.0 Hits@1 0.78 Hits@3 0.98 Hits@10 1.0 MRR 0.8806666666666666 cur_rank 4 abs_cur_rank 4 total_num 49 188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 38\n",
      "9 18 8\n",
      "checkcorrect 0 0 real score 1.2535340383648874 Hits@1 0.7843137254901961 Hits@3 0.9803921568627451 Hits@10 1.0 MRR 0.8830065359477124 cur_rank 0 abs_cur_rank 0 total_num 50 188\n",
      "9 54\n",
      "9 23 20\n",
      "checkcorrect 0 0 real score 1.7500863373279572 Hits@1 0.7884615384615384 Hits@3 0.9807692307692307 Hits@10 1.0 MRR 0.8852564102564102 cur_rank 0 abs_cur_rank 0 total_num 51 188\n",
      "9 5\n",
      "9 71 28\n",
      "checkcorrect 0 0 real score 1.5344414383172988 Hits@1 0.7924528301886793 Hits@3 0.9811320754716981 Hits@10 1.0 MRR 0.8874213836477987 cur_rank 0 abs_cur_rank 0 total_num 52 188\n",
      "9 53\n",
      "9 35 13\n",
      "checkcorrect 0 0 real score 1.4713187865912913 Hits@1 0.7962962962962963 Hits@3 0.9814814814814815 Hits@10 1.0 MRR 0.8895061728395062 cur_rank 0 abs_cur_rank 0 total_num 53 188\n",
      "9 4\n",
      "9 23 22\n",
      "checkcorrect 10 10 real score 1.7709940746426582 Hits@1 0.8 Hits@3 0.9818181818181818 Hits@10 1.0 MRR 0.8915151515151515 cur_rank 0 abs_cur_rank 0 total_num 54 188\n",
      "9 86\n",
      "9 32 19\n",
      "checkcorrect 0 0 real score 1.4118973553180694 Hits@1 0.8035714285714286 Hits@3 0.9821428571428571 Hits@10 1.0 MRR 0.8934523809523809 cur_rank 0 abs_cur_rank 0 total_num 55 188\n",
      "9 73\n",
      "9 24 18\n",
      "checkcorrect 0 0 real score 1.6595102936029433 Hits@1 0.8070175438596491 Hits@3 0.9824561403508771 Hits@10 1.0 MRR 0.8953216374269005 cur_rank 0 abs_cur_rank 0 total_num 56 188\n",
      "9 13\n",
      "9 25 16\n",
      "checkcorrect 0 0 real score 1.6059784591197968 Hits@1 0.8103448275862069 Hits@3 0.9827586206896551 Hits@10 1.0 MRR 0.8971264367816092 cur_rank 0 abs_cur_rank 0 total_num 57 188\n",
      "0 0\n",
      "0 3 2\n",
      "checkcorrect 2 2 real score 0.0 Hits@1 0.7966101694915254 Hits@3 0.9830508474576272 Hits@10 1.0 MRR 0.8903954802259887 cur_rank 1 abs_cur_rank 1 total_num 58 188\n",
      "0 2\n",
      "9 43 9\n",
      "checkcorrect 0 0 real score 0.32285005822777746 Hits@1 0.8 Hits@3 0.9833333333333333 Hits@10 1.0 MRR 0.8922222222222221 cur_rank 0 abs_cur_rank 0 total_num 59 188\n",
      "0 1\n",
      "9 12 38\n",
      "checkcorrect 0 0 real score 0.6931261956691742 Hits@1 0.8032786885245902 Hits@3 0.9836065573770492 Hits@10 1.0 MRR 0.8939890710382513 cur_rank 0 abs_cur_rank 0 total_num 60 188\n",
      "9 81\n",
      "9 24 22\n",
      "checkcorrect 0 0 real score 1.737787139415741 Hits@1 0.8064516129032258 Hits@3 0.9838709677419355 Hits@10 1.0 MRR 0.8956989247311827 cur_rank 0 abs_cur_rank 0 total_num 61 188\n",
      "0 1\n",
      "9 7 18\n",
      "checkcorrect 0 0 real score 0.7377564787864686 Hits@1 0.8095238095238095 Hits@3 0.9841269841269841 Hits@10 1.0 MRR 0.8973544973544973 cur_rank 0 abs_cur_rank 0 total_num 62 188\n",
      "0 0\n",
      "0 27 1\n",
      "checkcorrect 8 8 real score 0.0 Hits@1 0.796875 Hits@3 0.96875 Hits@10 1.0 MRR 0.8864583333333333 cur_rank 4 abs_cur_rank 4 total_num 63 188\n",
      "9 12\n",
      "9 58 25\n",
      "checkcorrect 0 0 real score 1.4159194812178613 Hits@1 0.8 Hits@3 0.9692307692307692 Hits@10 1.0 MRR 0.8882051282051282 cur_rank 0 abs_cur_rank 0 total_num 64 188\n",
      "9 39\n",
      "9 58 32\n",
      "checkcorrect 0 0 real score 1.6194710284471512 Hits@1 0.803030303030303 Hits@3 0.9696969696969697 Hits@10 1.0 MRR 0.88989898989899 cur_rank 0 abs_cur_rank 0 total_num 65 188\n",
      "0 1\n",
      "9 41 19\n",
      "checkcorrect 0 0 real score 0.7472785651683808 Hits@1 0.8059701492537313 Hits@3 0.9701492537313433 Hits@10 1.0 MRR 0.891542288557214 cur_rank 0 abs_cur_rank 0 total_num 66 188\n",
      "0 1\n",
      "9 7 16\n",
      "checkcorrect 0 0 real score 0.654996320605278 Hits@1 0.8088235294117647 Hits@3 0.9705882352941176 Hits@10 1.0 MRR 0.8931372549019608 cur_rank 0 abs_cur_rank 0 total_num 67 188\n",
      "9 3\n",
      "9 18 24\n",
      "checkcorrect 0 0 real score 1.527984408289194 Hits@1 0.8115942028985508 Hits@3 0.9710144927536232 Hits@10 1.0 MRR 0.8946859903381643 cur_rank 0 abs_cur_rank 0 total_num 68 188\n",
      "9 97\n",
      "9 69 31\n",
      "checkcorrect 0 0 real score 1.5987285107374192 Hits@1 0.8142857142857143 Hits@3 0.9714285714285714 Hits@10 1.0 MRR 0.8961904761904762 cur_rank 0 abs_cur_rank 0 total_num 69 188\n",
      "9 136\n",
      "9 23 33\n",
      "checkcorrect 0 0 real score 1.4541923433542252 Hits@1 0.8169014084507042 Hits@3 0.971830985915493 Hits@10 1.0 MRR 0.8976525821596244 cur_rank 0 abs_cur_rank 0 total_num 70 188\n",
      "0 1\n",
      "9 11 48\n",
      "checkcorrect 0 0 real score 0.6999289274215699 Hits@1 0.8194444444444444 Hits@3 0.9722222222222222 Hits@10 1.0 MRR 0.8990740740740741 cur_rank 0 abs_cur_rank 0 total_num 71 188\n",
      "0 1\n",
      "9 14 45\n",
      "checkcorrect 0 0 real score 0.6633407533168793 Hits@1 0.821917808219178 Hits@3 0.9726027397260274 Hits@10 1.0 MRR 0.9004566210045662 cur_rank 0 abs_cur_rank 0 total_num 72 188\n",
      "9 5\n",
      "9 29 29\n",
      "checkcorrect 10 10 real score 0.7584616061300039 Hits@1 0.8108108108108109 Hits@3 0.972972972972973 Hits@10 1.0 MRR 0.8927927927927928 cur_rank 2 abs_cur_rank 2 total_num 73 188\n",
      "9 150\n",
      "9 60 44\n",
      "checkcorrect 0 0 real score 1.7045018523931503 Hits@1 0.8133333333333334 Hits@3 0.9733333333333334 Hits@10 1.0 MRR 0.8942222222222221 cur_rank 0 abs_cur_rank 0 total_num 74 188\n",
      "0 1\n",
      "9 24 11\n",
      "checkcorrect 0 0 real score 0.5939670085906983 Hits@1 0.8157894736842105 Hits@3 0.9736842105263158 Hits@10 1.0 MRR 0.8956140350877192 cur_rank 0 abs_cur_rank 0 total_num 75 188\n",
      "9 50\n",
      "9 36 16\n",
      "checkcorrect 0 0 real score 1.4675512105226516 Hits@1 0.8181818181818182 Hits@3 0.974025974025974 Hits@10 1.0 MRR 0.896969696969697 cur_rank 0 abs_cur_rank 0 total_num 76 188\n",
      "0 1\n",
      "9 33 22\n",
      "checkcorrect 0 0 real score 0.6232778787612915 Hits@1 0.8205128205128205 Hits@3 0.9743589743589743 Hits@10 1.0 MRR 0.8982905982905982 cur_rank 0 abs_cur_rank 0 total_num 77 188\n",
      "9 149\n",
      "9 31 43\n",
      "checkcorrect 0 0 real score 1.585110718011856 Hits@1 0.8227848101265823 Hits@3 0.9746835443037974 Hits@10 1.0 MRR 0.8995780590717299 cur_rank 0 abs_cur_rank 0 total_num 78 188\n",
      "0 2\n",
      "9 23 11\n",
      "checkcorrect 0 0 real score 0.6441745400428772 Hits@1 0.825 Hits@3 0.975 Hits@10 1.0 MRR 0.9008333333333333 cur_rank 0 abs_cur_rank 0 total_num 79 188\n",
      "0 1\n",
      "9 11 24\n",
      "checkcorrect 0 0 real score 0.6720864295959472 Hits@1 0.8271604938271605 Hits@3 0.9753086419753086 Hits@10 1.0 MRR 0.9020576131687242 cur_rank 0 abs_cur_rank 0 total_num 80 188\n",
      "0 1\n",
      "9 14 38\n",
      "checkcorrect 0 0 real score 0.6903811097145081 Hits@1 0.8292682926829268 Hits@3 0.975609756097561 Hits@10 1.0 MRR 0.9032520325203252 cur_rank 0 abs_cur_rank 0 total_num 81 188\n",
      "9 41\n",
      "9 83 71\n",
      "checkcorrect 0 0 real score 1.7047539412975312 Hits@1 0.8313253012048193 Hits@3 0.9759036144578314 Hits@10 1.0 MRR 0.9044176706827308 cur_rank 0 abs_cur_rank 0 total_num 82 188\n",
      "9 33\n",
      "9 35 46\n",
      "checkcorrect 0 0 real score 1.5735977053642274 Hits@1 0.8333333333333334 Hits@3 0.9761904761904762 Hits@10 1.0 MRR 0.9055555555555556 cur_rank 0 abs_cur_rank 0 total_num 83 188\n",
      "0 1\n",
      "9 26 15\n",
      "checkcorrect 0 0 real score 0.5891757562756539 Hits@1 0.8352941176470589 Hits@3 0.9764705882352941 Hits@10 1.0 MRR 0.9066666666666666 cur_rank 0 abs_cur_rank 0 total_num 84 188\n",
      "9 54\n",
      "9 21 15\n",
      "checkcorrect 0 0 real score 1.3019806772470475 Hits@1 0.8372093023255814 Hits@3 0.9767441860465116 Hits@10 1.0 MRR 0.907751937984496 cur_rank 0 abs_cur_rank 0 total_num 85 188\n",
      "9 3\n",
      "9 14 7\n",
      "checkcorrect 0 0 real score 1.7299756467342378 Hits@1 0.8390804597701149 Hits@3 0.9770114942528736 Hits@10 1.0 MRR 0.9088122605363984 cur_rank 0 abs_cur_rank 0 total_num 86 188\n",
      "0 1\n",
      "9 8 10\n",
      "checkcorrect 0 0 real score 0.5347825914621354 Hits@1 0.8409090909090909 Hits@3 0.9772727272727273 Hits@10 1.0 MRR 0.9098484848484848 cur_rank 0 abs_cur_rank 0 total_num 87 188\n",
      "9 46\n",
      "9 42 64\n",
      "checkcorrect 0 0 real score 1.578922563791275 Hits@1 0.8426966292134831 Hits@3 0.9775280898876404 Hits@10 1.0 MRR 0.9108614232209737 cur_rank 0 abs_cur_rank 0 total_num 88 188\n",
      "9 58\n",
      "9 28 66\n",
      "checkcorrect 0 0 real score 1.4799200728535653 Hits@1 0.8444444444444444 Hits@3 0.9777777777777777 Hits@10 1.0 MRR 0.9118518518518518 cur_rank 0 abs_cur_rank 0 total_num 89 188\n",
      "9 124\n",
      "9 32 22\n",
      "checkcorrect 0 0 real score 1.7075432956218721 Hits@1 0.8461538461538461 Hits@3 0.978021978021978 Hits@10 1.0 MRR 0.9128205128205128 cur_rank 0 abs_cur_rank 0 total_num 90 188\n",
      "9 94\n",
      "9 22 22\n",
      "checkcorrect 0 0 real score 1.72243509888649 Hits@1 0.8478260869565217 Hits@3 0.9782608695652174 Hits@10 1.0 MRR 0.9137681159420289 cur_rank 0 abs_cur_rank 0 total_num 91 188\n",
      "0 2\n",
      "9 16 71\n",
      "checkcorrect 0 0 real score 0.6593846440315246 Hits@1 0.8494623655913979 Hits@3 0.978494623655914 Hits@10 1.0 MRR 0.914695340501792 cur_rank 0 abs_cur_rank 0 total_num 92 188\n",
      "0 1\n",
      "9 13 48\n",
      "checkcorrect 0 0 real score 0.7529690027236938 Hits@1 0.851063829787234 Hits@3 0.9787234042553191 Hits@10 1.0 MRR 0.9156028368794326 cur_rank 0 abs_cur_rank 0 total_num 93 188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 150\n",
      "9 12 13\n",
      "checkcorrect 0 0 real score 1.5491866767406464 Hits@1 0.8526315789473684 Hits@3 0.9789473684210527 Hits@10 1.0 MRR 0.9164912280701754 cur_rank 0 abs_cur_rank 0 total_num 94 188\n",
      "9 7\n",
      "9 26 9\n",
      "checkcorrect 0 0 real score 1.6799812585115432 Hits@1 0.8541666666666666 Hits@3 0.9791666666666666 Hits@10 1.0 MRR 0.9173611111111111 cur_rank 0 abs_cur_rank 0 total_num 95 188\n",
      "0 0\n",
      "0 28 1\n",
      "checkcorrect 0 0 real score 0.0 Hits@1 0.8556701030927835 Hits@3 0.979381443298969 Hits@10 1.0 MRR 0.9182130584192439 cur_rank 0 abs_cur_rank 0 total_num 96 188\n",
      "0 0\n",
      "9 32 5\n",
      "checkcorrect 8 8 real score 0.2664215698838234 Hits@1 0.8469387755102041 Hits@3 0.9795918367346939 Hits@10 1.0 MRR 0.9139455782312925 cur_rank 1 abs_cur_rank 1 total_num 97 188\n",
      "9 65\n",
      "9 27 34\n",
      "checkcorrect 0 0 real score 1.5753029331564905 Hits@1 0.8484848484848485 Hits@3 0.9797979797979798 Hits@10 1.0 MRR 0.9148148148148147 cur_rank 0 abs_cur_rank 0 total_num 98 188\n",
      "0 1\n",
      "9 15 46\n",
      "checkcorrect 0 0 real score 0.6504505783319473 Hits@1 0.85 Hits@3 0.98 Hits@10 1.0 MRR 0.9156666666666666 cur_rank 0 abs_cur_rank 0 total_num 99 188\n",
      "9 110\n",
      "9 28 53\n",
      "checkcorrect 0 0 real score 1.6359428286552429 Hits@1 0.8514851485148515 Hits@3 0.9801980198019802 Hits@10 1.0 MRR 0.9165016501650165 cur_rank 0 abs_cur_rank 0 total_num 100 188\n",
      "0 1\n",
      "9 61 35\n",
      "checkcorrect 0 0 real score 0.6480682253837585 Hits@1 0.8529411764705882 Hits@3 0.9803921568627451 Hits@10 1.0 MRR 0.9173202614379085 cur_rank 0 abs_cur_rank 0 total_num 101 188\n",
      "9 110\n",
      "9 12 66\n",
      "checkcorrect 8 8 real score 1.1219991363584996 Hits@1 0.8543689320388349 Hits@3 0.9805825242718447 Hits@10 1.0 MRR 0.9181229773462782 cur_rank 0 abs_cur_rank 0 total_num 102 188\n",
      "0 1\n",
      "9 6 15\n",
      "checkcorrect 0 0 real score 0.5171144653111697 Hits@1 0.8461538461538461 Hits@3 0.9807692307692307 Hits@10 1.0 MRR 0.9141025641025641 cur_rank 1 abs_cur_rank 1 total_num 103 188\n",
      "0 1\n",
      "9 19 23\n",
      "checkcorrect 0 0 real score 0.6073870182037353 Hits@1 0.8476190476190476 Hits@3 0.9809523809523809 Hits@10 1.0 MRR 0.9149206349206349 cur_rank 0 abs_cur_rank 0 total_num 104 188\n",
      "9 32\n",
      "9 22 39\n",
      "checkcorrect 0 0 real score 1.6101245611906052 Hits@1 0.8490566037735849 Hits@3 0.9811320754716981 Hits@10 1.0 MRR 0.9157232704402516 cur_rank 0 abs_cur_rank 0 total_num 105 188\n",
      "0 1\n",
      "9 66 19\n",
      "checkcorrect 10 10 real score 0.817459100484848 Hits@1 0.8504672897196262 Hits@3 0.9813084112149533 Hits@10 1.0 MRR 0.9165109034267912 cur_rank 0 abs_cur_rank 0 total_num 106 188\n",
      "0 1\n",
      "9 49 18\n",
      "checkcorrect 0 0 real score 0.5284277319908142 Hits@1 0.8425925925925926 Hits@3 0.9814814814814815 Hits@10 1.0 MRR 0.9126543209876543 cur_rank 1 abs_cur_rank 1 total_num 107 188\n",
      "9 22\n",
      "9 45 50\n",
      "checkcorrect 0 0 real score 1.5065730273723603 Hits@1 0.8440366972477065 Hits@3 0.981651376146789 Hits@10 1.0 MRR 0.9134556574923547 cur_rank 0 abs_cur_rank 0 total_num 108 188\n",
      "0 1\n",
      "9 20 9\n",
      "checkcorrect 0 0 real score 0.6080980956554413 Hits@1 0.8454545454545455 Hits@3 0.9818181818181818 Hits@10 1.0 MRR 0.9142424242424242 cur_rank 0 abs_cur_rank 0 total_num 109 188\n",
      "0 1\n",
      "9 23 11\n",
      "checkcorrect 10 10 real score 0.6310646593570709 Hits@1 0.8468468468468469 Hits@3 0.9819819819819819 Hits@10 1.0 MRR 0.915015015015015 cur_rank 0 abs_cur_rank 0 total_num 110 188\n",
      "0 1\n",
      "9 52 22\n",
      "checkcorrect 10 10 real score 0.8679198920726776 Hits@1 0.8482142857142857 Hits@3 0.9821428571428571 Hits@10 1.0 MRR 0.9157738095238095 cur_rank 0 abs_cur_rank 0 total_num 111 188\n",
      "0 1\n",
      "9 35 13\n",
      "checkcorrect 0 0 real score 0.6827412664890289 Hits@1 0.8495575221238938 Hits@3 0.9823008849557522 Hits@10 1.0 MRR 0.9165191740412979 cur_rank 0 abs_cur_rank 0 total_num 112 188\n",
      "9 30\n",
      "9 20 17\n",
      "checkcorrect 0 0 real score 1.5361566543579102 Hits@1 0.8508771929824561 Hits@3 0.9824561403508771 Hits@10 1.0 MRR 0.9172514619883041 cur_rank 0 abs_cur_rank 0 total_num 113 188\n",
      "9 112\n",
      "9 63 50\n",
      "checkcorrect 10 10 real score 1.8358274340629577 Hits@1 0.8521739130434782 Hits@3 0.9826086956521739 Hits@10 1.0 MRR 0.9179710144927536 cur_rank 0 abs_cur_rank 0 total_num 114 188\n",
      "0 1\n",
      "9 38 14\n",
      "checkcorrect 0 0 real score 0.6618900388479233 Hits@1 0.853448275862069 Hits@3 0.9827586206896551 Hits@10 1.0 MRR 0.9186781609195402 cur_rank 0 abs_cur_rank 0 total_num 115 188\n",
      "0 1\n",
      "9 19 18\n",
      "checkcorrect 0 0 real score 0.7050649940967559 Hits@1 0.8547008547008547 Hits@3 0.9829059829059829 Hits@10 1.0 MRR 0.9193732193732194 cur_rank 0 abs_cur_rank 0 total_num 116 188\n",
      "9 26\n",
      "9 19 13\n",
      "checkcorrect 0 0 real score 1.6134827584028244 Hits@1 0.8559322033898306 Hits@3 0.9830508474576272 Hits@10 1.0 MRR 0.9200564971751413 cur_rank 0 abs_cur_rank 0 total_num 117 188\n",
      "9 52\n",
      "9 37 20\n",
      "checkcorrect 8 8 real score 1.0842143565416336 Hits@1 0.8487394957983193 Hits@3 0.9831932773109243 Hits@10 1.0 MRR 0.9165266106442577 cur_rank 1 abs_cur_rank 1 total_num 118 188\n",
      "9 3\n",
      "9 17 25\n",
      "checkcorrect 0 0 real score 1.6292072892189027 Hits@1 0.85 Hits@3 0.9833333333333333 Hits@10 1.0 MRR 0.9172222222222222 cur_rank 0 abs_cur_rank 0 total_num 119 188\n",
      "9 6\n",
      "9 9 10\n",
      "checkcorrect 8 8 real score 1.3372221261262893 Hits@1 0.8512396694214877 Hits@3 0.9834710743801653 Hits@10 1.0 MRR 0.9179063360881542 cur_rank 0 abs_cur_rank 0 total_num 120 188\n",
      "9 25\n",
      "9 26 25\n",
      "checkcorrect 0 0 real score 1.7565877556800842 Hits@1 0.8524590163934426 Hits@3 0.9836065573770492 Hits@10 1.0 MRR 0.9185792349726776 cur_rank 0 abs_cur_rank 0 total_num 121 188\n",
      "9 14\n",
      "9 16 22\n",
      "checkcorrect 0 0 real score 1.6286795079708098 Hits@1 0.8536585365853658 Hits@3 0.983739837398374 Hits@10 1.0 MRR 0.919241192411924 cur_rank 0 abs_cur_rank 0 total_num 122 188\n",
      "9 54\n",
      "9 20 23\n",
      "checkcorrect 0 0 real score 1.7223635077476502 Hits@1 0.8548387096774194 Hits@3 0.9838709677419355 Hits@10 1.0 MRR 0.9198924731182795 cur_rank 0 abs_cur_rank 0 total_num 123 188\n",
      "9 52\n",
      "9 19 28\n",
      "checkcorrect 0 0 real score 1.5514747381210325 Hits@1 0.856 Hits@3 0.984 Hits@10 1.0 MRR 0.9205333333333333 cur_rank 0 abs_cur_rank 0 total_num 124 188\n",
      "0 1\n",
      "9 46 14\n",
      "checkcorrect 12 12 real score 0.40372155606746674 Hits@1 0.8492063492063492 Hits@3 0.9841269841269841 Hits@10 1.0 MRR 0.9171957671957671 cur_rank 1 abs_cur_rank 1 total_num 125 188\n",
      "0 1\n",
      "0 2 2\n",
      "checkcorrect 10 10 real score 0.0 Hits@1 0.84251968503937 Hits@3 0.9763779527559056 Hits@10 1.0 MRR 0.9112860892388451 cur_rank 5 abs_cur_rank 5 total_num 126 188\n",
      "9 5\n",
      "9 25 26\n",
      "checkcorrect 0 0 real score 1.5960208147764205 Hits@1 0.84375 Hits@3 0.9765625 Hits@10 1.0 MRR 0.9119791666666667 cur_rank 0 abs_cur_rank 0 total_num 127 188\n",
      "9 150\n",
      "9 20 53\n",
      "checkcorrect 8 8 real score 1.3625225096940994 Hits@1 0.8449612403100775 Hits@3 0.9767441860465116 Hits@10 1.0 MRR 0.9126614987080104 cur_rank 0 abs_cur_rank 0 total_num 128 188\n",
      "0 0\n",
      "9 15 5\n",
      "checkcorrect 8 8 real score 0.3710731744766235 Hits@1 0.8461538461538461 Hits@3 0.9769230769230769 Hits@10 1.0 MRR 0.9133333333333333 cur_rank 0 abs_cur_rank 0 total_num 129 188\n",
      "9 75\n",
      "9 27 41\n",
      "checkcorrect 0 0 real score 1.5896996140480042 Hits@1 0.8473282442748091 Hits@3 0.9770992366412213 Hits@10 1.0 MRR 0.9139949109414758 cur_rank 0 abs_cur_rank 0 total_num 130 188\n",
      "9 106\n",
      "9 33 25\n",
      "checkcorrect 0 0 real score 1.6061910301446916 Hits@1 0.8484848484848485 Hits@3 0.9772727272727273 Hits@10 1.0 MRR 0.9146464646464647 cur_rank 0 abs_cur_rank 0 total_num 131 188\n",
      "9 7\n",
      "9 9 16\n",
      "checkcorrect 0 0 real score 1.1293725684285163 Hits@1 0.849624060150376 Hits@3 0.9774436090225563 Hits@10 1.0 MRR 0.9152882205513785 cur_rank 0 abs_cur_rank 0 total_num 132 188\n",
      "9 79\n",
      "9 27 52\n",
      "checkcorrect 0 0 real score 1.3786236882209777 Hits@1 0.8507462686567164 Hits@3 0.9776119402985075 Hits@10 1.0 MRR 0.9159203980099503 cur_rank 0 abs_cur_rank 0 total_num 133 188\n",
      "0 0\n",
      "9 44 16\n",
      "checkcorrect 0 0 real score 0.5629496872425079 Hits@1 0.8518518518518519 Hits@3 0.9777777777777777 Hits@10 1.0 MRR 0.9165432098765433 cur_rank 0 abs_cur_rank 0 total_num 134 188\n",
      "0 1\n",
      "9 26 32\n",
      "checkcorrect 0 0 real score 0.6122008115053177 Hits@1 0.8529411764705882 Hits@3 0.9779411764705882 Hits@10 1.0 MRR 0.917156862745098 cur_rank 0 abs_cur_rank 0 total_num 135 188\n",
      "9 106\n",
      "9 47 31\n",
      "checkcorrect 0 0 real score 1.6978628277778625 Hits@1 0.8540145985401459 Hits@3 0.9781021897810219 Hits@10 1.0 MRR 0.9177615571776155 cur_rank 0 abs_cur_rank 0 total_num 136 188\n",
      "0 0\n",
      "0 51 1\n",
      "checkcorrect 0 0 real score 0.0 Hits@1 0.855072463768116 Hits@3 0.9782608695652174 Hits@10 1.0 MRR 0.9183574879227053 cur_rank 0 abs_cur_rank 0 total_num 137 188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 45\n",
      "9 28 37\n",
      "checkcorrect 0 0 real score 1.6402869790792465 Hits@1 0.8561151079136691 Hits@3 0.9784172661870504 Hits@10 1.0 MRR 0.9189448441247002 cur_rank 0 abs_cur_rank 0 total_num 138 188\n",
      "0 1\n",
      "9 45 22\n",
      "checkcorrect 0 0 real score 0.6212806850671768 Hits@1 0.8571428571428571 Hits@3 0.9785714285714285 Hits@10 1.0 MRR 0.9195238095238096 cur_rank 0 abs_cur_rank 0 total_num 139 188\n",
      "9 93\n",
      "9 31 26\n",
      "checkcorrect 0 0 real score 1.6512427419424056 Hits@1 0.8581560283687943 Hits@3 0.9787234042553191 Hits@10 1.0 MRR 0.9200945626477542 cur_rank 0 abs_cur_rank 0 total_num 140 188\n",
      "9 87\n",
      "9 39 44\n",
      "checkcorrect 0 0 real score 1.5928798407316207 Hits@1 0.8591549295774648 Hits@3 0.9788732394366197 Hits@10 1.0 MRR 0.9206572769953053 cur_rank 0 abs_cur_rank 0 total_num 141 188\n",
      "0 2\n",
      "9 14 9\n",
      "checkcorrect 0 0 real score 0.46829487979412077 Hits@1 0.8531468531468531 Hits@3 0.9790209790209791 Hits@10 1.0 MRR 0.9177156177156178 cur_rank 1 abs_cur_rank 1 total_num 142 188\n",
      "9 132\n",
      "9 58 37\n",
      "checkcorrect 0 0 real score 1.661644023656845 Hits@1 0.8541666666666666 Hits@3 0.9791666666666666 Hits@10 1.0 MRR 0.9182870370370372 cur_rank 0 abs_cur_rank 0 total_num 143 188\n",
      "9 108\n",
      "9 27 36\n",
      "checkcorrect 0 0 real score 1.6012095868587495 Hits@1 0.8551724137931035 Hits@3 0.9793103448275862 Hits@10 1.0 MRR 0.9188505747126438 cur_rank 0 abs_cur_rank 0 total_num 144 188\n",
      "0 0\n",
      "0 1 14\n",
      "checkcorrect 0 0 real score 0.0 Hits@1 0.8561643835616438 Hits@3 0.9794520547945206 Hits@10 1.0 MRR 0.919406392694064 cur_rank 0 abs_cur_rank 0 total_num 145 188\n",
      "9 11\n",
      "9 39 52\n",
      "checkcorrect 0 0 real score 1.7578512668609618 Hits@1 0.8571428571428571 Hits@3 0.9795918367346939 Hits@10 1.0 MRR 0.9199546485260772 cur_rank 0 abs_cur_rank 0 total_num 146 188\n",
      "9 30\n",
      "9 42 32\n",
      "checkcorrect 0 0 real score 1.648819163441658 Hits@1 0.8581081081081081 Hits@3 0.9797297297297297 Hits@10 1.0 MRR 0.9204954954954956 cur_rank 0 abs_cur_rank 0 total_num 147 188\n",
      "0 1\n",
      "9 28 13\n",
      "checkcorrect 0 0 real score 0.7102257907390594 Hits@1 0.8590604026845637 Hits@3 0.9798657718120806 Hits@10 1.0 MRR 0.9210290827740493 cur_rank 0 abs_cur_rank 0 total_num 148 188\n",
      "9 43\n",
      "9 71 50\n",
      "checkcorrect 10 10 real score 0.1775833934545517 Hits@1 0.8533333333333334 Hits@3 0.9733333333333334 Hits@10 1.0 MRR 0.9165555555555557 cur_rank 3 abs_cur_rank 3 total_num 149 188\n",
      "9 101\n",
      "9 88 48\n",
      "checkcorrect 0 0 real score 1.549162384867668 Hits@1 0.8543046357615894 Hits@3 0.9735099337748344 Hits@10 1.0 MRR 0.9171081677704195 cur_rank 0 abs_cur_rank 0 total_num 150 188\n",
      "0 1\n",
      "9 16 29\n",
      "checkcorrect 0 0 real score 0.645219087600708 Hits@1 0.8552631578947368 Hits@3 0.9736842105263158 Hits@10 1.0 MRR 0.91765350877193 cur_rank 0 abs_cur_rank 0 total_num 151 188\n",
      "0 1\n",
      "9 40 39\n",
      "checkcorrect 0 0 real score 0.5219604447484016 Hits@1 0.8496732026143791 Hits@3 0.9738562091503268 Hits@10 1.0 MRR 0.9149237472766886 cur_rank 1 abs_cur_rank 1 total_num 152 188\n",
      "9 45\n",
      "9 32 49\n",
      "checkcorrect 0 0 real score 1.6301788061857225 Hits@1 0.8506493506493507 Hits@3 0.974025974025974 Hits@10 1.0 MRR 0.9154761904761906 cur_rank 0 abs_cur_rank 0 total_num 153 188\n",
      "9 150\n",
      "9 10 20\n",
      "checkcorrect 8 8 real score 0.5574166515376419 Hits@1 0.8451612903225807 Hits@3 0.9741935483870968 Hits@10 1.0 MRR 0.9127956989247313 cur_rank 1 abs_cur_rank 1 total_num 154 188\n",
      "9 133\n",
      "9 32 58\n",
      "checkcorrect 0 0 real score 1.6877112567424775 Hits@1 0.8461538461538461 Hits@3 0.9743589743589743 Hits@10 1.0 MRR 0.9133547008547009 cur_rank 0 abs_cur_rank 0 total_num 155 188\n",
      "9 14\n",
      "9 28 36\n",
      "checkcorrect 0 0 real score 1.6523512691259383 Hits@1 0.8471337579617835 Hits@3 0.9745222929936306 Hits@10 1.0 MRR 0.9139065817409767 cur_rank 0 abs_cur_rank 0 total_num 156 188\n",
      "0 1\n",
      "9 38 12\n",
      "checkcorrect 0 0 real score 0.6805837363004684 Hits@1 0.8481012658227848 Hits@3 0.9746835443037974 Hits@10 1.0 MRR 0.914451476793249 cur_rank 0 abs_cur_rank 0 total_num 157 188\n",
      "0 1\n",
      "9 13 35\n",
      "checkcorrect 0 0 real score 0.7284045577049255 Hits@1 0.8490566037735849 Hits@3 0.9748427672955975 Hits@10 1.0 MRR 0.9149895178197066 cur_rank 0 abs_cur_rank 0 total_num 158 188\n",
      "9 13\n",
      "9 42 28\n",
      "checkcorrect 0 0 real score 1.4768144220113755 Hits@1 0.85 Hits@3 0.975 Hits@10 1.0 MRR 0.9155208333333335 cur_rank 0 abs_cur_rank 0 total_num 159 188\n",
      "0 1\n",
      "9 15 45\n",
      "checkcorrect 10 10 real score 0.6066299065947532 Hits@1 0.8509316770186336 Hits@3 0.9751552795031055 Hits@10 1.0 MRR 0.9160455486542444 cur_rank 0 abs_cur_rank 0 total_num 160 188\n",
      "9 57\n",
      "9 16 20\n",
      "checkcorrect 0 0 real score 1.6313146322965622 Hits@1 0.8518518518518519 Hits@3 0.9753086419753086 Hits@10 1.0 MRR 0.9165637860082305 cur_rank 0 abs_cur_rank 0 total_num 161 188\n",
      "0 0\n",
      "0 14 1\n",
      "checkcorrect 0 0 real score 0.0 Hits@1 0.852760736196319 Hits@3 0.9754601226993865 Hits@10 1.0 MRR 0.917075664621677 cur_rank 0 abs_cur_rank 0 total_num 162 188\n",
      "0 0\n",
      "0 15 1\n",
      "checkcorrect 8 8 real score 0.0 Hits@1 0.8475609756097561 Hits@3 0.9695121951219512 Hits@10 1.0 MRR 0.9127032520325203 cur_rank 4 abs_cur_rank 4 total_num 163 188\n",
      "0 1\n",
      "9 88 22\n",
      "checkcorrect 0 0 real score 0.6686978280544281 Hits@1 0.8484848484848485 Hits@3 0.9696969696969697 Hits@10 1.0 MRR 0.9132323232323233 cur_rank 0 abs_cur_rank 0 total_num 164 188\n",
      "0 0\n",
      "9 36 7\n",
      "checkcorrect 0 0 real score 0.6860753297805786 Hits@1 0.8493975903614458 Hits@3 0.9698795180722891 Hits@10 1.0 MRR 0.9137550200803213 cur_rank 0 abs_cur_rank 0 total_num 165 188\n",
      "9 74\n",
      "9 22 5\n",
      "checkcorrect 8 8 real score 0.7430939361453056 Hits@1 0.844311377245509 Hits@3 0.9700598802395209 Hits@10 1.0 MRR 0.9112774451097805 cur_rank 1 abs_cur_rank 1 total_num 166 188\n",
      "9 3\n",
      "9 28 19\n",
      "checkcorrect 0 0 real score 1.8565567553043367 Hits@1 0.8452380952380952 Hits@3 0.9702380952380952 Hits@10 1.0 MRR 0.9118055555555555 cur_rank 0 abs_cur_rank 0 total_num 167 188\n",
      "9 6\n",
      "9 28 33\n",
      "checkcorrect 0 0 real score 1.739774039387703 Hits@1 0.8461538461538461 Hits@3 0.9704142011834319 Hits@10 1.0 MRR 0.91232741617357 cur_rank 0 abs_cur_rank 0 total_num 168 188\n",
      "9 68\n",
      "9 36 23\n",
      "checkcorrect 0 0 real score 1.7283393919467926 Hits@1 0.8470588235294118 Hits@3 0.9705882352941176 Hits@10 1.0 MRR 0.912843137254902 cur_rank 0 abs_cur_rank 0 total_num 169 188\n",
      "0 2\n",
      "9 29 11\n",
      "checkcorrect 0 0 real score 0.5495398789644241 Hits@1 0.847953216374269 Hits@3 0.9707602339181286 Hits@10 1.0 MRR 0.9133528265107212 cur_rank 0 abs_cur_rank 0 total_num 170 188\n",
      "9 93\n",
      "9 50 68\n",
      "checkcorrect 6 6 real score 1.357521453499794 Hits@1 0.8488372093023255 Hits@3 0.9709302325581395 Hits@10 1.0 MRR 0.9138565891472868 cur_rank 0 abs_cur_rank 0 total_num 171 188\n",
      "9 7\n",
      "9 49 30\n",
      "checkcorrect 0 0 real score 1.6729821503162383 Hits@1 0.8497109826589595 Hits@3 0.9710982658959537 Hits@10 1.0 MRR 0.914354527938343 cur_rank 0 abs_cur_rank 0 total_num 172 188\n",
      "9 77\n",
      "9 34 41\n",
      "checkcorrect 8 8 real score 1.275895357131958 Hits@1 0.8505747126436781 Hits@3 0.9712643678160919 Hits@10 1.0 MRR 0.9148467432950191 cur_rank 0 abs_cur_rank 0 total_num 173 188\n",
      "9 12\n",
      "9 43 50\n",
      "checkcorrect 0 0 real score 1.4787789553403854 Hits@1 0.8514285714285714 Hits@3 0.9714285714285714 Hits@10 1.0 MRR 0.9153333333333333 cur_rank 0 abs_cur_rank 0 total_num 174 188\n",
      "0 1\n",
      "9 8 18\n",
      "checkcorrect 0 0 real score 0.6022745728492737 Hits@1 0.8465909090909091 Hits@3 0.9715909090909091 Hits@10 1.0 MRR 0.9129734848484848 cur_rank 1 abs_cur_rank 1 total_num 175 188\n",
      "9 124\n",
      "9 96 76\n",
      "checkcorrect 0 0 real score 1.676014006137848 Hits@1 0.847457627118644 Hits@3 0.9717514124293786 Hits@10 1.0 MRR 0.9134651600753296 cur_rank 0 abs_cur_rank 0 total_num 176 188\n",
      "9 21\n",
      "9 10 32\n",
      "checkcorrect 0 0 real score 1.6859278321266173 Hits@1 0.848314606741573 Hits@3 0.9719101123595506 Hits@10 1.0 MRR 0.9139513108614232 cur_rank 0 abs_cur_rank 0 total_num 177 188\n",
      "0 1\n",
      "9 46 24\n",
      "checkcorrect 0 0 real score 0.6601182162761688 Hits@1 0.8491620111731844 Hits@3 0.9720670391061452 Hits@10 1.0 MRR 0.9144320297951584 cur_rank 0 abs_cur_rank 0 total_num 178 188\n",
      "9 150\n",
      "9 49 97\n",
      "checkcorrect 0 0 real score 1.5470402091741562 Hits@1 0.85 Hits@3 0.9722222222222222 Hits@10 1.0 MRR 0.9149074074074074 cur_rank 0 abs_cur_rank 0 total_num 179 188\n",
      "9 132\n",
      "9 18 11\n",
      "checkcorrect 8 8 real score 1.5948498010635377 Hits@1 0.850828729281768 Hits@3 0.9723756906077348 Hits@10 1.0 MRR 0.9153775322283609 cur_rank 0 abs_cur_rank 0 total_num 180 188\n",
      "9 3\n",
      "9 18 7\n",
      "checkcorrect 0 0 real score 1.6323722422122955 Hits@1 0.8516483516483516 Hits@3 0.9725274725274725 Hits@10 1.0 MRR 0.9158424908424908 cur_rank 0 abs_cur_rank 0 total_num 181 188\n",
      "0 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 16 34\n",
      "checkcorrect 0 0 real score 0.6142259627580643 Hits@1 0.8524590163934426 Hits@3 0.9726775956284153 Hits@10 1.0 MRR 0.9163023679417123 cur_rank 0 abs_cur_rank 0 total_num 182 188\n",
      "9 4\n",
      "9 22 19\n",
      "checkcorrect 10 10 real score 1.9311034083366394 Hits@1 0.8532608695652174 Hits@3 0.9728260869565217 Hits@10 1.0 MRR 0.9167572463768117 cur_rank 0 abs_cur_rank 0 total_num 183 188\n",
      "9 22\n",
      "9 50 58\n",
      "checkcorrect 0 0 real score 1.5718801110982894 Hits@1 0.8540540540540541 Hits@3 0.972972972972973 Hits@10 1.0 MRR 0.9172072072072073 cur_rank 0 abs_cur_rank 0 total_num 184 188\n",
      "9 18\n",
      "9 16 10\n",
      "checkcorrect 0 0 real score 1.3778696570545435 Hits@1 0.8548387096774194 Hits@3 0.9731182795698925 Hits@10 1.0 MRR 0.9176523297491039 cur_rank 0 abs_cur_rank 0 total_num 185 188\n",
      "9 14\n",
      "9 12 33\n",
      "checkcorrect 0 0 real score 1.2510857969522475 Hits@1 0.8556149732620321 Hits@3 0.9732620320855615 Hits@10 1.0 MRR 0.9180926916221034 cur_rank 0 abs_cur_rank 0 total_num 186 188\n",
      "0 0\n",
      "0 1 51\n",
      "checkcorrect 0 0 real score 0.0 Hits@1 0.8563829787234043 Hits@3 0.973404255319149 Hits@10 1.0 MRR 0.9185283687943263 cur_rank 0 abs_cur_rank 0 total_num 187 188\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "#obtain the Hits@N for relation prediction##############\n",
    "\n",
    "#we select all the triples in the inductive test set\n",
    "selected = list(data_ind_test)\n",
    "\n",
    "###Hit at 1#############################\n",
    "#generate the negative samples by randomly replace relation with all the other relaiton\n",
    "Hits_at_1 = 0\n",
    "Hits_at_3 = 0\n",
    "Hits_at_10 = 0\n",
    "MRR_raw = 0.\n",
    "\n",
    "for i in range(len(selected)):\n",
    "    \n",
    "    s_true, r_true, t_true = selected[i][0], selected[i][1], selected[i][2]\n",
    "    \n",
    "    #run the path-based scoring\n",
    "    score_dict_path = path_based_relation_scoring(s_true, t_true, 1, 10, one_hop_ind, id2relation, model)\n",
    "    \n",
    "    #run the one-hop neighbour based scoring\n",
    "    score_dict_subg = subgraph_relation_scoring(s_true, t_true, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "    \n",
    "    #final score dict\n",
    "    score_dict = defaultdict(float)\n",
    "    \n",
    "    for r in score_dict_path:\n",
    "        score_dict[r] += score_dict_path[r]\n",
    "    for r in score_dict_subg:\n",
    "        score_dict[r] += score_dict_subg[r]\n",
    "    \n",
    "    #[... [score, r], ...]\n",
    "    temp_list = list()\n",
    "    \n",
    "    for r in id2relation:\n",
    "        \n",
    "        #again, we only care about initial relation prediciton\n",
    "        if r % 2 == 0:\n",
    "        \n",
    "            if r in score_dict:\n",
    "\n",
    "                temp_list.append([score_dict[r], r])\n",
    "\n",
    "            else:\n",
    "\n",
    "                temp_list.append([0.0, r])\n",
    "        \n",
    "    sorted_list = sorted(temp_list, key = lambda x: x[0], reverse=True)\n",
    "    \n",
    "    p = 0\n",
    "    exist_tri = 0\n",
    "    \n",
    "    while p < len(sorted_list) and sorted_list[p][1] != r_true:\n",
    "        \n",
    "        #moreover, we want to remove existing triples\n",
    "        if ((s_true, sorted_list[p][1], t_true) in data_test) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data_valid) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data_ind) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data_ind_valid) or (\n",
    "            (s_true, sorted_list[p][1], t_true) in data_ind_test):\n",
    "            \n",
    "            exist_tri += 1\n",
    "            \n",
    "        p += 1\n",
    "    \n",
    "    if p - exist_tri == 0:\n",
    "        \n",
    "        Hits_at_1 += 1\n",
    "        \n",
    "    if p - exist_tri < 3:\n",
    "        \n",
    "        Hits_at_3 += 1\n",
    "        \n",
    "    if p - exist_tri < 10:\n",
    "        \n",
    "        Hits_at_10 += 1\n",
    "        \n",
    "    MRR_raw += 1./float(p - exist_tri + 1.) \n",
    "        \n",
    "    print('checkcorrect', r_true, sorted_list[p][1],\n",
    "          'real score', sorted_list[p][0],\n",
    "          'Hits@1', Hits_at_1/(i+1),\n",
    "          'Hits@3', Hits_at_3/(i+1),\n",
    "          'Hits@10', Hits_at_10/(i+1),\n",
    "          'MRR', MRR_raw/(i+1),\n",
    "          'cur_rank', p - exist_tri,\n",
    "          'abs_cur_rank', p,\n",
    "          'total_num', i, len(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "550a7ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating scores 20 376\n",
      "AUC-PR is: 0.8158124039702987\n",
      "evaluating scores 40 376\n",
      "AUC-PR is: 0.770603450876653\n",
      "evaluating scores 60 376\n",
      "AUC-PR is: 0.7587513046465775\n",
      "evaluating scores 80 376\n",
      "AUC-PR is: 0.7889110246028787\n",
      "evaluating scores 100 376\n",
      "AUC-PR is: 0.77768457943568\n",
      "evaluating scores 120 376\n",
      "AUC-PR is: 0.7778079025696366\n",
      "evaluating scores 140 376\n",
      "AUC-PR is: 0.7901361514723642\n",
      "evaluating scores 160 376\n",
      "AUC-PR is: 0.7539759441124845\n",
      "evaluating scores 180 376\n",
      "AUC-PR is: 0.7480333614245009\n",
      "evaluating scores 200 376\n",
      "AUC-PR is: 0.7373484679242981\n",
      "evaluating scores 220 376\n",
      "AUC-PR is: 0.7403965974871085\n",
      "evaluating scores 240 376\n",
      "AUC-PR is: 0.7600854965707611\n",
      "evaluating scores 260 376\n",
      "AUC-PR is: 0.7360974188142251\n",
      "evaluating scores 280 376\n",
      "AUC-PR is: 0.7377639545950183\n",
      "evaluating scores 300 376\n",
      "AUC-PR is: 0.725380399187881\n",
      "evaluating scores 320 376\n",
      "AUC-PR is: 0.7198041945682027\n",
      "evaluating scores 340 376\n",
      "AUC-PR is: 0.7173594115404267\n",
      "evaluating scores 360 376\n",
      "AUC-PR is: 0.7250464293392811\n",
      "AUC-PR is: 0.7292184864458535\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "##obtain the AUC-PR for the test triples###\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#we select all the triples in the inductive test set\n",
    "pos_triples = list(data_ind_test)\n",
    "\n",
    "#we build the negative samples by randomly replace head or tail entity in the triple.\n",
    "neg_triples = list()\n",
    "\n",
    "for i in range(len(pos_triples)):\n",
    "    \n",
    "    s_pos, r_pos, t_pos = pos_triples[i][0], pos_triples[i][1], pos_triples[i][2]\n",
    "    \n",
    "    #decide to replace the head or tail entity\n",
    "    number_0 = random.uniform(0, 1)\n",
    "    \n",
    "    if number_0 < 0.5: #replace head entity\n",
    "        s_neg = random.choice(list(new_ent_set))\n",
    "        neg_triples.append((s_neg, r_pos, t_pos))\n",
    "    else: #replace tail entity\n",
    "        t_neg = random.choice(list(new_ent_set))\n",
    "        neg_triples.append((s_pos, r_pos, t_neg))\n",
    "\n",
    "if len(pos_triples) != len(neg_triples):\n",
    "    raise ValueError('error when generating negative triples')\n",
    "        \n",
    "#combine all triples\n",
    "all_triples = pos_triples + neg_triples\n",
    "\n",
    "#obtain the label array\n",
    "arr1 = np.ones((len(pos_triples),))\n",
    "arr2 = np.zeros((len(neg_triples),))\n",
    "y_test = np.concatenate((arr1, arr2))\n",
    "\n",
    "#shuffle positive and negative triples (optional)\n",
    "all_triples, y_test = shuffle(all_triples, y_test)\n",
    "\n",
    "#obtain the score aray\n",
    "y_score = np.zeros((len(y_test),))\n",
    "\n",
    "#implement the scoring\n",
    "for i in range(len(all_triples)):\n",
    "    \n",
    "    s, r, t = all_triples[i][0], all_triples[i][1], all_triples[i][2]\n",
    "    \n",
    "    #path_score = path_based_triple_scoring(s, r, t, 1, 10, one_hop_ind, id2relation, model)\n",
    "    \n",
    "    subg_score = subgraph_triple_scoring(s, r, t, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "    \n",
    "    #ave_score = (path_score + subg_score)/float(2)\n",
    "    \n",
    "    #y_score[i] = ave_score\n",
    "    y_score[i] = subg_score\n",
    "    \n",
    "    if i % 20 == 0 and i > 0:\n",
    "        print('evaluating scores', i, len(all_triples))\n",
    "        \n",
    "        # Data to plot precision - recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test[:i], y_score[:i])\n",
    "        # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "        auc_precision_recall = auc(recall, precision)\n",
    "        print('AUC-PR is:', auc_precision_recall)\n",
    "        \n",
    "        \n",
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print('AUC-PR is:', auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9380c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkcorrect (3616, 0, 3274) (3616, 0, 3274) real score 0.4064545691013336 Hits@1 0.0 Hits@3 0.0 Hits@10 0.0 MRR 0.03571428571428571 rank 27 total_num 0 188\n",
      "checkcorrect (3613, 0, 3144) (3613, 0, 3144) real score 0.7161331176757812 Hits@1 0.0 Hits@3 0.5 Hits@10 0.5 MRR 0.26785714285714285 rank 1 total_num 1 188\n",
      "checkcorrect (2799, 0, 3251) (2799, 0, 3251) real score 0.7103965640068054 Hits@1 0.0 Hits@3 0.3333333333333333 Hits@10 0.6666666666666666 MRR 0.2261904761904762 rank 6 total_num 2 188\n",
      "checkcorrect (3170, 0, 2776) (3170, 0, 2776) real score 0.7012916684150696 Hits@1 0.0 Hits@3 0.25 Hits@10 0.75 MRR 0.20535714285714285 rank 6 total_num 3 188\n",
      "checkcorrect (3074, 0, 3194) (3074, 0, 3194) real score 0.749379575252533 Hits@1 0.0 Hits@3 0.4 Hits@10 0.8 MRR 0.23095238095238094 rank 2 total_num 4 188\n",
      "checkcorrect (3329, 8, 2803) (3329, 8, 2803) real score 0.287155294418335 Hits@1 0.0 Hits@3 0.3333333333333333 Hits@10 0.6666666666666666 MRR 0.19912698412698412 rank 24 total_num 5 188\n",
      "checkcorrect (2829, 8, 3612) (2829, 8, 3612) real score 0.19535211846232414 Hits@1 0.0 Hits@3 0.2857142857142857 Hits@10 0.5714285714285714 MRR 0.1754421768707483 rank 29 total_num 6 188\n",
      "checkcorrect (3496, 0, 3258) (3496, 0, 3258) real score 0.6856578767299653 Hits@1 0.0 Hits@3 0.375 Hits@10 0.625 MRR 0.19517857142857142 rank 2 total_num 7 188\n",
      "checkcorrect (2951, 8, 3384) (2951, 8, 3384) real score 0.30361056625843047 Hits@1 0.0 Hits@3 0.3333333333333333 Hits@10 0.5555555555555556 MRR 0.1808994708994709 rank 14 total_num 8 188\n",
      "checkcorrect (2845, 0, 3562) (2845, 0, 3562) real score 0.6257483989000321 Hits@1 0.0 Hits@3 0.3 Hits@10 0.5 MRR 0.16869187675070027 rank 16 total_num 9 188\n",
      "checkcorrect (2929, 0, 3169) (2929, 0, 3169) real score 0.7062711954116822 Hits@1 0.0 Hits@3 0.36363636363636365 Hits@10 0.5454545454545454 MRR 0.18365928189457603 rank 2 total_num 10 188\n",
      "checkcorrect (3366, 0, 3414) (3366, 0, 3414) real score 0.0 Hits@1 0.0 Hits@3 0.3333333333333333 Hits@10 0.5 MRR 0.17095850840336135 rank 31 total_num 11 188\n",
      "checkcorrect (3319, 0, 2907) (3319, 0, 2907) real score 0.5361194342374802 Hits@1 0.0 Hits@3 0.3076923076923077 Hits@10 0.46153846153846156 MRR 0.16372501367410872 rank 12 total_num 12 188\n",
      "checkcorrect (3326, 0, 3165) (3326, 0, 3165) real score 0.7001446396112442 Hits@1 0.0 Hits@3 0.35714285714285715 Hits@10 0.5 MRR 0.18774465555452952 rank 1 total_num 13 188\n",
      "checkcorrect (3636, 0, 3073) (3636, 0, 3073) real score 0.7738904356956482 Hits@1 0.0 Hits@3 0.4 Hits@10 0.5333333333333333 MRR 0.20856167851756088 rank 1 total_num 14 188\n",
      "checkcorrect (3162, 8, 3442) (3162, 8, 3442) real score 0.24473604708909988 Hits@1 0.0 Hits@3 0.375 Hits@10 0.5 MRR 0.19969324027688 rank 14 total_num 15 188\n",
      "checkcorrect (3383, 8, 3093) (3383, 8, 3093) real score 0.44352283254265784 Hits@1 0.0 Hits@3 0.35294117647058826 Hits@10 0.47058823529411764 MRR 0.19247146596195042 rank 12 total_num 16 188\n",
      "checkcorrect (2784, 0, 2923) (2784, 0, 2923) real score 0.6085920929908752 Hits@1 0.0 Hits@3 0.3333333333333333 Hits@10 0.5 MRR 0.18733416229739763 rank 9 total_num 17 188\n",
      "checkcorrect (3495, 8, 2941) (3495, 8, 2941) real score 0.2384562999010086 Hits@1 0.0 Hits@3 0.3157894736842105 Hits@10 0.47368421052631576 MRR 0.18010604849227144 rank 19 total_num 18 188\n",
      "checkcorrect (3555, 0, 3212) (3555, 0, 3212) real score 0.5405438907444478 Hits@1 0.0 Hits@3 0.3 Hits@10 0.45 MRR 0.17302382299073477 rank 25 total_num 19 188\n",
      "checkcorrect (3529, 8, 3509) (3529, 8, 3509) real score 0.6542540669441224 Hits@1 0.0 Hits@3 0.2857142857142857 Hits@10 0.42857142857142855 MRR 0.16729085898866972 rank 18 total_num 20 188\n",
      "checkcorrect (3244, 6, 3131) (3244, 6, 3131) real score 0.07267479971051216 Hits@1 0.0 Hits@3 0.2727272727272727 Hits@10 0.45454545454545453 MRR 0.16423218358009384 rank 9 total_num 21 188\n",
      "checkcorrect (3358, 0, 3110) (3358, 0, 3110) real score 0.668941606208682 Hits@1 0.0 Hits@3 0.30434782608695654 Hits@10 0.4782608695652174 MRR 0.1715844074824086 rank 2 total_num 22 188\n",
      "checkcorrect (3373, 0, 3116) (3373, 0, 3116) real score 0.4731670841574669 Hits@1 0.0 Hits@3 0.2916666666666667 Hits@10 0.4583333333333333 MRR 0.16632899656458097 rank 21 total_num 23 188\n",
      "checkcorrect (3246, 0, 2827) (3246, 0, 2827) real score 0.712384819984436 Hits@1 0.0 Hits@3 0.32 Hits@10 0.48 MRR 0.17300917003533103 rank 2 total_num 24 188\n",
      "checkcorrect (3085, 0, 2982) (3085, 0, 2982) real score 0.5037496328353882 Hits@1 0.0 Hits@3 0.3076923076923077 Hits@10 0.5 MRR 0.17116266349551063 rank 7 total_num 25 188\n",
      "checkcorrect (2904, 0, 2933) (2904, 0, 2933) real score 0.6512075692415238 Hits@1 0.0 Hits@3 0.2962962962962963 Hits@10 0.48148148148148145 MRR 0.16700195482574223 rank 16 total_num 26 188\n",
      "checkcorrect (3065, 0, 3164) (3065, 0, 3164) real score 0.32854900378733876 Hits@1 0.0 Hits@3 0.2857142857142857 Hits@10 0.4642857142857143 MRR 0.16218967302897033 rank 30 total_num 27 188\n",
      "checkcorrect (3298, 0, 3186) (3298, 0, 3186) real score 0.5380708456039429 Hits@1 0.0 Hits@3 0.27586206896551724 Hits@10 0.4482758620689655 MRR 0.1580961760579564 rank 22 total_num 28 188\n",
      "checkcorrect (3634, 8, 3315) (3634, 8, 3315) real score 0.22381098419427872 Hits@1 0.0 Hits@3 0.26666666666666666 Hits@10 0.43333333333333335 MRR 0.15383640453279218 rank 32 total_num 29 188\n",
      "checkcorrect (3434, 8, 3087) (3434, 8, 3087) real score 0.3953783124685287 Hits@1 0.0 Hits@3 0.25806451612903225 Hits@10 0.41935483870967744 MRR 0.1503402155302681 rank 21 total_num 30 188\n",
      "checkcorrect (3238, 0, 3030) (3238, 0, 3030) real score 0.0 Hits@1 0.0 Hits@3 0.25 Hits@10 0.40625 MRR 0.1468440068718703 rank 25 total_num 31 188\n",
      "checkcorrect (2803, 0, 3604) (2803, 0, 3604) real score 0.7047195374965668 Hits@1 0.0 Hits@3 0.2727272727272727 Hits@10 0.42424242424242425 MRR 0.1524951985828237 rank 2 total_num 32 188\n",
      "checkcorrect (2749, 0, 3298) (2749, 0, 3298) real score 0.7376165896654129 Hits@1 0.0 Hits@3 0.29411764705882354 Hits@10 0.4411764705882353 MRR 0.15781396725195634 rank 2 total_num 33 188\n",
      "checkcorrect (3227, 8, 2914) (3227, 8, 2914) real score 0.27679534554481505 Hits@1 0.0 Hits@3 0.2857142857142857 Hits@10 0.42857142857142855 MRR 0.1552097586638052 rank 14 total_num 34 188\n",
      "checkcorrect (3202, 0, 2941) (3202, 0, 2941) real score 0.4400895059108734 Hits@1 0.0 Hits@3 0.2777777777777778 Hits@10 0.4166666666666667 MRR 0.1526344875898106 rank 15 total_num 35 188\n",
      "checkcorrect (2862, 0, 3101) (2862, 0, 3101) real score 0.7005464494228363 Hits@1 0.0 Hits@3 0.2972972972972973 Hits@10 0.43243243243243246 MRR 0.15751824017747337 rank 2 total_num 36 188\n",
      "checkcorrect (3476, 8, 3531) (3476, 8, 3531) real score 0.12478653900325298 Hits@1 0.0 Hits@3 0.2894736842105263 Hits@10 0.42105263157894735 MRR 0.15404778716335632 rank 38 total_num 37 188\n",
      "checkcorrect (2765, 0, 2764) (2765, 0, 2764) real score 0.6429634690284729 Hits@1 0.0 Hits@3 0.28205128205128205 Hits@10 0.41025641025641024 MRR 0.1522345960395096 rank 11 total_num 38 188\n",
      "checkcorrect (3000, 0, 3440) (3000, 0, 3440) real score 0.6397290736436844 Hits@1 0.0 Hits@3 0.3 Hits@10 0.425 MRR 0.16092873113852185 rank 1 total_num 39 188\n",
      "checkcorrect (2989, 0, 2850) (2989, 0, 2850) real score 0.45926915407180785 Hits@1 0.0 Hits@3 0.2926829268292683 Hits@10 0.4146341463414634 MRR 0.15779042219651226 rank 30 total_num 40 188\n",
      "checkcorrect (3131, 0, 3041) (3131, 0, 3041) real score 0.6976802349090576 Hits@1 0.0 Hits@3 0.2857142857142857 Hits@10 0.42857142857142855 MRR 0.15641445976326196 rank 9 total_num 41 188\n",
      "checkcorrect (3215, 0, 2940) (3215, 0, 2940) real score 0.6953262269496918 Hits@1 0.0 Hits@3 0.3023255813953488 Hits@10 0.4418604651162791 MRR 0.16440482116411634 rank 1 total_num 42 188\n",
      "checkcorrect (3474, 0, 2904) (3474, 0, 2904) real score 0.7303421318531036 Hits@1 0.0 Hits@3 0.3181818181818182 Hits@10 0.45454545454545453 MRR 0.16824410553159852 rank 2 total_num 43 188\n",
      "checkcorrect (3298, 0, 2749) (3298, 0, 2749) real score 0.6751683443784714 Hits@1 0.0 Hits@3 0.3333333333333333 Hits@10 0.4666666666666667 MRR 0.17561645874200746 rank 1 total_num 44 188\n",
      "checkcorrect (3325, 0, 3192) (3325, 0, 3192) real score 0.7945961713790893 Hits@1 0.0 Hits@3 0.34782608695652173 Hits@10 0.4782608695652174 MRR 0.17904508645051453 rank 2 total_num 45 188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkcorrect (2940, 0, 3343) (2940, 0, 3343) real score 0.7114482671022415 Hits@1 0.0 Hits@3 0.3404255319148936 Hits@10 0.48936170212765956 MRR 0.1805547654622057 rank 3 total_num 46 188\n",
      "checkcorrect (3339, 0, 3170) (3339, 0, 3170) real score 0.5601408511400223 Hits@1 0.0 Hits@3 0.3333333333333333 Hits@10 0.4791666666666667 MRR 0.17839577195097386 rank 12 total_num 47 188\n",
      "checkcorrect (3212, 8, 3283) (3212, 8, 3283) real score 0.5529832601547241 Hits@1 0.0 Hits@3 0.32653061224489793 Hits@10 0.46938775510204084 MRR 0.1764557221832669 rank 11 total_num 48 188\n",
      "checkcorrect (3377, 8, 3576) (3377, 8, 3576) real score 0.0 Hits@1 0.0 Hits@3 0.32 Hits@10 0.46 MRR 0.17345292352907526 rank 37 total_num 49 188\n",
      "checkcorrect (3154, 0, 3597) (3154, 0, 3597) real score 0.25739180445671084 Hits@1 0.0 Hits@3 0.3137254901960784 Hits@10 0.45098039215686275 MRR 0.17058182751923118 rank 36 total_num 50 188\n",
      "checkcorrect (3150, 0, 3219) (3150, 0, 3219) real score 0.726323926448822 Hits@1 0.0 Hits@3 0.3076923076923077 Hits@10 0.46153846153846156 MRR 0.1711475616053998 rank 4 total_num 51 188\n",
      "checkcorrect (2809, 0, 3275) (2809, 0, 3275) real score 0.5794817060232162 Hits@1 0.0 Hits@3 0.3018867924528302 Hits@10 0.4528301886792453 MRR 0.16917622396504634 rank 14 total_num 52 188\n",
      "checkcorrect (2974, 0, 3635) (2974, 0, 3635) real score 0.5780866205692291 Hits@1 0.0 Hits@3 0.2962962962962963 Hits@10 0.4444444444444444 MRR 0.16696925685458253 rank 19 total_num 53 188\n",
      "checkcorrect (2873, 10, 3504) (2873, 10, 3504) real score 0.8862844586372376 Hits@1 0.01818181818181818 Hits@3 0.3090909090909091 Hits@10 0.45454545454545453 MRR 0.1821152703663174 rank 0 total_num 54 188\n",
      "checkcorrect (3489, 0, 3626) (3489, 0, 3626) real score 0.4395515829324722 Hits@1 0.017857142857142856 Hits@3 0.30357142857142855 Hits@10 0.44642857142857145 MRR 0.17955002515373206 rank 25 total_num 55 188\n",
      "checkcorrect (3359, 0, 3573) (3359, 0, 3573) real score 0.6576962530612945 Hits@1 0.017543859649122806 Hits@3 0.2982456140350877 Hits@10 0.43859649122807015 MRR 0.17799492104417697 rank 10 total_num 56 188\n",
      "checkcorrect (3415, 0, 3226) (3415, 0, 3226) real score 0.7168565154075622 Hits@1 0.017241379310344827 Hits@3 0.3103448275862069 Hits@10 0.4482758620689655 MRR 0.18067316953192106 rank 2 total_num 57 188\n",
      "checkcorrect (3566, 2, 3305) (3566, 2, 3305) real score 0.0 Hits@1 0.01694915254237288 Hits@3 0.3050847457627119 Hits@10 0.4406779661016949 MRR 0.17855253200689788 rank 17 total_num 58 188\n",
      "checkcorrect (2879, 0, 3617) (2879, 0, 3617) real score 0.2873796343803406 Hits@1 0.016666666666666666 Hits@3 0.3 Hits@10 0.43333333333333335 MRR 0.17595544435223748 rank 43 total_num 59 188\n",
      "checkcorrect (3475, 0, 2893) (3475, 0, 2893) real score 0.6755952417850495 Hits@1 0.01639344262295082 Hits@3 0.29508196721311475 Hits@10 0.4262295081967213 MRR 0.1744370490896325 rank 11 total_num 60 188\n",
      "checkcorrect (3474, 0, 2970) (3474, 0, 2970) real score 0.7185694456100464 Hits@1 0.016129032258064516 Hits@3 0.2903225806451613 Hits@10 0.41935483870967744 MRR 0.1730898239576883 rank 10 total_num 61 188\n",
      "checkcorrect (3586, 0, 3079) (3586, 0, 3079) real score 0.7194134414196014 Hits@1 0.015873015873015872 Hits@3 0.2857142857142857 Hits@10 0.42857142857142855 MRR 0.17298786908005304 rank 5 total_num 62 188\n",
      "checkcorrect (3004, 8, 3584) (3004, 8, 3584) real score 0.0 Hits@1 0.015625 Hits@3 0.28125 Hits@10 0.421875 MRR 0.17078896588374173 rank 30 total_num 63 188\n",
      "checkcorrect (2907, 0, 3319) (2907, 0, 3319) real score 0.5282856553792954 Hits@1 0.015384615384615385 Hits@3 0.27692307692307694 Hits@10 0.4153846153846154 MRR 0.16956004473028558 rank 10 total_num 64 188\n",
      "checkcorrect (2803, 0, 3489) (2803, 0, 3489) real score 0.6352448850870133 Hits@1 0.015151515151515152 Hits@3 0.2727272727272727 Hits@10 0.4090909090909091 MRR 0.1680010541535641 rank 14 total_num 65 188\n",
      "checkcorrect (2784, 0, 3286) (2784, 0, 3286) real score 0.5351272553205491 Hits@1 0.014925373134328358 Hits@3 0.26865671641791045 Hits@10 0.40298507462686567 MRR 0.1660676285462204 rank 25 total_num 66 188\n",
      "checkcorrect (3364, 0, 3027) (3364, 0, 3027) real score 0.6788058638572693 Hits@1 0.014705882352941176 Hits@3 0.2647058823529412 Hits@10 0.4117647058823529 MRR 0.1657262978743222 rank 6 total_num 67 188\n",
      "checkcorrect (3230, 0, 2838) (3230, 0, 2838) real score 0.5870185129344463 Hits@1 0.014492753623188406 Hits@3 0.2608695652173913 Hits@10 0.4057971014492754 MRR 0.1642302645717958 rank 15 total_num 68 188\n",
      "checkcorrect (3056, 0, 2892) (3056, 0, 2892) real score 0.6423091948032379 Hits@1 0.014285714285714285 Hits@3 0.2571428571428571 Hits@10 0.4142857142857143 MRR 0.16366983222077014 rank 7 total_num 69 188\n",
      "checkcorrect (3389, 0, 2902) (3389, 0, 2902) real score 0.48049577325582504 Hits@1 0.014084507042253521 Hits@3 0.2535211267605634 Hits@10 0.4084507042253521 MRR 0.16190633512556968 rank 25 total_num 70 188\n",
      "checkcorrect (3012, 0, 3218) (3012, 0, 3218) real score 0.7281792044639588 Hits@1 0.027777777777777776 Hits@3 0.2638888888888889 Hits@10 0.4166666666666667 MRR 0.17354652491549233 rank 0 total_num 71 188\n",
      "checkcorrect (3329, 0, 3045) (3329, 0, 3045) real score 0.6052659422159195 Hits@1 0.0273972602739726 Hits@3 0.2602739726027397 Hits@10 0.410958904109589 MRR 0.1719749770318796 rank 16 total_num 72 188\n",
      "checkcorrect (2789, 10, 2788) (2789, 10, 2788) real score 0.350359670817852 Hits@1 0.02702702702702703 Hits@3 0.2702702702702703 Hits@10 0.4189189189189189 MRR 0.1764077476125299 rank 1 total_num 73 188\n",
      "checkcorrect (3383, 0, 2823) (3383, 0, 2823) real score 0.6438006281852722 Hits@1 0.02666666666666667 Hits@3 0.26666666666666666 Hits@10 0.4266666666666667 MRR 0.17572231097769617 rank 7 total_num 74 188\n",
      "checkcorrect (3013, 0, 3614) (3013, 0, 3614) real score 0.6008771091699601 Hits@1 0.02631578947368421 Hits@3 0.2631578947368421 Hits@10 0.42105263157894735 MRR 0.17460634755574084 rank 10 total_num 75 188\n",
      "checkcorrect (2941, 0, 3202) (2941, 0, 3202) real score 0.44163821041584017 Hits@1 0.025974025974025976 Hits@3 0.2597402597402597 Hits@10 0.4155844155844156 MRR 0.17287985819354507 rank 23 total_num 76 188\n",
      "checkcorrect (2902, 0, 3338) (2902, 0, 3338) real score 0.4321796029806137 Hits@1 0.02564102564102564 Hits@3 0.2564102564102564 Hits@10 0.41025641025641024 MRR 0.1711762702679868 rank 24 total_num 77 188\n",
      "checkcorrect (3281, 0, 3028) (3281, 0, 3028) real score 0.5975298166275025 Hits@1 0.02531645569620253 Hits@3 0.25316455696202533 Hits@10 0.4050632911392405 MRR 0.16967570455506756 rank 18 total_num 78 188\n",
      "checkcorrect (3023, 0, 3012) (3023, 0, 3012) real score 0.6396697670221329 Hits@1 0.025 Hits@3 0.2625 Hits@10 0.4125 MRR 0.17380475824812922 rank 1 total_num 79 188\n",
      "checkcorrect (3627, 0, 2778) (3627, 0, 2778) real score 0.5896766811609269 Hits@1 0.024691358024691357 Hits@3 0.25925925925925924 Hits@10 0.4074074074074074 MRR 0.17268782707634162 rank 11 total_num 80 188\n",
      "checkcorrect (3592, 0, 3491) (3592, 0, 3491) real score 0.5206843674182892 Hits@1 0.024390243902439025 Hits@3 0.25609756097560976 Hits@10 0.4024390243902439 MRR 0.17109000804695534 rank 23 total_num 81 188\n",
      "checkcorrect (2979, 0, 2920) (2979, 0, 2920) real score 0.7435807675123215 Hits@1 0.024096385542168676 Hits@3 0.26506024096385544 Hits@10 0.40963855421686746 MRR 0.1750527790343414 rank 1 total_num 82 188\n",
      "checkcorrect (3043, 0, 2763) (3043, 0, 2763) real score 0.5571626543998718 Hits@1 0.023809523809523808 Hits@3 0.2619047619047619 Hits@10 0.40476190476190477 MRR 0.17353571080320696 rank 20 total_num 83 188\n",
      "checkcorrect (2768, 0, 2767) (2768, 0, 2767) real score 0.6535162895917892 Hits@1 0.023529411764705882 Hits@3 0.25882352941176473 Hits@10 0.4117647058823529 MRR 0.1744352906761104 rank 3 total_num 84 188\n",
      "checkcorrect (2998, 0, 3427) (2998, 0, 3427) real score 0.3685401797294617 Hits@1 0.023255813953488372 Hits@3 0.2558139534883721 Hits@10 0.4069767441860465 MRR 0.17278206711611063 rank 30 total_num 85 188\n",
      "checkcorrect (2860, 0, 3601) (2860, 0, 3601) real score 0.7332610607147216 Hits@1 0.022988505747126436 Hits@3 0.25287356321839083 Hits@10 0.41379310344827586 MRR 0.1736696295630519 rank 3 total_num 86 188\n",
      "checkcorrect (2792, 0, 3390) (2792, 0, 3390) real score 0.5055336683988572 Hits@1 0.022727272727272728 Hits@3 0.25 Hits@10 0.4090909090909091 MRR 0.1720879605750705 rank 28 total_num 87 188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkcorrect (3572, 0, 2813) (3572, 0, 2813) real score 0.5788687020540237 Hits@1 0.02247191011235955 Hits@3 0.24719101123595505 Hits@10 0.4044943820224719 MRR 0.17062255277834687 rank 23 total_num 88 188\n",
      "checkcorrect (3540, 0, 2833) (3540, 0, 2833) real score 0.6214325815439224 Hits@1 0.022222222222222223 Hits@3 0.24444444444444444 Hits@10 0.4111111111111111 MRR 0.17150452441414302 rank 3 total_num 89 188\n",
      "checkcorrect (2859, 0, 3040) (2859, 0, 3040) real score 0.6616534888744354 Hits@1 0.02197802197802198 Hits@3 0.24175824175824176 Hits@10 0.4175824175824176 MRR 0.170718760409592 rank 9 total_num 90 188\n",
      "checkcorrect (2956, 0, 2903) (2956, 0, 2903) real score 0.7293300211429596 Hits@1 0.021739130434782608 Hits@3 0.25 Hits@10 0.42391304347826086 MRR 0.17248631011528484 rank 2 total_num 91 188\n",
      "checkcorrect (3388, 0, 2809) (3388, 0, 2809) real score 0.7448042243719101 Hits@1 0.03225806451612903 Hits@3 0.25806451612903225 Hits@10 0.43010752688172044 MRR 0.18138430678071185 rank 0 total_num 92 188\n",
      "checkcorrect (3554, 0, 3081) (3554, 0, 3081) real score 0.7010343134403229 Hits@1 0.031914893617021274 Hits@3 0.2553191489361702 Hits@10 0.43617021276595747 MRR 0.18211426096389577 rank 3 total_num 93 188\n",
      "checkcorrect (3511, 0, 3635) (3511, 0, 3635) real score 0.5582620620727539 Hits@1 0.031578947368421054 Hits@3 0.25263157894736843 Hits@10 0.43157894736842106 MRR 0.1808551634800653 rank 15 total_num 94 188\n",
      "checkcorrect (2899, 0, 3607) (2899, 0, 3607) real score 0.5409736260771751 Hits@1 0.03125 Hits@3 0.25 Hits@10 0.4270833333333333 MRR 0.17937189655278898 rank 25 total_num 95 188\n",
      "checkcorrect (3138, 0, 3362) (3138, 0, 3362) real score 0.0 Hits@1 0.030927835051546393 Hits@3 0.24742268041237114 Hits@10 0.422680412371134 MRR 0.17782591581209925 rank 33 total_num 96 188\n",
      "checkcorrect (2949, 8, 3605) (2949, 8, 3605) real score 0.2822619900107384 Hits@1 0.030612244897959183 Hits@3 0.24489795918367346 Hits@10 0.41836734693877553 MRR 0.17641952891605742 rank 24 total_num 97 188\n",
      "checkcorrect (2923, 0, 2965) (2923, 0, 2965) real score 0.48851313889026643 Hits@1 0.030303030303030304 Hits@3 0.24242424242424243 Hits@10 0.41414141414141414 MRR 0.17492611376106115 rank 34 total_num 98 188\n",
      "checkcorrect (3598, 0, 3242) (3598, 0, 3242) real score 0.6709854125976562 Hits@1 0.03 Hits@3 0.25 Hits@10 0.42 MRR 0.17651018595678386 rank 2 total_num 99 188\n",
      "checkcorrect (2835, 0, 2972) (2835, 0, 2972) real score 0.7000596940517425 Hits@1 0.0297029702970297 Hits@3 0.25742574257425743 Hits@10 0.42574257425742573 MRR 0.17806289038625464 rank 2 total_num 100 188\n",
      "checkcorrect (2855, 0, 2854) (2855, 0, 2854) real score 0.5551030024886131 Hits@1 0.029411764705882353 Hits@3 0.2549019607843137 Hits@10 0.4215686274509804 MRR 0.17683317164665774 rank 18 total_num 101 188\n",
      "checkcorrect (3486, 8, 3258) (3486, 8, 3258) real score 0.14821264445781707 Hits@1 0.02912621359223301 Hits@3 0.2524271844660194 Hits@10 0.4174757281553398 MRR 0.17547592762132164 rank 26 total_num 102 188\n",
      "checkcorrect (3323, 0, 2806) (3323, 0, 2806) real score 0.5422250419855118 Hits@1 0.028846153846153848 Hits@3 0.25 Hits@10 0.4230769230769231 MRR 0.17571173600957815 rank 4 total_num 103 188\n",
      "checkcorrect (3151, 0, 3150) (3151, 0, 3150) real score 0.662813413143158 Hits@1 0.02857142857142857 Hits@3 0.24761904761904763 Hits@10 0.42857142857142855 MRR 0.17499067185710598 rank 9 total_num 104 188\n",
      "checkcorrect (3438, 0, 3186) (3438, 0, 3186) real score 0.6538251012563705 Hits@1 0.02830188679245283 Hits@3 0.24528301886792453 Hits@10 0.4339622641509434 MRR 0.17438803449157772 rank 8 total_num 105 188\n",
      "checkcorrect (2833, 10, 3447) (2833, 10, 3447) real score 0.846570348739624 Hits@1 0.028037383177570093 Hits@3 0.2523364485981308 Hits@10 0.4392523364485981 MRR 0.17743113697296484 rank 1 total_num 106 188\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#obtain the Hits@N for entity prediction##############\n",
    "\n",
    "#we select all the triples in the inductive test set\n",
    "selected = list(data_ind_test)\n",
    "\n",
    "###Hit at 1#############################\n",
    "#generate the negative samples by randomly replace relation with all the other relaiton\n",
    "Hits_at_1 = 0\n",
    "Hits_at_3 = 0\n",
    "Hits_at_10 = 0\n",
    "MRR_raw = 0.\n",
    "\n",
    "for i in range(len(selected)):\n",
    "    \n",
    "    triple_list = list()\n",
    "    \n",
    "    #score the true triple\n",
    "    s_pos, r_pos, t_pos = selected[i][0], selected[i][1], selected[i][2]\n",
    "\n",
    "    #path_score = path_based_triple_scoring(s_pos, r_pos, t_pos, 1, 10, one_hop_ind, id2relation, model)\n",
    "\n",
    "    subg_score = subgraph_triple_scoring(s_pos, r_pos, t_pos, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "    \n",
    "    #ave_score = (path_score + subg_score)/float(2)\n",
    "    \n",
    "    triple_list.append([(s_pos, r_pos, t_pos), subg_score])\n",
    "    \n",
    "    #generate the 50 random samples\n",
    "    for sub_i in range(50):\n",
    "        \n",
    "        #decide to replace the head or tail entity\n",
    "        number_0 = random.uniform(0, 1)\n",
    "\n",
    "        if number_0 < 0.5: #replace head entity\n",
    "            \n",
    "            s_neg = random.choice(list(new_ent_set))\n",
    "            \n",
    "            #path_score = path_based_triple_scoring(s_neg, r_pos, t_pos, 1, 10, one_hop_ind, id2relation, model)\n",
    "\n",
    "            subg_score = subgraph_triple_scoring(s_neg, r_pos, t_pos, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "\n",
    "            #ave_score = (path_score + subg_score)/float(2)\n",
    "\n",
    "            triple_list.append([(s_neg, r_pos, t_pos), subg_score])\n",
    "            \n",
    "        else: #replace tail entity\n",
    "\n",
    "            t_neg = random.choice(list(new_ent_set))\n",
    "            \n",
    "            #path_score = path_based_triple_scoring(s_pos, r_pos, t_neg, 1, 10, one_hop_ind, id2relation, model)\n",
    "\n",
    "            subg_score = subgraph_triple_scoring(s_pos, r_pos, t_neg, 1, 6, one_hop_ind, id2relation, model_2)\n",
    "\n",
    "            #ave_score = (path_score + subg_score)/float(2)\n",
    "\n",
    "            triple_list.append([(s_pos, r_pos, t_neg), subg_score])\n",
    "            \n",
    "    #random shuffle!\n",
    "    random.shuffle(triple_list)\n",
    "    \n",
    "    #sort\n",
    "    sorted_list = sorted(triple_list, key = lambda x: x[-1], reverse=True)\n",
    "    \n",
    "    p = 0\n",
    "    \n",
    "    while p < len(sorted_list) and sorted_list[p][0] != (s_pos, r_pos, t_pos):\n",
    "            \n",
    "        p += 1\n",
    "    \n",
    "    if p == 0:\n",
    "        \n",
    "        Hits_at_1 += 1\n",
    "        \n",
    "    if p < 3:\n",
    "        \n",
    "        Hits_at_3 += 1\n",
    "        \n",
    "    if p < 10:\n",
    "        \n",
    "        Hits_at_10 += 1\n",
    "        \n",
    "    MRR_raw += 1./float(p + 1.) \n",
    "        \n",
    "    print('checkcorrect', (s_pos, r_pos, t_pos), sorted_list[p][0],\n",
    "          'real score', sorted_list[p][-1],\n",
    "          'Hits@1', Hits_at_1/(i+1),\n",
    "          'Hits@3', Hits_at_3/(i+1),\n",
    "          'Hits@10', Hits_at_10/(i+1),\n",
    "          'MRR', MRR_raw/(i+1),\n",
    "          'rank', p,\n",
    "          'total_num', i, len(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa2d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb613b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4951254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6af14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998880eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
