{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba371e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import opensmile\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c098e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadKG:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.x = 'Hello'\n",
    "        \n",
    "    def load_train_data(self, data_path, one_hop, data, s_t_r, entity2id, id2entity,\n",
    "                     relation2id, id2relation):\n",
    "        \n",
    "        data_ = set()\n",
    "    \n",
    "        ####load the train, valid and test set##########\n",
    "        with open (data_path, 'r') as f:\n",
    "            \n",
    "            data_ini = f.readlines()\n",
    "                        \n",
    "            for i in range(len(data_ini)):\n",
    "            \n",
    "                x = data_ini[i].split()\n",
    "                \n",
    "                x_ = tuple(x)\n",
    "                \n",
    "                data_.add(x_)\n",
    "        \n",
    "        ####relation dict#################\n",
    "        index = len(relation2id)\n",
    "     \n",
    "        for key in data_:\n",
    "            \n",
    "            if key[1] not in relation2id:\n",
    "                \n",
    "                relation = key[1]\n",
    "                \n",
    "                relation2id[relation] = index\n",
    "                \n",
    "                id2relation[index] = relation\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "                #the inverse relation\n",
    "                iv_r = '_inverse_' + relation\n",
    "                \n",
    "                relation2id[iv_r] = index\n",
    "                \n",
    "                id2relation[index] = iv_r\n",
    "                \n",
    "                index += 1\n",
    "        \n",
    "        #get the id of the inverse relation, by above definition, initial relation has \n",
    "        #always even id, while inverse relation has always odd id.\n",
    "        def inverse_r(r):\n",
    "            \n",
    "            if r % 2 == 0: #initial relation\n",
    "                \n",
    "                iv_r = r + 1\n",
    "            \n",
    "            else: #inverse relation\n",
    "                \n",
    "                iv_r = r - 1\n",
    "            \n",
    "            return(iv_r)\n",
    "        \n",
    "        ####entity dict###################\n",
    "        index = len(entity2id)\n",
    "        \n",
    "        for key in data_:\n",
    "            \n",
    "            source, target = key[0], key[2]\n",
    "            \n",
    "            if source not in entity2id:\n",
    "                                \n",
    "                entity2id[source] = index\n",
    "                \n",
    "                id2entity[index] = source\n",
    "                \n",
    "                index += 1\n",
    "            \n",
    "            if target not in entity2id:\n",
    "                \n",
    "                entity2id[target] = index\n",
    "                \n",
    "                id2entity[index] = target\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "        #create the set of triples using id instead of string        \n",
    "        for ele in data_:\n",
    "            \n",
    "            s = entity2id[ele[0]]\n",
    "            \n",
    "            r = relation2id[ele[1]]\n",
    "            \n",
    "            t = entity2id[ele[2]]\n",
    "            \n",
    "            if (s,r,t) not in data:\n",
    "                \n",
    "                data.add((s,r,t))\n",
    "            \n",
    "            s_t_r[(s,t)].add(r)\n",
    "            \n",
    "            if s not in one_hop:\n",
    "                \n",
    "                one_hop[s] = dict()\n",
    "            \n",
    "            if r not in one_hop[s]:\n",
    "                \n",
    "                one_hop[s][r] = set()\n",
    "            \n",
    "            one_hop[s][r].add(t)\n",
    "            \n",
    "            if t not in one_hop:\n",
    "                \n",
    "                one_hop[t] = dict()\n",
    "            \n",
    "            r_inv = inverse_r(r)\n",
    "            \n",
    "            s_t_r[(t,s)].add(r_inv)\n",
    "            \n",
    "            if r_inv not in one_hop[t]:\n",
    "                \n",
    "                one_hop[t][r_inv] = set()\n",
    "            \n",
    "            one_hop[t][r_inv].add(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6cd0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObtainPathsByDynamicProgramming:\n",
    "\n",
    "    def __init__(self, size_bd=50, threshold=100000):\n",
    "                \n",
    "        self.size_bd = size_bd\n",
    "        \n",
    "        self.threshold = threshold\n",
    "    \n",
    "    '''\n",
    "    Given an entity s, here is the function to find:\n",
    "      1. any else entity t that is directely connected to s\n",
    "      2. most of the paths from s to each t with length L\n",
    "    \n",
    "    One may refer to LeetCode Problem 797 for details:\n",
    "        https://leetcode.com/problems/all-paths-from-source-to-target/\n",
    "    '''\n",
    "    def obtain_paths(self, mode, s, t_input, lower_bd, upper_bd, one_hop):\n",
    "\n",
    "        if type(lower_bd) != type(1) or lower_bd < 1:\n",
    "            \n",
    "            raise TypeError(\"!!! invalid lower bound setting, must >= 1 !!!\")\n",
    "            \n",
    "        if type(upper_bd) != type(1) or upper_bd < 1:\n",
    "            \n",
    "            raise TypeError(\"!!! invalid upper bound setting, must >= 1 !!!\")\n",
    "            \n",
    "        if lower_bd > upper_bd:\n",
    "            \n",
    "            raise TypeError(\"!!! lower bound must not exced upper bound !!!\")\n",
    "            \n",
    "        if s not in one_hop:\n",
    "            \n",
    "            raise ValueError('!!! entity not in one_hop. Please work on active entities for validation')\n",
    "        \n",
    "        #here is the result dict. Its key is each entity t that is directly connected to s\n",
    "        #The value of each t is a set containing the paths from s to t\n",
    "        #These paths can be either the direct connection r, or a multi-hop path\n",
    "        res = defaultdict(set)\n",
    "        \n",
    "        #direct_nb contains all the direct neighbour of s\n",
    "        direct_nb = set()\n",
    "        \n",
    "        if mode == 'direct_neighbour':\n",
    "        \n",
    "            for r in one_hop[s]:\n",
    "            \n",
    "                for t in one_hop[s][r]:\n",
    "                \n",
    "                    direct_nb.add(t)\n",
    "                    \n",
    "        elif mode == 'target_specified':\n",
    "            \n",
    "            direct_nb.add(t_input)\n",
    "            \n",
    "        elif mode == 'any_target':\n",
    "            \n",
    "            for s_any in one_hop:\n",
    "                \n",
    "                direct_nb.add(s_any)\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            raise ValueError('not a valid mode')\n",
    "        \n",
    "        '''\n",
    "        We use recursion to find the paths\n",
    "        On current node with the path [r1, ..., rk] and on-path entities {e1, ..., ek-1, node}\n",
    "        from s to this node, we further find the direct neighbor t' of this node. \n",
    "        If t' is not a on-path entity (not among e1,...ek-1), we recursively proceed to t' \n",
    "        '''\n",
    "        def helper(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict):\n",
    "            \n",
    "            #when the current path is within lower_bd and upper_bd and its corresponding\n",
    "            #length still within the size_bd and its tail node is within the note dict, \n",
    "            #we will then intend to add this path\n",
    "            if (len(path) >= lower_bd) and (len(path) <= upper_bd) and (\n",
    "                node in direct_nb) and (length_dict[len(path)] < self.size_bd):\n",
    "                \n",
    "                #if this path already exists between the source entity and the current target node,\n",
    "                #we will not count it.\n",
    "                #here is an interesting situation: this path may exist between s and some other node t,\n",
    "                #however, it does not exist between s and this node t. Then, we still count it: length_dict[len(path)] += 1\n",
    "                #That is, each path may be counted for multiple times.\n",
    "                #We count how many paths we \"actually\" found between entity pairs\n",
    "                #Same type of path between different entity pairs are count separately.\n",
    "                if tuple(path) not in res[node]:\n",
    "                \n",
    "                    res[node].add(tuple(path))\n",
    "                \n",
    "                    length_dict[len(path)] += 1\n",
    "                \n",
    "            #For some rare entities, we may face such a case: so many paths are evaluated,\n",
    "            #but no entities on the paths are direct neighbors of the rare entity.\n",
    "            #In this case, the recursion cannot be bounded and stoped by the size threshold.\n",
    "            #In order to cure this, we count how many times the recursion happens on a specific length, using the count_dict.\n",
    "            #Its key is length, value counts the recursion occurred to that length. \n",
    "            #The recursion is forced to stop for that length (and hence for longer lengths) once reach the threshold.\n",
    "            if (len(path) < upper_bd) and (length_dict[len(path) + 1] < self.size_bd) and (\n",
    "                count_dict[len(path)] <= self.threshold):\n",
    "                \n",
    "                #we randomly shuffle relation r so that the reading in order is not fixed\n",
    "                temp_list = list()\n",
    "                \n",
    "                for r in one_hop[node]:\n",
    "                    \n",
    "                    temp_list.append(r)\n",
    "                \n",
    "                for i_0 in range(len(temp_list)):\n",
    "                    \n",
    "                    if count_dict[len(path)] > self.threshold:\n",
    "                        break\n",
    "                    \n",
    "                    r = random.choice(temp_list)\n",
    "                    \n",
    "                    for i_1 in range(len(one_hop[node][r])):\n",
    "                        \n",
    "                        if count_dict[len(path)] > self.threshold:\n",
    "                            break\n",
    "                        \n",
    "                        t = random.choice(list(one_hop[node][r]))\n",
    "                        \n",
    "                        if t not in on_path_en:\n",
    "                                \n",
    "                            count_dict[len(path)] += 1\n",
    "\n",
    "                            helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n",
    "                                   lower_bd, upper_bd, one_hop, length_dict, count_dict)\n",
    "        \n",
    "        length_dict = defaultdict(int)\n",
    "        count_dict = defaultdict(int)\n",
    "        \n",
    "        helper(s, [], {s}, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\n",
    "        \n",
    "        return(res, length_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecaf24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/nell_v4/train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5718867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the classes\n",
    "Class_1 = LoadKG()\n",
    "Class_2 = ObtainPathsByDynamicProgramming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c472f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the dictionaries and sets for load KG\n",
    "one_hop = dict() \n",
    "data = set()\n",
    "s_t_r = defaultdict(set)\n",
    "entity2id = dict()\n",
    "id2entity = dict()\n",
    "relation2id = dict()\n",
    "id2relation = dict()\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(train_path, one_hop, data, s_t_r,\n",
    "                        entity2id, id2entity, relation2id, id2relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8babf",
   "metadata": {},
   "source": [
    "### Build the deep neural network structure\n",
    "\n",
    "We use biLSTM to train on the input path embedding sequence to predict the output embedding or the relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68239c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 22:22:19.735895: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Input layer, using integer to represent each relation type\n",
    "#note that inputs_path is the path inputs, while inputs_out_re is the output relation inputs\n",
    "fst_path = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "scd_path = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "#the relation input layer (for output embedding)\n",
    "id_rela = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Embed each integer in a 300-dimensional vector as input,\n",
    "# note that we add another \"space holder\" embedding, \n",
    "# which hold the spaces if the initial length of two paths are not the same\n",
    "in_embd_var = layers.Embedding(len(relation2id)+1, 300)\n",
    "\n",
    "# Obtain the embedding\n",
    "fst_p_embd = in_embd_var(fst_path)\n",
    "scd_p_embd = in_embd_var(scd_path)\n",
    "\n",
    "# Embed each integer in a 300-dimensional vector as output\n",
    "rela_embd = layers.Embedding(len(relation2id)+1, 300)(id_rela)\n",
    "\n",
    "#add 2 layer bi-directional LSTM\n",
    "lstm_layer_1 = layers.Bidirectional(layers.LSTM(150, return_sequences=True))\n",
    "lstm_layer_2 = layers.Bidirectional(layers.LSTM(150, return_sequences=False))\n",
    "\n",
    "#first LSTM layer\n",
    "fst_lstm_mid = lstm_layer_1(fst_p_embd)\n",
    "scd_lstm_mid = lstm_layer_1(scd_p_embd)\n",
    "\n",
    "#second LSTM layer\n",
    "fst_lstm_out = lstm_layer_2(fst_lstm_mid)\n",
    "scd_lstm_out = lstm_layer_2(scd_lstm_mid)\n",
    "\n",
    "#concatenate the output vector from both siamese tunnel\n",
    "path_concat = layers.concatenate([fst_lstm_out, scd_lstm_out], axis=-1)\n",
    "\n",
    "#remove the time dimension from the output embd since there is only one step\n",
    "sum_r_embd = tf.reduce_sum(rela_embd, axis=1)\n",
    "\n",
    "#concatenate the lstm output and output embd\n",
    "concat = layers.concatenate([path_concat, sum_r_embd], axis=-1)\n",
    "\n",
    "#add the dense layer\n",
    "dense_1 = layers.Dense(32, activation='relu')(concat)\n",
    "batch_norm = layers.BatchNormalization()(dense_1)\n",
    "dropout = layers.Dropout(0.25)(batch_norm)\n",
    "\n",
    "#final layer\n",
    "final_out = layers.Dense(2, activation='softmax')(dropout)\n",
    "\n",
    "#put together the model\n",
    "model = keras.Model([fst_path, scd_path, id_rela], final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6db9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimization settings\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0005, decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fd204f",
   "metadata": {},
   "source": [
    "### Build the batches\n",
    "We build each big-batch for each path combination with length (i,j). Then, we iteratively train the siamese network on different big-batches. The length of each big-batch is N.\n",
    "\n",
    "To be specific:\n",
    "* If we allow the length difference between two paths in a combination to be d, then the combination with path length i and path length j, denoted as (i,j), will be like (2,2), (2,3), (2,4), (3,3), (3,4), (3,5), ... \n",
    "* We will first build all the big-batches before fitting the NN model. \n",
    "* That is, we will perform the ObtainPathsByDynamicProgramming class function for some randomly chosen source entities. Then, for each target entity, we will further have two for loops:\n",
    "* for path_1 in all the \n",
    "* Do this until all the slots in all big-batchs are filled.\n",
    "* In every epoch, big-batchs will be re-filled.\n",
    "\n",
    "Then, in the training, we will use negative sampling: In each batch (actual batch, not the big-batch), we will include K true output relation embeddings and K random selected output relation embeddings. The true label is [1,0], while the false label is [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bb3ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build all the big batches\n",
    "def build_big_batches(diff, holder_len, lower_bd, upper_bd, Class_2, one_hop, s_t_r,\n",
    "                      x_p_dict, x_r_dict, y_dict, path_comb, filled, total_num_need_to_fill,\n",
    "                      relation2id, entity2id, id2relation, id2entity, epoch):\n",
    "    \n",
    "    if holder_len % 10 != 0:\n",
    "        raise ValueError('We would like to take 10X as a big-batch size')\n",
    "    \n",
    "    #the set of all relation IDs\n",
    "    relation_id_set = set()\n",
    "    for i in range(len(id2relation)):\n",
    "        \n",
    "        if i not in id2relation:\n",
    "            raise ValueError('error when generaing id2relation')\n",
    "        \n",
    "        relation_id_set.add(i)\n",
    "    \n",
    "    num_r = len(id2relation)\n",
    "    \n",
    "    #count how many appending has performed\n",
    "    count = 0\n",
    "    \n",
    "    #we count how many combinations need to fill\n",
    "    need_to_fill = set()\n",
    "    \n",
    "    for i in range(lower_bd, upper_bd+1):\n",
    "\n",
    "        Max = min(upper_bd, i+diff)\n",
    "\n",
    "        for j in range(i, Max+1):\n",
    "            \n",
    "            need_to_fill.add((i,j))\n",
    "\n",
    "    #in case not all entities in entity2id are in one_hop, \n",
    "    #so we need to find out who are indeed in\n",
    "    existing_ids = set()\n",
    "    \n",
    "    for s_1 in one_hop:\n",
    "        existing_ids.add(s_1)\n",
    "        \n",
    "    existing_ids = list(existing_ids)\n",
    "    \n",
    "    carry_on = True\n",
    "    \n",
    "    while carry_on:\n",
    "\n",
    "        #obtain paths by dynamic programming\n",
    "        source_id = random.choice(existing_ids)\n",
    "\n",
    "        result, length_dict = Class_2.obtain_paths('direct_neighbour', source_id, \n",
    "                                                   'not_specified', lower_bd, upper_bd, one_hop)\n",
    "        for target_id in result:\n",
    "\n",
    "            if not carry_on:\n",
    "                break\n",
    "            \n",
    "            #we want to make sure s, t are indeed directly connected, \n",
    "            #otherwise there is no relation for positive sample\n",
    "            #also, we want to make sure s and t and not connected by all relations, \n",
    "            #although this situation is rare. \n",
    "            #But in that case, there is no relation for negative samples \n",
    "            if ((source_id, target_id) in s_t_r) and (\n",
    "                len(s_t_r[(source_id, target_id)]) < len(id2relation)):\n",
    "                \n",
    "                dir_r = list(s_t_r[(source_id, target_id)])\n",
    "                \n",
    "                non_dir_r = list(relation_id_set.difference(dir_r))\n",
    "                \n",
    "                if len(dir_r) <= 0:\n",
    "                    \n",
    "                    raise ValueError('errors when creating s_t_r !!')\n",
    "                \n",
    "                #iterate over path_1\n",
    "                for path_1 in result[target_id]:\n",
    "\n",
    "                    if not carry_on:\n",
    "                        break\n",
    "\n",
    "                    #iterate over path_2\n",
    "                    for path_2 in result[target_id]:\n",
    "\n",
    "                        if not carry_on:\n",
    "                            break\n",
    "\n",
    "                        #decide which path is shorter and which is longer\n",
    "                        if len(path_1) <= len(path_2):\n",
    "\n",
    "                            path_s, path_l = path_1, path_2\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            path_s, path_l = path_2, path_1                            \n",
    "\n",
    "                        #whether lengths of the two paths satisfies the requirments\n",
    "                        if (len(path_s) >= lower_bd) and (len(path_l) <= upper_bd) and (\n",
    "                            abs(len(path_s)-len(path_l)) <= diff):\n",
    "\n",
    "                            #further consider: whether the corresponding length comb is not full,\n",
    "                            #and whether this path pair is new, and whether the two paths are different\n",
    "                            #But it is optional to require the path to be new. \n",
    "                            #We may remove this requirment, especially for short paths\n",
    "                            '''remember to cancel the comment below when using path_comb'''\n",
    "                            if (len(y_dict[(len(path_s), len(path_l))]) < holder_len) and (\n",
    "                                path_s != path_l):\n",
    "                                \n",
    "                                #we always add one positive and one negative situation together,\n",
    "                                #hence, the length of list should always be even.\n",
    "                                #also we want to make sure the length of lists coincide\n",
    "                                if (len(x_p_dict[(len(path_s), len(path_l))]['s']) != len(\n",
    "                                    y_dict[(len(path_s), len(path_l))])) or (\n",
    "                                    len(x_p_dict[(len(path_s), len(path_l))]['s']) != len(\n",
    "                                        x_p_dict[(len(path_s), len(path_l))]['l'])) or (\n",
    "                                    len(y_dict[(len(path_s), len(path_l))]) != len(\n",
    "                                        x_r_dict[(len(path_s), len(path_l))])) or (\n",
    "                                    len(y_dict[(len(path_s), len(path_l))]) % 2 != 0):\n",
    "                                    \n",
    "                                    raise ValueError('error when building big batches: length error')\n",
    "                                \n",
    "                                #####positive#####################\n",
    "                                relation_id = random.choice(dir_r)\n",
    "                                \n",
    "                                #append the paths: note that we add the space holder id at the end\n",
    "                                #of the shorter path\n",
    "                                x_p_dict[(len(path_s), len(path_l))]['s'].append(\n",
    "                                          list(path_s) + [num_r]*abs(len(path_s)-len(path_l)))\n",
    "                                x_p_dict[(len(path_s), len(path_l))]['l'].append(list(path_l))\n",
    "\n",
    "                                #append relation\n",
    "                                x_r_dict[(len(path_s), len(path_l))].append([relation_id])\n",
    "                                y_dict[(len(path_s), len(path_l))].append([1., 0.])\n",
    "                                \n",
    "                                #####negative#####################\n",
    "                                relation_id = random.choice(non_dir_r)\n",
    "                                \n",
    "                                #append the paths: note that we add the space holder id at the end\n",
    "                                #of the shorter path\n",
    "                                x_p_dict[(len(path_s), len(path_l))]['s'].append(\n",
    "                                          list(path_s) + [num_r]*abs(len(path_s)-len(path_l)))\n",
    "                                x_p_dict[(len(path_s), len(path_l))]['l'].append(list(path_l))\n",
    "\n",
    "                                #append relation\n",
    "                                x_r_dict[(len(path_s), len(path_l))].append([relation_id])\n",
    "                                y_dict[(len(path_s), len(path_l))].append([0., 1.])\n",
    "                                \n",
    "                                ######add to path combinations#####\n",
    "                                #here is the tricky part: we have to add both (path_s, path_l)\n",
    "                                #and (path_l, path_s). This is because when the length are the same\n",
    "                                #adding only one situation won't guarantee that \n",
    "                                #the same path with different order is also considered.\n",
    "                                #in other words: path combination don't have order, but our dict does.\n",
    "                                #so we have to add both situations.\n",
    "                                '''remember to cancel the comment here when using path_comb'''\n",
    "                                #path_comb[(len(path_s), len(path_l))].add((path_s, path_l))\n",
    "                                #path_comb[(len(path_s), len(path_l))].add((path_l, path_s))\n",
    "                                \n",
    "                                count += 1\n",
    "                                \n",
    "                                if count % 10000 == 0:\n",
    "                                    print('generating big-batches', count, \n",
    "                                          int(holder_len*0.5*len(need_to_fill)), 'in epoch', epoch)\n",
    "                                \n",
    "                            if len(y_dict[(len(path_s), len(path_l))]) >= holder_len:\n",
    "                                \n",
    "                                prev_size = len(filled)\n",
    "\n",
    "                                filled.add((len(path_s), len(path_l)))\n",
    "                                \n",
    "                                post_size = len(filled)\n",
    "                                \n",
    "                                #when we indeed find a new filled combo, we will print, which looks like:\n",
    "                                #big-batches 1 ( 2 2 ) in N completed in epoch k\n",
    "                                #big-batches 2 ( 3 5 ) in N completed in epoch k\n",
    "                                #big-batches 3 ( 3 4 ) in N completed in epoch k\n",
    "                                if post_size > prev_size:\n",
    "\n",
    "                                    print('big-batches', len(filled), \n",
    "                                          '(', len(path_s), len(path_l), ')',\n",
    "                                          'in', total_num_need_to_fill, \n",
    "                                          'completed in epoch', epoch)\n",
    "                        \n",
    "                        #check whether to finish\n",
    "                        if len(need_to_fill.difference(filled)) == 0:\n",
    "                            \n",
    "                            carry_on = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e0ac2",
   "metadata": {},
   "source": [
    "### Start Training: load the KG and call classes\n",
    "\n",
    "Here, we use the validation set to see the training efficiency. That is, we use the validation to check whether the true relation between entities can be predicted by paths.\n",
    "\n",
    "The trick is: in validation, we have to use the same relation ID and entity ID as in the training. But we don't want to use the links in training anymore. That is, in validation, we want to use (and update if necessary) entity2id, id2entity, relation2id and id2relation. But we want to use new one_hop, data, data_ and s_t_r for validation set. Then, path-finding will also be based on new one_hop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf14347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#difine the names for saving\n",
    "model_name = 'Model_main_1_nell_v4'\n",
    "ids_name = 'IDs_main_1_nell_v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f57c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, we save the relation and ids\n",
    "Dict = dict()\n",
    "Dict['one_hop'] = one_hop\n",
    "Dict['data'] = data\n",
    "Dict['s_t_r'] = s_t_r\n",
    "Dict['entity2id'] = entity2id\n",
    "Dict['id2entity'] = id2entity\n",
    "Dict['relation2id'] = relation2id\n",
    "Dict['id2relation'] = id2relation\n",
    "\n",
    "with open('../weight_bin/' + ids_name + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(Dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25a5deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating big-batches 10000 100000 in epoch 0\n",
      "generating big-batches 20000 100000 in epoch 0\n",
      "generating big-batches 30000 100000 in epoch 0\n",
      "generating big-batches 40000 100000 in epoch 0\n",
      "generating big-batches 50000 100000 in epoch 0\n",
      "generating big-batches 60000 100000 in epoch 0\n",
      "generating big-batches 70000 100000 in epoch 0\n",
      "generating big-batches 80000 100000 in epoch 0\n",
      "generating big-batches 90000 100000 in epoch 0\n",
      "generating big-batches 100000 100000 in epoch 0\n",
      "big-batches 1 ( 2 2 ) in 9 completed in epoch 0\n",
      "generating big-batches 10000 900000 in epoch 0\n",
      "generating big-batches 20000 900000 in epoch 0\n",
      "generating big-batches 30000 900000 in epoch 0\n",
      "generating big-batches 40000 900000 in epoch 0\n",
      "generating big-batches 50000 900000 in epoch 0\n",
      "generating big-batches 60000 900000 in epoch 0\n",
      "generating big-batches 70000 900000 in epoch 0\n",
      "generating big-batches 80000 900000 in epoch 0\n",
      "generating big-batches 90000 900000 in epoch 0\n",
      "generating big-batches 100000 900000 in epoch 0\n",
      "generating big-batches 110000 900000 in epoch 0\n",
      "generating big-batches 120000 900000 in epoch 0\n",
      "generating big-batches 130000 900000 in epoch 0\n",
      "generating big-batches 140000 900000 in epoch 0\n",
      "generating big-batches 150000 900000 in epoch 0\n",
      "generating big-batches 160000 900000 in epoch 0\n",
      "generating big-batches 170000 900000 in epoch 0\n",
      "generating big-batches 180000 900000 in epoch 0\n",
      "generating big-batches 190000 900000 in epoch 0\n",
      "generating big-batches 200000 900000 in epoch 0\n",
      "generating big-batches 210000 900000 in epoch 0\n",
      "generating big-batches 220000 900000 in epoch 0\n",
      "generating big-batches 230000 900000 in epoch 0\n",
      "generating big-batches 240000 900000 in epoch 0\n",
      "generating big-batches 250000 900000 in epoch 0\n",
      "generating big-batches 260000 900000 in epoch 0\n",
      "generating big-batches 270000 900000 in epoch 0\n",
      "generating big-batches 280000 900000 in epoch 0\n",
      "generating big-batches 290000 900000 in epoch 0\n",
      "generating big-batches 300000 900000 in epoch 0\n",
      "generating big-batches 310000 900000 in epoch 0\n",
      "generating big-batches 320000 900000 in epoch 0\n",
      "big-batches 2 ( 4 5 ) in 9 completed in epoch 0\n",
      "generating big-batches 330000 900000 in epoch 0\n",
      "generating big-batches 340000 900000 in epoch 0\n",
      "generating big-batches 350000 900000 in epoch 0\n",
      "generating big-batches 360000 900000 in epoch 0\n",
      "generating big-batches 370000 900000 in epoch 0\n",
      "generating big-batches 380000 900000 in epoch 0\n",
      "generating big-batches 390000 900000 in epoch 0\n",
      "generating big-batches 400000 900000 in epoch 0\n",
      "generating big-batches 410000 900000 in epoch 0\n",
      "generating big-batches 420000 900000 in epoch 0\n",
      "generating big-batches 430000 900000 in epoch 0\n",
      "generating big-batches 440000 900000 in epoch 0\n",
      "generating big-batches 450000 900000 in epoch 0\n",
      "big-batches 3 ( 5 5 ) in 9 completed in epoch 0\n",
      "generating big-batches 460000 900000 in epoch 0\n",
      "generating big-batches 470000 900000 in epoch 0\n",
      "generating big-batches 480000 900000 in epoch 0\n",
      "generating big-batches 490000 900000 in epoch 0\n",
      "generating big-batches 500000 900000 in epoch 0\n",
      "generating big-batches 510000 900000 in epoch 0\n",
      "generating big-batches 520000 900000 in epoch 0\n",
      "big-batches 4 ( 4 4 ) in 9 completed in epoch 0\n",
      "generating big-batches 530000 900000 in epoch 0\n",
      "generating big-batches 540000 900000 in epoch 0\n",
      "generating big-batches 550000 900000 in epoch 0\n",
      "big-batches 5 ( 3 5 ) in 9 completed in epoch 0\n",
      "big-batches 6 ( 3 4 ) in 9 completed in epoch 0\n",
      "generating big-batches 560000 900000 in epoch 0\n",
      "generating big-batches 570000 900000 in epoch 0\n",
      "generating big-batches 580000 900000 in epoch 0\n",
      "generating big-batches 590000 900000 in epoch 0\n",
      "generating big-batches 600000 900000 in epoch 0\n",
      "generating big-batches 610000 900000 in epoch 0\n",
      "generating big-batches 620000 900000 in epoch 0\n",
      "generating big-batches 630000 900000 in epoch 0\n",
      "generating big-batches 640000 900000 in epoch 0\n",
      "generating big-batches 650000 900000 in epoch 0\n",
      "big-batches 7 ( 3 3 ) in 9 completed in epoch 0\n",
      "generating big-batches 660000 900000 in epoch 0\n",
      "generating big-batches 670000 900000 in epoch 0\n",
      "generating big-batches 680000 900000 in epoch 0\n",
      "generating big-batches 690000 900000 in epoch 0\n",
      "generating big-batches 700000 900000 in epoch 0\n",
      "generating big-batches 710000 900000 in epoch 0\n",
      "generating big-batches 720000 900000 in epoch 0\n",
      "generating big-batches 730000 900000 in epoch 0\n",
      "generating big-batches 740000 900000 in epoch 0\n",
      "generating big-batches 750000 900000 in epoch 0\n",
      "generating big-batches 760000 900000 in epoch 0\n",
      "generating big-batches 770000 900000 in epoch 0\n",
      "generating big-batches 780000 900000 in epoch 0\n",
      "big-batches 8 ( 2 4 ) in 9 completed in epoch 0\n",
      "generating big-batches 790000 900000 in epoch 0\n",
      "generating big-batches 800000 900000 in epoch 0\n",
      "big-batches 9 ( 2 3 ) in 9 completed in epoch 0\n",
      "training on length (2, 2) for epoch 0\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 207s 5ms/step - loss: 0.3543 - categorical_accuracy: 0.8584 - val_loss: 0.1945 - val_categorical_accuracy: 0.9344\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 1164s 26ms/step - loss: 0.3209 - categorical_accuracy: 0.8744 - val_loss: 0.1890 - val_categorical_accuracy: 0.9383\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 1113s 25ms/step - loss: 0.3110 - categorical_accuracy: 0.8794 - val_loss: 0.1964 - val_categorical_accuracy: 0.9413\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 201s 4ms/step - loss: 0.3068 - categorical_accuracy: 0.8816 - val_loss: 0.1863 - val_categorical_accuracy: 0.9454\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 219s 5ms/step - loss: 0.2989 - categorical_accuracy: 0.8844 - val_loss: 0.1789 - val_categorical_accuracy: 0.9449\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 226s 5ms/step - loss: 0.2974 - categorical_accuracy: 0.8869 - val_loss: 0.1797 - val_categorical_accuracy: 0.9481\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 233s 5ms/step - loss: 0.2902 - categorical_accuracy: 0.8878 - val_loss: 0.1757 - val_categorical_accuracy: 0.9492\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 237s 5ms/step - loss: 0.2915 - categorical_accuracy: 0.8876 - val_loss: 0.1628 - val_categorical_accuracy: 0.9501\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 241s 5ms/step - loss: 0.2854 - categorical_accuracy: 0.8898 - val_loss: 0.1681 - val_categorical_accuracy: 0.9515\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 242s 5ms/step - loss: 0.2848 - categorical_accuracy: 0.8905 - val_loss: 0.1763 - val_categorical_accuracy: 0.9491\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 244s 5ms/step - loss: 0.2813 - categorical_accuracy: 0.8911 - val_loss: 0.1681 - val_categorical_accuracy: 0.9522\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 246s 5ms/step - loss: 0.2796 - categorical_accuracy: 0.8914 - val_loss: 0.1604 - val_categorical_accuracy: 0.9546\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 248s 6ms/step - loss: 0.2782 - categorical_accuracy: 0.8924 - val_loss: 0.1743 - val_categorical_accuracy: 0.9541\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 246s 5ms/step - loss: 0.2732 - categorical_accuracy: 0.8956 - val_loss: 0.1584 - val_categorical_accuracy: 0.9533\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 250s 6ms/step - loss: 0.2758 - categorical_accuracy: 0.8927 - val_loss: 0.1713 - val_categorical_accuracy: 0.9506\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 248s 6ms/step - loss: 0.2706 - categorical_accuracy: 0.8956 - val_loss: 0.1787 - val_categorical_accuracy: 0.9539\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 249s 6ms/step - loss: 0.2713 - categorical_accuracy: 0.8953 - val_loss: 0.1599 - val_categorical_accuracy: 0.9560\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 1996s 44ms/step - loss: 0.2671 - categorical_accuracy: 0.8968 - val_loss: 0.1610 - val_categorical_accuracy: 0.9557\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 2004s 45ms/step - loss: 0.2683 - categorical_accuracy: 0.8958 - val_loss: 0.1604 - val_categorical_accuracy: 0.9574\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 196s 4ms/step - loss: 0.2683 - categorical_accuracy: 0.8960 - val_loss: 0.1661 - val_categorical_accuracy: 0.9548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model\n",
      "training on length (2, 3) for epoch 0\n",
      "load model\n",
      "Epoch 21/40\n",
      "45000/45000 [==============================] - 269s 6ms/step - loss: 0.2941 - categorical_accuracy: 0.8873 - val_loss: 0.1744 - val_categorical_accuracy: 0.9479\n",
      "Epoch 22/40\n",
      "45000/45000 [==============================] - 281s 6ms/step - loss: 0.2789 - categorical_accuracy: 0.8920 - val_loss: 0.1585 - val_categorical_accuracy: 0.9481\n",
      "Epoch 23/40\n",
      "45000/45000 [==============================] - 289s 6ms/step - loss: 0.2710 - categorical_accuracy: 0.8951 - val_loss: 0.1583 - val_categorical_accuracy: 0.9520\n",
      "Epoch 24/40\n",
      "45000/45000 [==============================] - 296s 7ms/step - loss: 0.2675 - categorical_accuracy: 0.8964 - val_loss: 0.1553 - val_categorical_accuracy: 0.9533\n",
      "Epoch 25/40\n",
      "45000/45000 [==============================] - 304s 7ms/step - loss: 0.2643 - categorical_accuracy: 0.8982 - val_loss: 0.1528 - val_categorical_accuracy: 0.9518\n",
      "Epoch 26/40\n",
      "45000/45000 [==============================] - 306s 7ms/step - loss: 0.2586 - categorical_accuracy: 0.9005 - val_loss: 0.1625 - val_categorical_accuracy: 0.9542\n",
      "Epoch 27/40\n",
      "45000/45000 [==============================] - 308s 7ms/step - loss: 0.2597 - categorical_accuracy: 0.8987 - val_loss: 0.1602 - val_categorical_accuracy: 0.9550\n",
      "Epoch 28/40\n",
      "45000/45000 [==============================] - 311s 7ms/step - loss: 0.2604 - categorical_accuracy: 0.8982 - val_loss: 0.1453 - val_categorical_accuracy: 0.9568\n",
      "Epoch 29/40\n",
      "45000/45000 [==============================] - 311s 7ms/step - loss: 0.2556 - categorical_accuracy: 0.9000 - val_loss: 0.1523 - val_categorical_accuracy: 0.9564\n",
      "Epoch 30/40\n",
      "45000/45000 [==============================] - 313s 7ms/step - loss: 0.2550 - categorical_accuracy: 0.9011 - val_loss: 0.1523 - val_categorical_accuracy: 0.9582\n",
      "Epoch 31/40\n",
      "45000/45000 [==============================] - 317s 7ms/step - loss: 0.2511 - categorical_accuracy: 0.9017 - val_loss: 0.1477 - val_categorical_accuracy: 0.9582\n",
      "Epoch 32/40\n",
      "45000/45000 [==============================] - 4102s 91ms/step - loss: 0.2502 - categorical_accuracy: 0.9022 - val_loss: 0.1426 - val_categorical_accuracy: 0.9581\n",
      "Epoch 33/40\n",
      "45000/45000 [==============================] - 1150s 26ms/step - loss: 0.2489 - categorical_accuracy: 0.9018 - val_loss: 0.1513 - val_categorical_accuracy: 0.9579\n",
      "Epoch 34/40\n",
      "45000/45000 [==============================] - 257s 6ms/step - loss: 0.2502 - categorical_accuracy: 0.9026 - val_loss: 0.1479 - val_categorical_accuracy: 0.9595\n",
      "Epoch 35/40\n",
      "45000/45000 [==============================] - 278s 6ms/step - loss: 0.2490 - categorical_accuracy: 0.9017 - val_loss: 0.1407 - val_categorical_accuracy: 0.9609\n",
      "Epoch 36/40\n",
      "45000/45000 [==============================] - 288s 6ms/step - loss: 0.2462 - categorical_accuracy: 0.9042 - val_loss: 0.1451 - val_categorical_accuracy: 0.9569\n",
      "Epoch 37/40\n",
      "45000/45000 [==============================] - 297s 7ms/step - loss: 0.2448 - categorical_accuracy: 0.9050 - val_loss: 0.1417 - val_categorical_accuracy: 0.9587\n",
      "Epoch 38/40\n",
      "45000/45000 [==============================] - 303s 7ms/step - loss: 0.2396 - categorical_accuracy: 0.9062 - val_loss: 0.1458 - val_categorical_accuracy: 0.9599\n",
      "Epoch 39/40\n",
      "45000/45000 [==============================] - 307s 7ms/step - loss: 0.2446 - categorical_accuracy: 0.9043 - val_loss: 0.1648 - val_categorical_accuracy: 0.9613\n",
      "Epoch 40/40\n",
      "45000/45000 [==============================] - 310s 7ms/step - loss: 0.2432 - categorical_accuracy: 0.9037 - val_loss: 0.1428 - val_categorical_accuracy: 0.9596\n",
      "Save model\n",
      "training on length (2, 4) for epoch 0\n",
      "load model\n",
      "Epoch 41/60\n",
      "45000/45000 [==============================] - 383s 8ms/step - loss: 0.2612 - categorical_accuracy: 0.8981 - val_loss: 0.1484 - val_categorical_accuracy: 0.9533\n",
      "Epoch 42/60\n",
      "45000/45000 [==============================] - 379s 8ms/step - loss: 0.2583 - categorical_accuracy: 0.8982 - val_loss: 0.1439 - val_categorical_accuracy: 0.9506\n",
      "Epoch 43/60\n",
      "45000/45000 [==============================] - 387s 9ms/step - loss: 0.2471 - categorical_accuracy: 0.9040 - val_loss: 0.1614 - val_categorical_accuracy: 0.9524\n",
      "Epoch 44/60\n",
      "45000/45000 [==============================] - 690s 15ms/step - loss: 0.2472 - categorical_accuracy: 0.9033 - val_loss: 0.1468 - val_categorical_accuracy: 0.9517\n",
      "Epoch 45/60\n",
      "45000/45000 [==============================] - 1197s 27ms/step - loss: 0.2496 - categorical_accuracy: 0.9026 - val_loss: 0.1458 - val_categorical_accuracy: 0.9528\n",
      "Epoch 46/60\n",
      "45000/45000 [==============================] - 349s 8ms/step - loss: 0.2495 - categorical_accuracy: 0.9019 - val_loss: 0.1530 - val_categorical_accuracy: 0.9516\n",
      "Epoch 47/60\n",
      "45000/45000 [==============================] - 367s 8ms/step - loss: 0.2451 - categorical_accuracy: 0.9043 - val_loss: 0.1538 - val_categorical_accuracy: 0.9531\n",
      "Epoch 48/60\n",
      "45000/45000 [==============================] - 373s 8ms/step - loss: 0.2435 - categorical_accuracy: 0.9047 - val_loss: 0.1482 - val_categorical_accuracy: 0.9534\n",
      "Epoch 49/60\n",
      "45000/45000 [==============================] - 378s 8ms/step - loss: 0.2427 - categorical_accuracy: 0.9048 - val_loss: 0.1371 - val_categorical_accuracy: 0.9538\n",
      "Epoch 50/60\n",
      "45000/45000 [==============================] - 378s 8ms/step - loss: 0.2420 - categorical_accuracy: 0.9048 - val_loss: 0.1549 - val_categorical_accuracy: 0.9544\n",
      "Epoch 51/60\n",
      "45000/45000 [==============================] - 381s 8ms/step - loss: 0.2411 - categorical_accuracy: 0.9043 - val_loss: 0.1477 - val_categorical_accuracy: 0.9538\n",
      "Epoch 52/60\n",
      "45000/45000 [==============================] - 384s 9ms/step - loss: 0.2393 - categorical_accuracy: 0.9061 - val_loss: 0.1542 - val_categorical_accuracy: 0.9537\n",
      "Epoch 53/60\n",
      "45000/45000 [==============================] - 384s 9ms/step - loss: 0.2383 - categorical_accuracy: 0.9054 - val_loss: 0.1427 - val_categorical_accuracy: 0.9524\n",
      "Epoch 54/60\n",
      "45000/45000 [==============================] - 1272s 28ms/step - loss: 0.2372 - categorical_accuracy: 0.9066 - val_loss: 0.1363 - val_categorical_accuracy: 0.9535\n",
      "Epoch 55/60\n",
      "45000/45000 [==============================] - 2215s 49ms/step - loss: 0.2363 - categorical_accuracy: 0.9071 - val_loss: 0.1442 - val_categorical_accuracy: 0.9541\n",
      "Epoch 56/60\n",
      "45000/45000 [==============================] - 325s 7ms/step - loss: 0.2367 - categorical_accuracy: 0.9065 - val_loss: 0.1565 - val_categorical_accuracy: 0.9516\n",
      "Epoch 57/60\n",
      "45000/45000 [==============================] - 349s 8ms/step - loss: 0.2370 - categorical_accuracy: 0.9062 - val_loss: 0.1481 - val_categorical_accuracy: 0.9507\n",
      "Epoch 58/60\n",
      "45000/45000 [==============================] - 360s 8ms/step - loss: 0.2339 - categorical_accuracy: 0.9077 - val_loss: 0.1441 - val_categorical_accuracy: 0.9524\n",
      "Epoch 59/60\n",
      "45000/45000 [==============================] - 366s 8ms/step - loss: 0.2338 - categorical_accuracy: 0.9065 - val_loss: 0.1521 - val_categorical_accuracy: 0.9520\n",
      "Epoch 60/60\n",
      "45000/45000 [==============================] - 372s 8ms/step - loss: 0.2319 - categorical_accuracy: 0.9073 - val_loss: 0.1504 - val_categorical_accuracy: 0.9521\n",
      "Save model\n",
      "training on length (3, 3) for epoch 0\n",
      "load model\n",
      "Epoch 61/80\n",
      "45000/45000 [==============================] - 315s 7ms/step - loss: 0.2898 - categorical_accuracy: 0.8862 - val_loss: 0.1521 - val_categorical_accuracy: 0.9477\n",
      "Epoch 62/80\n",
      "45000/45000 [==============================] - 313s 7ms/step - loss: 0.2693 - categorical_accuracy: 0.8948 - val_loss: 0.1937 - val_categorical_accuracy: 0.9508\n",
      "Epoch 63/80\n",
      "45000/45000 [==============================] - 314s 7ms/step - loss: 0.2534 - categorical_accuracy: 0.9016 - val_loss: 0.1576 - val_categorical_accuracy: 0.9524\n",
      "Epoch 64/80\n",
      "45000/45000 [==============================] - 315s 7ms/step - loss: 0.2480 - categorical_accuracy: 0.9029 - val_loss: 0.1713 - val_categorical_accuracy: 0.9538\n",
      "Epoch 65/80\n",
      "45000/45000 [==============================] - 316s 7ms/step - loss: 0.2456 - categorical_accuracy: 0.9035 - val_loss: 0.1632 - val_categorical_accuracy: 0.9564\n",
      "Epoch 66/80\n",
      "45000/45000 [==============================] - 2151s 48ms/step - loss: 0.2402 - categorical_accuracy: 0.9069 - val_loss: 0.1427 - val_categorical_accuracy: 0.9599\n",
      "Epoch 67/80\n",
      "45000/45000 [==============================] - 259s 6ms/step - loss: 0.2420 - categorical_accuracy: 0.9047 - val_loss: 0.1364 - val_categorical_accuracy: 0.9610\n",
      "Epoch 68/80\n",
      "45000/45000 [==============================] - 280s 6ms/step - loss: 0.2386 - categorical_accuracy: 0.9060 - val_loss: 0.1772 - val_categorical_accuracy: 0.9575\n",
      "Epoch 69/80\n",
      "45000/45000 [==============================] - 292s 6ms/step - loss: 0.2389 - categorical_accuracy: 0.9053 - val_loss: 0.1364 - val_categorical_accuracy: 0.9572\n",
      "Epoch 70/80\n",
      "45000/45000 [==============================] - 303s 7ms/step - loss: 0.2353 - categorical_accuracy: 0.9073 - val_loss: 0.1550 - val_categorical_accuracy: 0.9581\n",
      "Epoch 71/80\n",
      "45000/45000 [==============================] - 312s 7ms/step - loss: 0.2352 - categorical_accuracy: 0.9067 - val_loss: 0.1588 - val_categorical_accuracy: 0.9560\n",
      "Epoch 72/80\n",
      "45000/45000 [==============================] - 327s 7ms/step - loss: 0.2300 - categorical_accuracy: 0.9084 - val_loss: 0.1475 - val_categorical_accuracy: 0.9573\n",
      "Epoch 73/80\n",
      "45000/45000 [==============================] - 344s 8ms/step - loss: 0.2291 - categorical_accuracy: 0.9091 - val_loss: 0.1443 - val_categorical_accuracy: 0.9579\n",
      "Epoch 74/80\n",
      "45000/45000 [==============================] - 410s 9ms/step - loss: 0.2262 - categorical_accuracy: 0.9110 - val_loss: 0.1537 - val_categorical_accuracy: 0.9590\n",
      "Epoch 75/80\n",
      "45000/45000 [==============================] - 430s 10ms/step - loss: 0.2279 - categorical_accuracy: 0.9089 - val_loss: 0.1501 - val_categorical_accuracy: 0.9579\n",
      "Epoch 76/80\n",
      "45000/45000 [==============================] - 474s 11ms/step - loss: 0.2291 - categorical_accuracy: 0.9088 - val_loss: 0.1486 - val_categorical_accuracy: 0.9596\n",
      "Epoch 77/80\n",
      "45000/45000 [==============================] - 1334s 30ms/step - loss: 0.2257 - categorical_accuracy: 0.9091 - val_loss: 0.1422 - val_categorical_accuracy: 0.9595\n",
      "Epoch 78/80\n",
      "45000/45000 [==============================] - 290s 6ms/step - loss: 0.2206 - categorical_accuracy: 0.9115 - val_loss: 0.1655 - val_categorical_accuracy: 0.9580\n",
      "Epoch 79/80\n",
      "45000/45000 [==============================] - 326s 7ms/step - loss: 0.2267 - categorical_accuracy: 0.9097 - val_loss: 0.1461 - val_categorical_accuracy: 0.9564\n",
      "Epoch 80/80\n",
      "45000/45000 [==============================] - 351s 8ms/step - loss: 0.2226 - categorical_accuracy: 0.9107 - val_loss: 0.1375 - val_categorical_accuracy: 0.9589\n",
      "Save model\n",
      "training on length (3, 4) for epoch 0\n",
      "load model\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 525s 12ms/step - loss: 0.2551 - categorical_accuracy: 0.8995 - val_loss: 0.1168 - val_categorical_accuracy: 0.9719\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 598s 13ms/step - loss: 0.2405 - categorical_accuracy: 0.9047 - val_loss: 0.1109 - val_categorical_accuracy: 0.9740\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 604s 13ms/step - loss: 0.2336 - categorical_accuracy: 0.9076 - val_loss: 0.1216 - val_categorical_accuracy: 0.9715\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 488s 11ms/step - loss: 0.2299 - categorical_accuracy: 0.9089 - val_loss: 0.1120 - val_categorical_accuracy: 0.9745\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 286s 6ms/step - loss: 0.2261 - categorical_accuracy: 0.9094 - val_loss: 0.1137 - val_categorical_accuracy: 0.9742\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 288s 6ms/step - loss: 0.2231 - categorical_accuracy: 0.9107 - val_loss: 0.1157 - val_categorical_accuracy: 0.9734\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 286s 6ms/step - loss: 0.2203 - categorical_accuracy: 0.9121 - val_loss: 0.1193 - val_categorical_accuracy: 0.9706\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 1277s 28ms/step - loss: 0.2200 - categorical_accuracy: 0.9117 - val_loss: 0.1199 - val_categorical_accuracy: 0.9699\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 643s 14ms/step - loss: 0.2146 - categorical_accuracy: 0.9136 - val_loss: 0.2484 - val_categorical_accuracy: 0.8943\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 288s 6ms/step - loss: 0.2163 - categorical_accuracy: 0.9122 - val_loss: 0.2164 - val_categorical_accuracy: 0.9077\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 288s 6ms/step - loss: 0.2151 - categorical_accuracy: 0.9127 - val_loss: 0.1580 - val_categorical_accuracy: 0.9428\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 285s 6ms/step - loss: 0.2106 - categorical_accuracy: 0.9143 - val_loss: 0.3647 - val_categorical_accuracy: 0.8742\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 485s 11ms/step - loss: 0.2126 - categorical_accuracy: 0.9135 - val_loss: 0.2928 - val_categorical_accuracy: 0.8882\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 373s 8ms/step - loss: 0.2102 - categorical_accuracy: 0.9140 - val_loss: 0.2508 - val_categorical_accuracy: 0.9011\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 284s 6ms/step - loss: 0.2110 - categorical_accuracy: 0.9131 - val_loss: 0.1776 - val_categorical_accuracy: 0.9308\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 296s 7ms/step - loss: 0.2113 - categorical_accuracy: 0.9127 - val_loss: 0.2290 - val_categorical_accuracy: 0.9064\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 305s 7ms/step - loss: 0.2077 - categorical_accuracy: 0.9154 - val_loss: 0.2726 - val_categorical_accuracy: 0.8855\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 298s 7ms/step - loss: 0.2077 - categorical_accuracy: 0.9154 - val_loss: 0.2798 - val_categorical_accuracy: 0.8914\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 291s 6ms/step - loss: 0.2069 - categorical_accuracy: 0.9155 - val_loss: 0.3178 - val_categorical_accuracy: 0.8809\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 291s 6ms/step - loss: 0.2073 - categorical_accuracy: 0.9151 - val_loss: 0.2768 - val_categorical_accuracy: 0.8874\n",
      "Save model\n",
      "training on length (3, 5) for epoch 0\n",
      "load model\n",
      "Epoch 101/120\n",
      "45000/45000 [==============================] - 338s 7ms/step - loss: 0.2309 - categorical_accuracy: 0.9082 - val_loss: 0.1136 - val_categorical_accuracy: 0.9653\n",
      "Epoch 102/120\n",
      "45000/45000 [==============================] - 335s 7ms/step - loss: 0.2207 - categorical_accuracy: 0.9113 - val_loss: 0.1134 - val_categorical_accuracy: 0.9696\n",
      "Epoch 103/120\n",
      "45000/45000 [==============================] - 335s 7ms/step - loss: 0.2192 - categorical_accuracy: 0.9116 - val_loss: 0.1112 - val_categorical_accuracy: 0.9694\n",
      "Epoch 104/120\n",
      "45000/45000 [==============================] - 331s 7ms/step - loss: 0.2182 - categorical_accuracy: 0.9114 - val_loss: 0.1279 - val_categorical_accuracy: 0.9672\n",
      "Epoch 105/120\n",
      "45000/45000 [==============================] - 327s 7ms/step - loss: 0.2137 - categorical_accuracy: 0.9136 - val_loss: 0.1186 - val_categorical_accuracy: 0.9682\n",
      "Epoch 106/120\n",
      "45000/45000 [==============================] - 1904s 42ms/step - loss: 0.2135 - categorical_accuracy: 0.9129 - val_loss: 0.1224 - val_categorical_accuracy: 0.9676\n",
      "Epoch 107/120\n",
      "45000/45000 [==============================] - 2290s 51ms/step - loss: 0.2104 - categorical_accuracy: 0.9150 - val_loss: 0.1151 - val_categorical_accuracy: 0.9686\n",
      "Epoch 108/120\n",
      "45000/45000 [==============================] - 2547s 57ms/step - loss: 0.2095 - categorical_accuracy: 0.9144 - val_loss: 0.1113 - val_categorical_accuracy: 0.9700\n",
      "Epoch 109/120\n",
      "45000/45000 [==============================] - 348s 8ms/step - loss: 0.2098 - categorical_accuracy: 0.9136 - val_loss: 0.1140 - val_categorical_accuracy: 0.9661\n",
      "Epoch 110/120\n",
      "45000/45000 [==============================] - 345s 8ms/step - loss: 0.2065 - categorical_accuracy: 0.9160 - val_loss: 0.1193 - val_categorical_accuracy: 0.9678\n",
      "Epoch 111/120\n",
      "45000/45000 [==============================] - 337s 7ms/step - loss: 0.2051 - categorical_accuracy: 0.9164 - val_loss: 0.1345 - val_categorical_accuracy: 0.9661\n",
      "Epoch 112/120\n",
      "45000/45000 [==============================] - 346s 8ms/step - loss: 0.2047 - categorical_accuracy: 0.9158 - val_loss: 0.1311 - val_categorical_accuracy: 0.9650\n",
      "Epoch 113/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 348s 8ms/step - loss: 0.2091 - categorical_accuracy: 0.9138 - val_loss: 0.1245 - val_categorical_accuracy: 0.9664\n",
      "Epoch 114/120\n",
      "45000/45000 [==============================] - 336s 7ms/step - loss: 0.2023 - categorical_accuracy: 0.9168 - val_loss: 0.1277 - val_categorical_accuracy: 0.9651\n",
      "Epoch 115/120\n",
      "45000/45000 [==============================] - 347s 8ms/step - loss: 0.1994 - categorical_accuracy: 0.9173 - val_loss: 0.1295 - val_categorical_accuracy: 0.9674\n",
      "Epoch 116/120\n",
      "45000/45000 [==============================] - 357s 8ms/step - loss: 0.2031 - categorical_accuracy: 0.9160 - val_loss: 0.1597 - val_categorical_accuracy: 0.9656\n",
      "Epoch 117/120\n",
      "45000/45000 [==============================] - 353s 8ms/step - loss: 0.2016 - categorical_accuracy: 0.9157 - val_loss: 0.1552 - val_categorical_accuracy: 0.9669\n",
      "Epoch 118/120\n",
      "45000/45000 [==============================] - 353s 8ms/step - loss: 0.2012 - categorical_accuracy: 0.9158 - val_loss: 0.1421 - val_categorical_accuracy: 0.9664\n",
      "Epoch 119/120\n",
      "45000/45000 [==============================] - 360s 8ms/step - loss: 0.1978 - categorical_accuracy: 0.9187 - val_loss: 0.1514 - val_categorical_accuracy: 0.9664\n",
      "Epoch 120/120\n",
      "45000/45000 [==============================] - 345s 8ms/step - loss: 0.2017 - categorical_accuracy: 0.9150 - val_loss: 0.1758 - val_categorical_accuracy: 0.9613\n",
      "Save model\n",
      "training on length (4, 4) for epoch 0\n",
      "load model\n",
      "Epoch 121/140\n",
      "45000/45000 [==============================] - 301s 7ms/step - loss: 0.2453 - categorical_accuracy: 0.9029 - val_loss: 0.1043 - val_categorical_accuracy: 0.9688\n",
      "Epoch 122/140\n",
      "45000/45000 [==============================] - 297s 7ms/step - loss: 0.2263 - categorical_accuracy: 0.9093 - val_loss: 0.1174 - val_categorical_accuracy: 0.9640\n",
      "Epoch 123/140\n",
      "45000/45000 [==============================] - 297s 7ms/step - loss: 0.2211 - categorical_accuracy: 0.9096 - val_loss: 0.1307 - val_categorical_accuracy: 0.9628\n",
      "Epoch 124/140\n",
      "45000/45000 [==============================] - 297s 7ms/step - loss: 0.2157 - categorical_accuracy: 0.9118 - val_loss: 0.1298 - val_categorical_accuracy: 0.9616\n",
      "Epoch 125/140\n",
      "45000/45000 [==============================] - 292s 6ms/step - loss: 0.2098 - categorical_accuracy: 0.9141 - val_loss: 0.1332 - val_categorical_accuracy: 0.9620\n",
      "Epoch 126/140\n",
      "45000/45000 [==============================] - 291s 6ms/step - loss: 0.2058 - categorical_accuracy: 0.9156 - val_loss: 0.1346 - val_categorical_accuracy: 0.9611\n",
      "Epoch 127/140\n",
      "45000/45000 [==============================] - 291s 6ms/step - loss: 0.2028 - categorical_accuracy: 0.9163 - val_loss: 0.1520 - val_categorical_accuracy: 0.9574\n",
      "Epoch 128/140\n",
      "45000/45000 [==============================] - 292s 6ms/step - loss: 0.2041 - categorical_accuracy: 0.9160 - val_loss: 0.1626 - val_categorical_accuracy: 0.9557\n",
      "Epoch 129/140\n",
      "45000/45000 [==============================] - 293s 7ms/step - loss: 0.2032 - categorical_accuracy: 0.9153 - val_loss: 0.1549 - val_categorical_accuracy: 0.9556\n",
      "Epoch 130/140\n",
      "45000/45000 [==============================] - 292s 6ms/step - loss: 0.1999 - categorical_accuracy: 0.9161 - val_loss: 0.1474 - val_categorical_accuracy: 0.9557\n",
      "Epoch 131/140\n",
      "45000/45000 [==============================] - 299s 7ms/step - loss: 0.1997 - categorical_accuracy: 0.9169 - val_loss: 0.1621 - val_categorical_accuracy: 0.9549\n",
      "Epoch 132/140\n",
      "45000/45000 [==============================] - 291s 6ms/step - loss: 0.2003 - categorical_accuracy: 0.9160 - val_loss: 0.1764 - val_categorical_accuracy: 0.9517\n",
      "Epoch 133/140\n",
      "45000/45000 [==============================] - 290s 6ms/step - loss: 0.1989 - categorical_accuracy: 0.9167 - val_loss: 0.1785 - val_categorical_accuracy: 0.9516\n",
      "Epoch 134/140\n",
      "45000/45000 [==============================] - 291s 6ms/step - loss: 0.1994 - categorical_accuracy: 0.9166 - val_loss: 0.1898 - val_categorical_accuracy: 0.9510\n",
      "Epoch 135/140\n",
      "45000/45000 [==============================] - 286s 6ms/step - loss: 0.1963 - categorical_accuracy: 0.9179 - val_loss: 0.1791 - val_categorical_accuracy: 0.9532\n",
      "Epoch 136/140\n",
      "45000/45000 [==============================] - 284s 6ms/step - loss: 0.1959 - categorical_accuracy: 0.9173 - val_loss: 0.1726 - val_categorical_accuracy: 0.9515\n",
      "Epoch 137/140\n",
      "45000/45000 [==============================] - 3189s 71ms/step - loss: 0.1983 - categorical_accuracy: 0.9161 - val_loss: 0.2066 - val_categorical_accuracy: 0.9475\n",
      "Epoch 138/140\n",
      "45000/45000 [==============================] - 3928s 87ms/step - loss: 0.1964 - categorical_accuracy: 0.9171 - val_loss: 0.2011 - val_categorical_accuracy: 0.9478\n",
      "Epoch 139/140\n",
      "45000/45000 [==============================] - 3759s 84ms/step - loss: 0.1907 - categorical_accuracy: 0.9201 - val_loss: 0.2145 - val_categorical_accuracy: 0.9473\n",
      "Epoch 140/140\n",
      "45000/45000 [==============================] - 293s 7ms/step - loss: 0.1936 - categorical_accuracy: 0.9180 - val_loss: 0.2255 - val_categorical_accuracy: 0.9477\n",
      "Save model\n",
      "training on length (4, 5) for epoch 0\n",
      "load model\n",
      "Epoch 141/160\n",
      "45000/45000 [==============================] - 357s 8ms/step - loss: 0.2133 - categorical_accuracy: 0.9118 - val_loss: 0.0632 - val_categorical_accuracy: 0.9839\n",
      "Epoch 142/160\n",
      "45000/45000 [==============================] - 344s 8ms/step - loss: 0.2035 - categorical_accuracy: 0.9153 - val_loss: 0.0689 - val_categorical_accuracy: 0.9831\n",
      "Epoch 143/160\n",
      "45000/45000 [==============================] - 340s 8ms/step - loss: 0.2009 - categorical_accuracy: 0.9150 - val_loss: 0.0682 - val_categorical_accuracy: 0.9814\n",
      "Epoch 144/160\n",
      "45000/45000 [==============================] - 345s 8ms/step - loss: 0.1953 - categorical_accuracy: 0.9175 - val_loss: 0.0668 - val_categorical_accuracy: 0.9800\n",
      "Epoch 145/160\n",
      "45000/45000 [==============================] - 347s 8ms/step - loss: 0.1914 - categorical_accuracy: 0.9194 - val_loss: 0.0691 - val_categorical_accuracy: 0.9814\n",
      "Epoch 146/160\n",
      "45000/45000 [==============================] - 341s 8ms/step - loss: 0.1927 - categorical_accuracy: 0.9177 - val_loss: 0.0731 - val_categorical_accuracy: 0.9787\n",
      "Epoch 147/160\n",
      "45000/45000 [==============================] - 331s 7ms/step - loss: 0.1907 - categorical_accuracy: 0.9187 - val_loss: 0.0797 - val_categorical_accuracy: 0.9730\n",
      "Epoch 148/160\n",
      "45000/45000 [==============================] - 934s 21ms/step - loss: 0.1886 - categorical_accuracy: 0.9195 - val_loss: 0.0836 - val_categorical_accuracy: 0.9746\n",
      "Epoch 149/160\n",
      "45000/45000 [==============================] - 1694s 38ms/step - loss: 0.1881 - categorical_accuracy: 0.9194 - val_loss: 0.0891 - val_categorical_accuracy: 0.9714\n",
      "Epoch 150/160\n",
      "45000/45000 [==============================] - 379s 8ms/step - loss: 0.1895 - categorical_accuracy: 0.9197 - val_loss: 0.0842 - val_categorical_accuracy: 0.9733\n",
      "Epoch 151/160\n",
      "45000/45000 [==============================] - 364s 8ms/step - loss: 0.1834 - categorical_accuracy: 0.9214 - val_loss: 0.0881 - val_categorical_accuracy: 0.9701\n",
      "Epoch 152/160\n",
      "45000/45000 [==============================] - 351s 8ms/step - loss: 0.1868 - categorical_accuracy: 0.9199 - val_loss: 0.0824 - val_categorical_accuracy: 0.9726\n",
      "Epoch 153/160\n",
      "45000/45000 [==============================] - 330s 7ms/step - loss: 0.1838 - categorical_accuracy: 0.9213 - val_loss: 0.0880 - val_categorical_accuracy: 0.9690\n",
      "Epoch 154/160\n",
      "45000/45000 [==============================] - 2231s 50ms/step - loss: 0.1831 - categorical_accuracy: 0.9210 - val_loss: 0.0907 - val_categorical_accuracy: 0.9692\n",
      "Epoch 155/160\n",
      "45000/45000 [==============================] - 5999s 133ms/step - loss: 0.1839 - categorical_accuracy: 0.9207 - val_loss: 0.0921 - val_categorical_accuracy: 0.9671\n",
      "Epoch 156/160\n",
      "45000/45000 [==============================] - 1395s 31ms/step - loss: 0.1819 - categorical_accuracy: 0.9217 - val_loss: 0.1148 - val_categorical_accuracy: 0.9625\n",
      "Epoch 157/160\n",
      "45000/45000 [==============================] - 393s 9ms/step - loss: 0.1854 - categorical_accuracy: 0.9195 - val_loss: 0.1018 - val_categorical_accuracy: 0.9643\n",
      "Epoch 158/160\n",
      "45000/45000 [==============================] - 416s 9ms/step - loss: 0.1857 - categorical_accuracy: 0.9193 - val_loss: 0.1057 - val_categorical_accuracy: 0.9639\n",
      "Epoch 159/160\n",
      "45000/45000 [==============================] - 430s 10ms/step - loss: 0.1813 - categorical_accuracy: 0.9217 - val_loss: 0.1002 - val_categorical_accuracy: 0.9645\n",
      "Epoch 160/160\n",
      "45000/45000 [==============================] - 443s 10ms/step - loss: 0.1825 - categorical_accuracy: 0.9211 - val_loss: 0.1054 - val_categorical_accuracy: 0.9644\n",
      "Save model\n",
      "training on length (5, 5) for epoch 0\n",
      "load model\n",
      "Epoch 161/180\n",
      "45000/45000 [==============================] - 460s 10ms/step - loss: 0.2276 - categorical_accuracy: 0.9074 - val_loss: 0.1996 - val_categorical_accuracy: 0.9139\n",
      "Epoch 162/180\n",
      "45000/45000 [==============================] - 463s 10ms/step - loss: 0.2073 - categorical_accuracy: 0.9147 - val_loss: 0.1758 - val_categorical_accuracy: 0.9394\n",
      "Epoch 163/180\n",
      "45000/45000 [==============================] - 487s 11ms/step - loss: 0.1997 - categorical_accuracy: 0.9171 - val_loss: 0.1725 - val_categorical_accuracy: 0.9391\n",
      "Epoch 164/180\n",
      "45000/45000 [==============================] - 2295s 51ms/step - loss: 0.1983 - categorical_accuracy: 0.9164 - val_loss: 0.1682 - val_categorical_accuracy: 0.9451\n",
      "Epoch 165/180\n",
      "45000/45000 [==============================] - 373s 8ms/step - loss: 0.1965 - categorical_accuracy: 0.9170 - val_loss: 0.1761 - val_categorical_accuracy: 0.9417\n",
      "Epoch 166/180\n",
      "45000/45000 [==============================] - 420s 9ms/step - loss: 0.1949 - categorical_accuracy: 0.9167 - val_loss: 0.2067 - val_categorical_accuracy: 0.9301\n",
      "Epoch 167/180\n",
      "45000/45000 [==============================] - 440s 10ms/step - loss: 0.1898 - categorical_accuracy: 0.9192 - val_loss: 0.2257 - val_categorical_accuracy: 0.9268\n",
      "Epoch 168/180\n",
      "45000/45000 [==============================] - 450s 10ms/step - loss: 0.1904 - categorical_accuracy: 0.9188 - val_loss: 0.2692 - val_categorical_accuracy: 0.8944\n",
      "Epoch 169/180\n",
      "45000/45000 [==============================] - 459s 10ms/step - loss: 0.1920 - categorical_accuracy: 0.9180 - val_loss: 0.2380 - val_categorical_accuracy: 0.9118\n",
      "Epoch 170/180\n",
      "45000/45000 [==============================] - 462s 10ms/step - loss: 0.1914 - categorical_accuracy: 0.9177 - val_loss: 0.2603 - val_categorical_accuracy: 0.9004\n",
      "Epoch 171/180\n",
      "45000/45000 [==============================] - 465s 10ms/step - loss: 0.1899 - categorical_accuracy: 0.9178 - val_loss: 0.2458 - val_categorical_accuracy: 0.9097\n",
      "Epoch 172/180\n",
      "45000/45000 [==============================] - 467s 10ms/step - loss: 0.1872 - categorical_accuracy: 0.9187 - val_loss: 0.2715 - val_categorical_accuracy: 0.8846\n",
      "Epoch 173/180\n",
      "45000/45000 [==============================] - 3289s 73ms/step - loss: 0.1835 - categorical_accuracy: 0.9210 - val_loss: 0.2442 - val_categorical_accuracy: 0.8977\n",
      "Epoch 174/180\n",
      "45000/45000 [==============================] - 392s 9ms/step - loss: 0.1845 - categorical_accuracy: 0.9205 - val_loss: 0.2519 - val_categorical_accuracy: 0.8908\n",
      "Epoch 175/180\n",
      "45000/45000 [==============================] - 418s 9ms/step - loss: 0.1849 - categorical_accuracy: 0.9198 - val_loss: 0.2466 - val_categorical_accuracy: 0.8906\n",
      "Epoch 176/180\n",
      "45000/45000 [==============================] - 436s 10ms/step - loss: 0.1842 - categorical_accuracy: 0.9196 - val_loss: 0.3355 - val_categorical_accuracy: 0.8668\n",
      "Epoch 177/180\n",
      "45000/45000 [==============================] - 447s 10ms/step - loss: 0.1848 - categorical_accuracy: 0.9199 - val_loss: 0.3370 - val_categorical_accuracy: 0.8655\n",
      "Epoch 178/180\n",
      "45000/45000 [==============================] - 460s 10ms/step - loss: 0.1827 - categorical_accuracy: 0.9204 - val_loss: 0.4236 - val_categorical_accuracy: 0.8571\n",
      "Epoch 179/180\n",
      "45000/45000 [==============================] - 484s 11ms/step - loss: 0.1833 - categorical_accuracy: 0.9197 - val_loss: 0.3414 - val_categorical_accuracy: 0.8672\n",
      "Epoch 180/180\n",
      "45000/45000 [==============================] - 477s 11ms/step - loss: 0.1814 - categorical_accuracy: 0.9210 - val_loss: 0.3399 - val_categorical_accuracy: 0.8650\n",
      "Save model\n"
     ]
    }
   ],
   "source": [
    "holder_len = 200000\n",
    "lower_bd = 2\n",
    "upper_bd = 5\n",
    "diff = 2\n",
    "each_epoch = 20\n",
    "entire_epoch = 0\n",
    "\n",
    "#90% to be train, 10% to be validation\n",
    "train_len = 9*int(holder_len/10)\n",
    "\n",
    "current = 0\n",
    "    \n",
    "######################################\n",
    "###pre-define the lists###############\n",
    "\n",
    "#define the lists\n",
    "x_p_list, x_p_dict, x_r_dict, y_dict, path_comb = list(), dict(), dict(), dict(), dict()\n",
    "filled, total_num_need_to_fill = set(), 0\n",
    "\n",
    "#build the lists first\n",
    "for i in range(lower_bd, upper_bd+1):\n",
    "\n",
    "    Max = min(upper_bd, i+diff)\n",
    "\n",
    "    for j in range(i, Max+1):\n",
    "\n",
    "        x_p_list.append((i,j))\n",
    "        x_p_dict[(i,j)] = {'s': [], 'l': []}\n",
    "        x_r_dict[(i,j)] = list()\n",
    "        y_dict[(i,j)] = list()\n",
    "        path_comb[(i,j)] = set()\n",
    "        total_num_need_to_fill += 1\n",
    "\n",
    "#######################################\n",
    "###build the big-batches###############\n",
    "\n",
    "#here is a tricky thing: if the distance between upper_bd and lower_bd is big,\n",
    "#then when run path_finding_dynamic_programming, \n",
    "#the chance to obtain paths with length close to lower bd is low.\n",
    "#For instance, if lower_bd = 2, upper_bd = 10, then most found paths will have length\n",
    "#from 6 to 10. Paths with length 2 or 3 is relatively rare.\n",
    "#Hence, we need to first build big-batches for combination between shorter lengths.\n",
    "#otherwise the while loop may last for really really long time,\n",
    "#due to difficulty to find shorter paths.\n",
    "build_big_batches(diff, holder_len, lower_bd, lower_bd, Class_2, one_hop, s_t_r,\n",
    "                      x_p_dict, x_r_dict, y_dict, path_comb, filled, total_num_need_to_fill,\n",
    "                      relation2id, entity2id, id2relation, id2entity, entire_epoch)    \n",
    "\n",
    "if upper_bd - lower_bd > 3:\n",
    "\n",
    "    build_big_batches(diff, holder_len, lower_bd, lower_bd + 3, Class_2, one_hop, s_t_r,\n",
    "                      x_p_dict, x_r_dict, y_dict, path_comb, filled, total_num_need_to_fill,\n",
    "                      relation2id, entity2id, id2relation, id2entity, entire_epoch)        \n",
    "\n",
    "#fill in the training array list\n",
    "build_big_batches(diff, holder_len, lower_bd, upper_bd, Class_2, one_hop, s_t_r,\n",
    "                      x_p_dict, x_r_dict, y_dict, path_comb, filled, total_num_need_to_fill,\n",
    "                      relation2id, entity2id, id2relation, id2entity, entire_epoch)\n",
    "\n",
    "#######################################\n",
    "###do the training#####################\n",
    "for key in x_p_list:\n",
    "\n",
    "    #generate the input arrays\n",
    "    x_train_s = np.asarray(x_p_dict[key]['s'][:train_len], dtype='int')\n",
    "    x_train_l = np.asarray(x_p_dict[key]['l'][:train_len], dtype='int')\n",
    "    x_train_r = np.asarray(x_r_dict[key][:train_len], dtype='int')\n",
    "    y_train = np.asarray(y_dict[key][:train_len], dtype='int')\n",
    "\n",
    "    x_valid_s = np.asarray(x_p_dict[key]['s'][train_len:], dtype='int')\n",
    "    x_valid_l = np.asarray(x_p_dict[key]['l'][train_len:], dtype='int')\n",
    "    x_valid_r = np.asarray(x_r_dict[key][train_len:], dtype='int')\n",
    "    y_valid = np.asarray(y_dict[key][train_len:], dtype='int')\n",
    "\n",
    "    print('training on length', key, 'for epoch', entire_epoch)\n",
    "\n",
    "    #we use a bit dummy method: in order to make sure the model is saved,\n",
    "    #we save it at each length pair in each epoch!!!\n",
    "    #so unless it is the first pair first epoch, we will always read from previous checkpoint\n",
    "    if key != x_p_list[0]:\n",
    "\n",
    "        print('load model')\n",
    "\n",
    "        model = keras.models.load_model('../weight_bin/' + model_name + '.h5')\n",
    "\n",
    "    else:\n",
    "\n",
    "        #compile the model\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=[\"categorical_accuracy\"],)\n",
    "\n",
    "    model.fit([x_train_s, x_train_l, x_train_r], y_train, \n",
    "              validation_data=([x_valid_s, x_valid_l, x_valid_r], y_valid),\n",
    "              batch_size=4, epochs=current+each_epoch, initial_epoch=current)\n",
    "\n",
    "    current += each_epoch\n",
    "\n",
    "    # Save model and weights\n",
    "    add_h5 = model_name + '.h5'\n",
    "    save_dir = os.path.join(os.getcwd(), '../weight_bin')\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, add_h5)\n",
    "    model.save(model_path)\n",
    "    print('Save model')\n",
    "    del(model)\n",
    "\n",
    "    del(x_train_s, x_train_l, x_train_r, y_train)\n",
    "    del(x_valid_s, x_valid_l, x_valid_r, y_valid)\n",
    "\n",
    "del(x_p_list, x_p_dict, x_r_dict, y_dict, path_comb)\n",
    "del(filled, total_num_need_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af0572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04108cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da50338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14b6bf00",
   "metadata": {},
   "source": [
    "### Result on the testset for inductive link prediction\n",
    "\n",
    "We use the testset for inductive link prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f959af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import opensmile\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c81c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadKG:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.x = 'Hello'\n",
    "        \n",
    "    def load_train_data(self, data_path, one_hop, data, s_t_r, entity2id, id2entity,\n",
    "                     relation2id, id2relation):\n",
    "        \n",
    "        data_ = set()\n",
    "    \n",
    "        ####load the train, valid and test set##########\n",
    "        with open (data_path, 'r') as f:\n",
    "            \n",
    "            data_ini = f.readlines()\n",
    "                        \n",
    "            for i in range(len(data_ini)):\n",
    "            \n",
    "                x = data_ini[i].split()\n",
    "                \n",
    "                x_ = tuple(x)\n",
    "                \n",
    "                data_.add(x_)\n",
    "        \n",
    "        ####relation dict#################\n",
    "        index = len(relation2id)\n",
    "     \n",
    "        for key in data_:\n",
    "            \n",
    "            if key[1] not in relation2id:\n",
    "                \n",
    "                relation = key[1]\n",
    "                \n",
    "                relation2id[relation] = index\n",
    "                \n",
    "                id2relation[index] = relation\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "                #the inverse relation\n",
    "                iv_r = '_inverse_' + relation\n",
    "                \n",
    "                relation2id[iv_r] = index\n",
    "                \n",
    "                id2relation[index] = iv_r\n",
    "                \n",
    "                index += 1\n",
    "        \n",
    "        #get the id of the inverse relation, by above definition, initial relation has \n",
    "        #always even id, while inverse relation has always odd id.\n",
    "        def inverse_r(r):\n",
    "            \n",
    "            if r % 2 == 0: #initial relation\n",
    "                \n",
    "                iv_r = r + 1\n",
    "            \n",
    "            else: #inverse relation\n",
    "                \n",
    "                iv_r = r - 1\n",
    "            \n",
    "            return(iv_r)\n",
    "        \n",
    "        ####entity dict###################\n",
    "        index = len(entity2id)\n",
    "        \n",
    "        for key in data_:\n",
    "            \n",
    "            source, target = key[0], key[2]\n",
    "            \n",
    "            if source not in entity2id:\n",
    "                                \n",
    "                entity2id[source] = index\n",
    "                \n",
    "                id2entity[index] = source\n",
    "                \n",
    "                index += 1\n",
    "            \n",
    "            if target not in entity2id:\n",
    "                \n",
    "                entity2id[target] = index\n",
    "                \n",
    "                id2entity[index] = target\n",
    "                \n",
    "                index += 1\n",
    "                \n",
    "        #create the set of triples using id instead of string        \n",
    "        for ele in data_:\n",
    "            \n",
    "            s = entity2id[ele[0]]\n",
    "            \n",
    "            r = relation2id[ele[1]]\n",
    "            \n",
    "            t = entity2id[ele[2]]\n",
    "            \n",
    "            if (s,r,t) not in data:\n",
    "                \n",
    "                data.add((s,r,t))\n",
    "            \n",
    "            s_t_r[(s,t)].add(r)\n",
    "            \n",
    "            if s not in one_hop:\n",
    "                \n",
    "                one_hop[s] = dict()\n",
    "            \n",
    "            if r not in one_hop[s]:\n",
    "                \n",
    "                one_hop[s][r] = set()\n",
    "            \n",
    "            one_hop[s][r].add(t)\n",
    "            \n",
    "            if t not in one_hop:\n",
    "                \n",
    "                one_hop[t] = dict()\n",
    "            \n",
    "            r_inv = inverse_r(r)\n",
    "            \n",
    "            s_t_r[(t,s)].add(r_inv)\n",
    "            \n",
    "            if r_inv not in one_hop[t]:\n",
    "                \n",
    "                one_hop[t][r_inv] = set()\n",
    "            \n",
    "            one_hop[t][r_inv].add(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a714e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObtainPathsByDynamicProgramming:\n",
    "\n",
    "    def __init__(self, size_bd=50, threshold=100000):\n",
    "                \n",
    "        self.size_bd = size_bd\n",
    "        \n",
    "        self.threshold = threshold\n",
    "    \n",
    "    '''\n",
    "    Given an entity s, here is the function to find:\n",
    "      1. any else entity t that is directely connected to s\n",
    "      2. most of the paths from s to each t with length L\n",
    "    \n",
    "    One may refer to LeetCode Problem 797 for details:\n",
    "        https://leetcode.com/problems/all-paths-from-source-to-target/\n",
    "    '''\n",
    "    def obtain_paths(self, mode, s, t_input, lower_bd, upper_bd, one_hop):\n",
    "\n",
    "        if type(lower_bd) != type(1) or lower_bd < 1:\n",
    "            \n",
    "            raise TypeError(\"!!! invalid lower bound setting, must >= 1 !!!\")\n",
    "            \n",
    "        if type(upper_bd) != type(1) or upper_bd < 1:\n",
    "            \n",
    "            raise TypeError(\"!!! invalid upper bound setting, must >= 1 !!!\")\n",
    "            \n",
    "        if lower_bd > upper_bd:\n",
    "            \n",
    "            raise TypeError(\"!!! lower bound must not exced upper bound !!!\")\n",
    "            \n",
    "        if s not in one_hop:\n",
    "            \n",
    "            raise ValueError('!!! entity not in one_hop. Please work on active entities for validation')\n",
    "        \n",
    "        #here is the result dict. Its key is each entity t that is directly connected to s\n",
    "        #The value of each t is a set containing the paths from s to t\n",
    "        #These paths can be either the direct connection r, or a multi-hop path\n",
    "        res = defaultdict(set)\n",
    "        \n",
    "        #direct_nb contains all the direct neighbour of s\n",
    "        direct_nb = set()\n",
    "        \n",
    "        if mode == 'direct_neighbour':\n",
    "        \n",
    "            for r in one_hop[s]:\n",
    "            \n",
    "                for t in one_hop[s][r]:\n",
    "                \n",
    "                    direct_nb.add(t)\n",
    "                    \n",
    "        elif mode == 'target_specified':\n",
    "            \n",
    "            direct_nb.add(t_input)\n",
    "            \n",
    "        elif mode == 'any_target':\n",
    "            \n",
    "            for s_any in one_hop:\n",
    "                \n",
    "                direct_nb.add(s_any)\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            raise ValueError('not a valid mode')\n",
    "        \n",
    "        '''\n",
    "        We use recursion to find the paths\n",
    "        On current node with the path [r1, ..., rk] and on-path entities {e1, ..., ek-1, node}\n",
    "        from s to this node, we further find the direct neighbor t' of this node. \n",
    "        If t' is not a on-path entity (not among e1,...ek-1), we recursively proceed to t' \n",
    "        '''\n",
    "        def helper(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict):\n",
    "            \n",
    "            #when the current path is within lower_bd and upper_bd and its corresponding\n",
    "            #length still within the size_bd and its tail node is within the note dict, \n",
    "            #we will then intend to add this path\n",
    "            if (len(path) >= lower_bd) and (len(path) <= upper_bd) and (\n",
    "                node in direct_nb) and (length_dict[len(path)] < self.size_bd):\n",
    "                \n",
    "                #if this path already exists between the source entity and the current target node,\n",
    "                #we will not count it.\n",
    "                #here is an interesting situation: this path may exist between s and some other node t,\n",
    "                #however, it does not exist between s and this node t. Then, we still count it: length_dict[len(path)] += 1\n",
    "                #That is, each path may be counted for multiple times.\n",
    "                #We count how many paths we \"actually\" found between entity pairs\n",
    "                #Same type of path between different entity pairs are count separately.\n",
    "                if tuple(path) not in res[node]:\n",
    "                \n",
    "                    res[node].add(tuple(path))\n",
    "                \n",
    "                    length_dict[len(path)] += 1\n",
    "                \n",
    "            #For some rare entities, we may face such a case: so many paths are evaluated,\n",
    "            #but no entities on the paths are direct neighbors of the rare entity.\n",
    "            #In this case, the recursion cannot be bounded and stoped by the size threshold.\n",
    "            #In order to cure this, we count how many times the recursion happens on a specific length, using the count_dict.\n",
    "            #Its key is length, value counts the recursion occurred to that length. \n",
    "            #The recursion is forced to stop for that length (and hence for longer lengths) once reach the threshold.\n",
    "            if (len(path) < upper_bd) and (length_dict[len(path) + 1] < self.size_bd) and (\n",
    "                count_dict[len(path)] <= self.threshold):\n",
    "                \n",
    "                #we randomly shuffle relation r so that the reading in order is not fixed\n",
    "                temp_list = list()\n",
    "                \n",
    "                for r in one_hop[node]:\n",
    "                    \n",
    "                    temp_list.append(r)\n",
    "                \n",
    "                for i_0 in range(len(temp_list)):\n",
    "                    \n",
    "                    if count_dict[len(path)] > self.threshold:\n",
    "                        break\n",
    "                    \n",
    "                    r = random.choice(temp_list)\n",
    "                    \n",
    "                    for i_1 in range(len(one_hop[node][r])):\n",
    "                        \n",
    "                        if count_dict[len(path)] > self.threshold:\n",
    "                            break\n",
    "                        \n",
    "                        t = random.choice(list(one_hop[node][r]))\n",
    "                        \n",
    "                        if t not in on_path_en:\n",
    "                                \n",
    "                            count_dict[len(path)] += 1\n",
    "\n",
    "                            helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n",
    "                                   lower_bd, upper_bd, one_hop, length_dict, count_dict)\n",
    "        \n",
    "        length_dict = defaultdict(int)\n",
    "        count_dict = defaultdict(int)\n",
    "        \n",
    "        helper(s, [], {s}, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\n",
    "        \n",
    "        return(res, length_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d1f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the classes\n",
    "Class_1 = LoadKG()\n",
    "Class_2 = ObtainPathsByDynamicProgramming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f13661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ids and relation/entity dicts\n",
    "with open('../weight_bin/IDs_main_1_nell_v4.pickle', 'rb') as handle:\n",
    "    Dict = pickle.load(handle)\n",
    "\n",
    "one_hop = Dict['one_hop']\n",
    "data = Dict['data']\n",
    "s_t_r = Dict['s_t_r']\n",
    "entity2id = Dict['entity2id']\n",
    "id2entity = Dict['id2entity']\n",
    "relation2id = Dict['relation2id']\n",
    "id2relation = Dict['id2relation']\n",
    "\n",
    "#we want to keep the initial entity/relation dicts\n",
    "entity2id_ini = deepcopy(entity2id)\n",
    "id2entity_ini = deepcopy(id2entity)\n",
    "relation2id_ini = deepcopy(relation2id)\n",
    "id2relation_ini = deepcopy(id2relation)\n",
    "\n",
    "num_r = len(id2relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50c64cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 07:46:36.552120: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "model = keras.models.load_model('../weight_bin/Model_main_1_nell_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ea521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_path = '../data/nell_v4_ind/train.txt'\n",
    "ind_valid_path = '../data/nell_v4_ind/valid.txt'\n",
    "ind_test_path = '../data/nell_v4_ind/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d2e6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test dataset\n",
    "one_hop_ind = dict() \n",
    "data_ind = set()\n",
    "s_t_r_ind = defaultdict(set)\n",
    "\n",
    "len_0 = len(relation2id)\n",
    "size_0 = len(entity2id)\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(ind_train_path, \n",
    "                        one_hop_ind, data_ind, s_t_r_ind,\n",
    "                        entity2id, id2entity, relation2id, id2relation)\n",
    "\n",
    "len_1 = len(relation2id)\n",
    "size_1 = len(entity2id)\n",
    "\n",
    "if len_0 != len_1:\n",
    "    raise ValueError('unseen relation!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a6dfe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2092 4886 7073\n"
     ]
    }
   ],
   "source": [
    "print(size_0, size_1, len(data_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63cec98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test dataset\n",
    "one_hop_test = dict() \n",
    "data_test = set()\n",
    "s_t_r_test = defaultdict(set)\n",
    "\n",
    "len_0 = len(relation2id)\n",
    "size_0 = len(entity2id)\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(ind_test_path, \n",
    "                        one_hop_test, data_test, s_t_r_test,\n",
    "                        entity2id, id2entity, relation2id, id2relation)\n",
    "\n",
    "\n",
    "len_1 = len(relation2id)\n",
    "size_1 = len(entity2id)\n",
    "\n",
    "if len_0 != len_1:\n",
    "    raise ValueError('unseen relation!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d18fee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4886 4886 731\n"
     ]
    }
   ],
   "source": [
    "print(size_0, size_1, len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "757526ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the validation for existing triple removal when ranking\n",
    "one_hop_valid = dict() \n",
    "data_valid = set()\n",
    "s_t_r_valid = defaultdict(set)\n",
    "\n",
    "len_0 = len(relation2id)\n",
    "size_0 = len(entity2id)\n",
    "\n",
    "#fill in the sets and dicts\n",
    "Class_1.load_train_data(ind_valid_path, \n",
    "                        one_hop_valid, data_valid, s_t_r_valid,\n",
    "                        entity2id, id2entity, relation2id, id2relation)\n",
    "\n",
    "len_1 = len(relation2id)\n",
    "size_1 = len(entity2id)\n",
    "\n",
    "if len_0 != len_1:\n",
    "    raise ValueError('unseen relation!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2980a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4886 4886 716\n"
     ]
    }
   ],
   "source": [
    "print(size_0, size_1, len(data_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f17ff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4886 2092\n"
     ]
    }
   ],
   "source": [
    "print(len(entity2id), len(entity2id_ini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "915ad29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to check whether there are overlapping \n",
    "#between the entities of train triples and inductive test and valid triples\n",
    "overlapping = 0\n",
    "\n",
    "for ele in data_test:\n",
    "    \n",
    "    s, r, t = ele[0], ele[1], ele[2]\n",
    "    \n",
    "    if s in id2entity_ini or t in id2entity_ini:\n",
    "        \n",
    "        overlapping += 1\n",
    "        \n",
    "overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80eb1e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlapping = 0\n",
    "\n",
    "for ele in data_valid:\n",
    "    \n",
    "    s, r, t = ele[0], ele[1], ele[2]\n",
    "    \n",
    "    if s in id2entity_ini or t in id2entity_ini:\n",
    "        \n",
    "        overlapping += 1\n",
    "        \n",
    "overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a3c9dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to check whether there are overlapping \n",
    "#between the entities of train triples and inductive test and valid triples\n",
    "overlapping = 0\n",
    "\n",
    "for ele in data_ind:\n",
    "    \n",
    "    s, r, t = ele[0], ele[1], ele[2]\n",
    "    \n",
    "    if s in id2entity_ini or t in id2entity_ini:\n",
    "        \n",
    "        overlapping += 1\n",
    "        \n",
    "overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83ea5533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_ranking(s, t, diff, lower_bd, upper_bd, one_hop, id2relation, model):\n",
    "    \n",
    "    path_holder = set()\n",
    "    \n",
    "    for iteration in range(20):\n",
    "    \n",
    "        result, length_dict = Class_2.obtain_paths('target_specified', \n",
    "                                                   s, t, lower_bd, upper_bd, one_hop)\n",
    "        if t in result:\n",
    "            \n",
    "            for path in result[t]:\n",
    "                \n",
    "                path_holder.add(path)\n",
    "    \n",
    "    path_holder_1 = list(path_holder)\n",
    "    path_holder_2 = list(path_holder)\n",
    "    \n",
    "    random.shuffle(path_holder_1)\n",
    "    random.shuffle(path_holder_2)\n",
    "    \n",
    "    score_dict = defaultdict(float)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    #iterate over path_1\n",
    "    for path_1 in path_holder_1:\n",
    "        \n",
    "        if count == 30:\n",
    "            break\n",
    "\n",
    "        #iterate over path_2\n",
    "        for path_2 in path_holder_2:\n",
    "            \n",
    "            if count == 30:\n",
    "                break\n",
    "\n",
    "            #decide which path is shorter and which is longer\n",
    "            if len(path_1) <= len(path_2):\n",
    "\n",
    "                path_s, path_l = path_1, path_2\n",
    "\n",
    "            else:\n",
    "\n",
    "                path_s, path_l = path_2, path_1                            \n",
    "\n",
    "            #whether lengths of the two paths satisfies the requirments\n",
    "            if (len(path_s) >= lower_bd) and (len(path_l) <= upper_bd) and (\n",
    "                abs(len(path_s)-len(path_l)) <= diff):\n",
    "                \n",
    "                list_s = list()\n",
    "                list_l = list()\n",
    "                list_r = list()\n",
    "\n",
    "                for i in range(len(id2relation)):\n",
    "                    \n",
    "                    if i not in id2relation:\n",
    "                        \n",
    "                        raise ValueError ('error when generating id2relation')\n",
    "\n",
    "                    list_s.append(list(path_s) + [num_r]*abs(len(path_s)-len(path_l)))\n",
    "                    list_l.append(list(path_l))\n",
    "                    list_r.append([i])\n",
    "                \n",
    "                input_s = np.array(list_s)\n",
    "                input_l = np.array(list_l)\n",
    "                input_r = np.array(list_r)\n",
    "                \n",
    "                pred = model.predict([input_s, input_l, input_r], verbose = 0)\n",
    "    \n",
    "                for i in range(pred.shape[0]):\n",
    "\n",
    "                    score_dict[i] += float(pred[i][0])\n",
    "                \n",
    "                count += 1\n",
    "                \n",
    "    print(len(score_dict), len(path_holder))\n",
    "\n",
    "    return(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d033a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 202\n",
      "Hits@1 0.0 Hits@10 0.0 MRR 0.023255813953488372 cur_rank 42 total_num 0 500\n",
      "0 0\n",
      "Hits@1 0.0 Hits@10 0.0 MRR 0.020102483247930625 cur_rank 58 total_num 1 500\n",
      "152 322\n",
      "Hits@1 0.0 Hits@10 0.0 MRR 0.024895908372183636 cur_rank 28 total_num 2 500\n",
      "152 298\n",
      "Hits@1 0.0 Hits@10 0.0 MRR 0.024921931279137728 cur_rank 39 total_num 3 500\n",
      "152 301\n",
      "Hits@1 0.0 Hits@10 0.0 MRR 0.024381989467754626 cur_rank 44 total_num 4 500\n",
      "152 75\n",
      "Hits@1 0.16666666666666666 Hits@10 0.16666666666666666 MRR 0.18698499122312887 cur_rank 0 total_num 5 500\n",
      "152 42\n",
      "Hits@1 0.14285714285714285 Hits@10 0.14285714285714285 MRR 0.162614769994532 cur_rank 60 total_num 6 500\n",
      "152 199\n",
      "Hits@1 0.125 Hits@10 0.125 MRR 0.14659826857280173 cur_rank 28 total_num 7 500\n",
      "152 215\n",
      "Hits@1 0.1111111111111111 Hits@10 0.1111111111111111 MRR 0.13272503100191071 cur_rank 45 total_num 8 500\n",
      "152 248\n",
      "Hits@1 0.1 Hits@10 0.1 MRR 0.12153586123505297 cur_rank 47 total_num 9 500\n",
      "152 312\n",
      "Hits@1 0.09090909090909091 Hits@10 0.09090909090909091 MRR 0.11301239910257341 cur_rank 35 total_num 10 500\n",
      "152 309\n",
      "Hits@1 0.08333333333333333 Hits@10 0.16666666666666666 MRR 0.11748358806624785 cur_rank 5 total_num 11 500\n",
      "152 190\n",
      "Hits@1 0.07692307692307693 Hits@10 0.15384615384615385 MRR 0.11011862978690437 cur_rank 45 total_num 12 500\n",
      "152 731\n",
      "Hits@1 0.07142857142857142 Hits@10 0.14285714285714285 MRR 0.10391414294166038 cur_rank 42 total_num 13 500\n",
      "152 219\n",
      "Hits@1 0.06666666666666667 Hits@10 0.13333333333333333 MRR 0.0984049731285284 cur_rank 46 total_num 14 500\n",
      "152 296\n",
      "Hits@1 0.0625 Hits@10 0.125 MRR 0.09394385149718457 cur_rank 36 total_num 15 500\n",
      "152 61\n",
      "Hits@1 0.058823529411764705 Hits@10 0.11764705882352941 MRR 0.08924624299983568 cur_rank 70 total_num 16 500\n",
      "0 0\n",
      "Hits@1 0.05555555555555555 Hits@10 0.16666666666666666 MRR 0.08984367394428926 cur_rank 9 total_num 17 500\n",
      "152 46\n",
      "Hits@1 0.05263157894736842 Hits@10 0.21052631578947367 MRR 0.09827295426301087 cur_rank 3 total_num 18 500\n",
      "152 165\n",
      "Hits@1 0.1 Hits@10 0.25 MRR 0.14335930654986034 cur_rank 0 total_num 19 500\n",
      "152 3\n",
      "Hits@1 0.14285714285714285 Hits@10 0.2857142857142857 MRR 0.1841517205236765 cur_rank 0 total_num 20 500\n",
      "152 164\n",
      "Hits@1 0.13636363636363635 Hits@10 0.2727272727272727 MRR 0.1767912887827013 cur_rank 44 total_num 21 500\n",
      "0 0\n",
      "Hits@1 0.13043478260869565 Hits@10 0.2608695652173913 MRR 0.17127862405301864 cur_rank 19 total_num 22 500\n",
      "152 317\n",
      "Hits@1 0.125 Hits@10 0.25 MRR 0.16544409805080953 cur_rank 31 total_num 23 500\n",
      "152 29\n",
      "Hits@1 0.12 Hits@10 0.24 MRR 0.1621596674621105 cur_rank 11 total_num 24 500\n",
      "152 216\n",
      "Hits@1 0.11538461538461539 Hits@10 0.23076923076923078 MRR 0.15696225821460727 cur_rank 36 total_num 25 500\n",
      "152 151\n",
      "Hits@1 0.1111111111111111 Hits@10 0.2222222222222222 MRR 0.1520101676864177 cur_rank 42 total_num 26 500\n",
      "152 37\n",
      "Hits@1 0.10714285714285714 Hits@10 0.21428571428571427 MRR 0.14707726487222025 cur_rank 71 total_num 27 500\n",
      "152 381\n",
      "Hits@1 0.10344827586206896 Hits@10 0.20689655172413793 MRR 0.14261059572659618 cur_rank 56 total_num 28 500\n",
      "152 15\n",
      "Hits@1 0.1 Hits@10 0.23333333333333334 MRR 0.15452357586904297 cur_rank 1 total_num 29 500\n",
      "0 0\n",
      "Hits@1 0.0967741935483871 Hits@10 0.22580645161290322 MRR 0.15133105908473693 cur_rank 17 total_num 30 500\n",
      "152 84\n",
      "Hits@1 0.09375 Hits@10 0.25 MRR 0.1505082134883389 cur_rank 7 total_num 31 500\n",
      "152 434\n",
      "Hits@1 0.09090909090909091 Hits@10 0.24242424242424243 MRR 0.14657867166545993 cur_rank 47 total_num 32 500\n",
      "152 216\n",
      "Hits@1 0.08823529411764706 Hits@10 0.23529411764705882 MRR 0.14310787039798842 cur_rank 34 total_num 33 500\n",
      "152 3\n",
      "Hits@1 0.08571428571428572 Hits@10 0.22857142857142856 MRR 0.14161647669830563 cur_rank 10 total_num 34 500\n",
      "152 396\n",
      "Hits@1 0.08333333333333333 Hits@10 0.2222222222222222 MRR 0.1383286805109496 cur_rank 42 total_num 35 500\n",
      "152 5\n",
      "Hits@1 0.10810810810810811 Hits@10 0.24324324324324326 MRR 0.1616170945511942 cur_rank 0 total_num 36 500\n",
      "0 0\n",
      "Hits@1 0.10526315789473684 Hits@10 0.23684210526315788 MRR 0.15797600821967564 cur_rank 42 total_num 37 500\n",
      "152 260\n",
      "Hits@1 0.10256410256410256 Hits@10 0.23076923076923078 MRR 0.15452164426413237 cur_rank 42 total_num 38 500\n",
      "152 263\n",
      "Hits@1 0.1 Hits@10 0.225 MRR 0.1514161789151048 cur_rank 32 total_num 39 500\n",
      "152 261\n",
      "Hits@1 0.0975609756097561 Hits@10 0.21951219512195122 MRR 0.14838229716173706 cur_rank 36 total_num 40 500\n",
      "152 353\n",
      "Hits@1 0.09523809523809523 Hits@10 0.21428571428571427 MRR 0.1453454170705846 cur_rank 47 total_num 41 500\n",
      "152 239\n",
      "Hits@1 0.09302325581395349 Hits@10 0.20930232558139536 MRR 0.14249383231841453 cur_rank 43 total_num 42 500\n",
      "152 426\n",
      "Hits@1 0.09090909090909091 Hits@10 0.20454545454545456 MRR 0.1406757906748142 cur_rank 15 total_num 43 500\n",
      "152 693\n",
      "Hits@1 0.08888888888888889 Hits@10 0.2 MRR 0.13803275378059127 cur_rank 45 total_num 44 500\n",
      "152 207\n",
      "Hits@1 0.08695652173913043 Hits@10 0.1956521739130435 MRR 0.13552611288812783 cur_rank 43 total_num 45 500\n",
      "152 1\n",
      "Hits@1 0.10638297872340426 Hits@10 0.2127659574468085 MRR 0.15391917431604 cur_rank 0 total_num 46 500\n",
      "152 12\n",
      "Hits@1 0.10416666666666667 Hits@10 0.20833333333333334 MRR 0.15106563219575528 cur_rank 58 total_num 47 500\n",
      "152 141\n",
      "Hits@1 0.10204081632653061 Hits@10 0.22448979591836735 MRR 0.15818674174278066 cur_rank 1 total_num 48 500\n",
      "0 0\n",
      "Hits@1 0.1 Hits@10 0.24 MRR 0.15788014976506792 cur_rank 6 total_num 49 500\n",
      "152 54\n",
      "Hits@1 0.09803921568627451 Hits@10 0.2549019607843137 MRR 0.1580524344101973 cur_rank 5 total_num 50 500\n",
      "0 0\n",
      "Hits@1 0.09615384615384616 Hits@10 0.2692307692307692 MRR 0.15693604144077045 cur_rank 9 total_num 51 500\n",
      "152 225\n",
      "Hits@1 0.09433962264150944 Hits@10 0.2641509433962264 MRR 0.15444668216830307 cur_rank 39 total_num 52 500\n",
      "152 15\n",
      "Hits@1 0.09259259259259259 Hits@10 0.25925925925925924 MRR 0.15183347200469252 cur_rank 74 total_num 53 500\n",
      "152 10\n",
      "Hits@1 0.10909090909090909 Hits@10 0.2727272727272727 MRR 0.1672546816046072 cur_rank 0 total_num 54 500\n",
      "152 56\n",
      "Hits@1 0.10714285714285714 Hits@10 0.26785714285714285 MRR 0.16463242234854827 cur_rank 48 total_num 55 500\n",
      "0 0\n",
      "Hits@1 0.10526315789473684 Hits@10 0.2631578947368421 MRR 0.16237070065321035 cur_rank 27 total_num 56 500\n",
      "0 0\n",
      "Hits@1 0.10344827586206896 Hits@10 0.25862068965517243 MRR 0.16018696936115995 cur_rank 27 total_num 57 500\n",
      "152 182\n",
      "Hits@1 0.1016949152542373 Hits@10 0.2542372881355932 MRR 0.1578325562490162 cur_rank 46 total_num 58 500\n",
      "152 582\n",
      "Hits@1 0.1 Hits@10 0.25 MRR 0.15555662357394395 cur_rank 46 total_num 59 500\n",
      "0 0\n",
      "Hits@1 0.09836065573770492 Hits@10 0.2459016393442623 MRR 0.15351881007273177 cur_rank 31 total_num 60 500\n",
      "152 42\n",
      "Hits@1 0.0967741935483871 Hits@10 0.25806451612903225 MRR 0.15507495829736512 cur_rank 3 total_num 61 500\n",
      "0 0\n",
      "Hits@1 0.09523809523809523 Hits@10 0.25396825396825395 MRR 0.15318034444684006 cur_rank 27 total_num 62 500\n",
      "152 315\n",
      "Hits@1 0.09375 Hits@10 0.25 MRR 0.15114201520122184 cur_rank 43 total_num 63 500\n",
      "152 182\n",
      "Hits@1 0.09230769230769231 Hits@10 0.24615384615384617 MRR 0.14913072517143852 cur_rank 48 total_num 64 500\n",
      "152 204\n",
      "Hits@1 0.09090909090909091 Hits@10 0.24242424242424243 MRR 0.1470787237315226 cur_rank 72 total_num 65 500\n",
      "152 579\n",
      "Hits@1 0.08955223880597014 Hits@10 0.23880597014925373 MRR 0.14523888492671663 cur_rank 41 total_num 66 500\n",
      "152 771\n",
      "Hits@1 0.08823529411764706 Hits@10 0.23529411764705882 MRR 0.1434706660307355 cur_rank 39 total_num 67 500\n",
      "152 37\n",
      "Hits@1 0.10144927536231885 Hits@10 0.2463768115942029 MRR 0.1558841346389857 cur_rank 0 total_num 68 500\n",
      "152 13\n",
      "Hits@1 0.1 Hits@10 0.2571428571428571 MRR 0.15524452001715894 cur_rank 8 total_num 69 500\n",
      "152 62\n",
      "Hits@1 0.09859154929577464 Hits@10 0.2535211267605634 MRR 0.1534386398341993 cur_rank 36 total_num 70 500\n",
      "152 337\n",
      "Hits@1 0.09722222222222222 Hits@10 0.25 MRR 0.15229961110634338 cur_rank 13 total_num 71 500\n",
      "0 0\n",
      "Hits@1 0.0958904109589041 Hits@10 0.2465753424657534 MRR 0.15097435007140106 cur_rank 17 total_num 72 500\n",
      "152 628\n",
      "Hits@1 0.0945945945945946 Hits@10 0.24324324324324326 MRR 0.14922792818441974 cur_rank 45 total_num 73 500\n",
      "0 0\n",
      "Hits@1 0.09333333333333334 Hits@10 0.25333333333333335 MRR 0.1516826669197386 cur_rank 2 total_num 74 500\n",
      "152 169\n",
      "Hits@1 0.09210526315789473 Hits@10 0.25 MRR 0.1500523394310286 cur_rank 35 total_num 75 500\n",
      "152 73\n",
      "Hits@1 0.09090909090909091 Hits@10 0.24675324675324675 MRR 0.14856742964249947 cur_rank 27 total_num 76 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 400\n",
      "Hits@1 0.08974358974358974 Hits@10 0.2564102564102564 MRR 0.1480872204305586 cur_rank 8 total_num 77 500\n",
      "152 61\n",
      "Hits@1 0.08860759493670886 Hits@10 0.26582278481012656 MRR 0.15043210793565703 cur_rank 2 total_num 78 500\n",
      "152 689\n",
      "Hits@1 0.0875 Hits@10 0.2625 MRR 0.1488424042608799 cur_rank 42 total_num 79 500\n",
      "152 159\n",
      "Hits@1 0.08641975308641975 Hits@10 0.25925925925925924 MRR 0.14727322804080464 cur_rank 45 total_num 80 500\n",
      "0 0\n",
      "Hits@1 0.08536585365853659 Hits@10 0.25609756097560976 MRR 0.14591275313438368 cur_rank 27 total_num 81 500\n",
      "0 0\n",
      "Hits@1 0.08433734939759036 Hits@10 0.26506024096385544 MRR 0.14535958743396943 cur_rank 9 total_num 82 500\n",
      "0 0\n",
      "Hits@1 0.08333333333333333 Hits@10 0.2619047619047619 MRR 0.1439508664767439 cur_rank 36 total_num 83 500\n",
      "152 662\n",
      "Hits@1 0.08235294117647059 Hits@10 0.25882352941176473 MRR 0.14251876477963188 cur_rank 44 total_num 84 500\n",
      "0 0\n",
      "Hits@1 0.08139534883720931 Hits@10 0.2558139534883721 MRR 0.14127685223236044 cur_rank 27 total_num 85 500\n",
      "152 400\n",
      "Hits@1 0.08045977011494253 Hits@10 0.26436781609195403 MRR 0.14348439799214174 cur_rank 2 total_num 86 500\n",
      "0 0\n",
      "Hits@1 0.07954545454545454 Hits@10 0.26136363636363635 MRR 0.14205681554742583 cur_rank 55 total_num 87 500\n",
      "152 926\n",
      "Hits@1 0.07865168539325842 Hits@10 0.25842696629213485 MRR 0.14074157042891544 cur_rank 39 total_num 88 500\n",
      "152 16\n",
      "Hits@1 0.07777777777777778 Hits@10 0.26666666666666666 MRR 0.14473333075748304 cur_rank 1 total_num 89 500\n",
      "152 98\n",
      "Hits@1 0.07692307692307693 Hits@10 0.26373626373626374 MRR 0.1434862611887195 cur_rank 31 total_num 90 500\n",
      "152 190\n",
      "Hits@1 0.07608695652173914 Hits@10 0.2608695652173913 MRR 0.1421917392616947 cur_rank 40 total_num 91 500\n",
      "152 183\n",
      "Hits@1 0.07526881720430108 Hits@10 0.25806451612903225 MRR 0.14107636075846722 cur_rank 25 total_num 92 500\n",
      "152 380\n",
      "Hits@1 0.07446808510638298 Hits@10 0.2553191489361702 MRR 0.13987949977775402 cur_rank 34 total_num 93 500\n",
      "152 103\n",
      "Hits@1 0.07368421052631578 Hits@10 0.25263157894736843 MRR 0.13864631844038056 cur_rank 43 total_num 94 500\n",
      "152 3\n",
      "Hits@1 0.07291666666666667 Hits@10 0.25 MRR 0.13767557080511142 cur_rank 21 total_num 95 500\n",
      "152 19\n",
      "Hits@1 0.07216494845360824 Hits@10 0.24742268041237114 MRR 0.13649598568292975 cur_rank 42 total_num 96 500\n",
      "152 389\n",
      "Hits@1 0.07142857142857142 Hits@10 0.24489795918367346 MRR 0.13558907815166565 cur_rank 20 total_num 97 500\n",
      "152 33\n",
      "Hits@1 0.0707070707070707 Hits@10 0.24242424242424243 MRR 0.13439364685023816 cur_rank 57 total_num 98 500\n",
      "152 45\n",
      "Hits@1 0.07 Hits@10 0.24 MRR 0.13360526593729133 cur_rank 17 total_num 99 500\n",
      "152 215\n",
      "Hits@1 0.06930693069306931 Hits@10 0.2376237623762376 MRR 0.132636048311321 cur_rank 27 total_num 100 500\n",
      "152 680\n",
      "Hits@1 0.06862745098039216 Hits@10 0.23529411764705882 MRR 0.1315585112957911 cur_rank 43 total_num 101 500\n",
      "0 0\n",
      "Hits@1 0.06796116504854369 Hits@10 0.23300970873786409 MRR 0.13047938170326215 cur_rank 48 total_num 102 500\n",
      "152 410\n",
      "Hits@1 0.0673076923076923 Hits@10 0.23076923076923078 MRR 0.12943380236414215 cur_rank 45 total_num 103 500\n",
      "152 31\n",
      "Hits@1 0.06666666666666667 Hits@10 0.23809523809523808 MRR 0.12978840107178524 cur_rank 5 total_num 104 500\n",
      "152 647\n",
      "Hits@1 0.0660377358490566 Hits@10 0.2358490566037736 MRR 0.1287998312503533 cur_rank 39 total_num 105 500\n",
      "152 167\n",
      "Hits@1 0.06542056074766354 Hits@10 0.2336448598130841 MRR 0.1278186134238035 cur_rank 41 total_num 106 500\n",
      "152 211\n",
      "Hits@1 0.06481481481481481 Hits@10 0.23148148148148148 MRR 0.1268408690608259 cur_rank 44 total_num 107 500\n",
      "152 184\n",
      "Hits@1 0.06422018348623854 Hits@10 0.22935779816513763 MRR 0.12588106496138915 cur_rank 44 total_num 108 500\n",
      "152 356\n",
      "Hits@1 0.06363636363636363 Hits@10 0.22727272727272727 MRR 0.12492608558295229 cur_rank 47 total_num 109 500\n",
      "152 300\n",
      "Hits@1 0.06306306306306306 Hits@10 0.22522522522522523 MRR 0.1241609857128356 cur_rank 24 total_num 110 500\n",
      "152 162\n",
      "Hits@1 0.0625 Hits@10 0.22321428571428573 MRR 0.1232465048621387 cur_rank 45 total_num 111 500\n",
      "152 232\n",
      "Hits@1 0.061946902654867256 Hits@10 0.22123893805309736 MRR 0.1224016488702417 cur_rank 35 total_num 112 500\n",
      "152 29\n",
      "Hits@1 0.06140350877192982 Hits@10 0.21929824561403508 MRR 0.12162034785676006 cur_rank 29 total_num 113 500\n",
      "152 178\n",
      "Hits@1 0.06086956521739131 Hits@10 0.21739130434782608 MRR 0.12074779349056805 cur_rank 46 total_num 114 500\n",
      "152 272\n",
      "Hits@1 0.0603448275862069 Hits@10 0.21551724137931033 MRR 0.1198942705331906 cur_rank 45 total_num 115 500\n",
      "152 351\n",
      "Hits@1 0.05982905982905983 Hits@10 0.21367521367521367 MRR 0.11906830081883417 cur_rank 42 total_num 116 500\n",
      "152 2\n",
      "Hits@1 0.059322033898305086 Hits@10 0.22033898305084745 MRR 0.12229653555765761 cur_rank 1 total_num 117 500\n",
      "152 285\n",
      "Hits@1 0.058823529411764705 Hits@10 0.2184873949579832 MRR 0.1214476285004057 cur_rank 46 total_num 118 500\n",
      "152 120\n",
      "Hits@1 0.058333333333333334 Hits@10 0.225 MRR 0.12126889826290231 cur_rank 9 total_num 119 500\n",
      "152 109\n",
      "Hits@1 0.05785123966942149 Hits@10 0.2231404958677686 MRR 0.12045450466343431 cur_rank 43 total_num 120 500\n",
      "152 364\n",
      "Hits@1 0.05737704918032787 Hits@10 0.22131147540983606 MRR 0.11964536225172405 cur_rank 45 total_num 121 500\n",
      "152 41\n",
      "Hits@1 0.056910569105691054 Hits@10 0.21951219512195122 MRR 0.11878555352519694 cur_rank 71 total_num 122 500\n",
      "152 47\n",
      "Hits@1 0.056451612903225805 Hits@10 0.21774193548387097 MRR 0.1179365854605866 cur_rank 73 total_num 123 500\n",
      "152 24\n",
      "Hits@1 0.056 Hits@10 0.216 MRR 0.11752642611023524 cur_rank 14 total_num 124 500\n",
      "152 12\n",
      "Hits@1 0.05555555555555555 Hits@10 0.21428571428571427 MRR 0.11701138764068868 cur_rank 18 total_num 125 500\n",
      "152 898\n",
      "Hits@1 0.05511811023622047 Hits@10 0.2125984251968504 MRR 0.11626899303507122 cur_rank 43 total_num 126 500\n",
      "152 175\n",
      "Hits@1 0.0546875 Hits@10 0.2109375 MRR 0.11554665343174664 cur_rank 41 total_num 127 500\n",
      "152 230\n",
      "Hits@1 0.05426356589147287 Hits@10 0.20930232558139536 MRR 0.11520465279606311 cur_rank 13 total_num 128 500\n",
      "0 0\n",
      "Hits@1 0.05384615384615385 Hits@10 0.2153846153846154 MRR 0.11508769392840108 cur_rank 9 total_num 129 500\n",
      "0 0\n",
      "Hits@1 0.05343511450381679 Hits@10 0.21374045801526717 MRR 0.11459084130299345 cur_rank 19 total_num 130 500\n",
      "152 131\n",
      "Hits@1 0.05303030303030303 Hits@10 0.21212121212121213 MRR 0.11388391520027895 cur_rank 46 total_num 131 500\n",
      "0 0\n",
      "Hits@1 0.05263157894736842 Hits@10 0.21052631578947367 MRR 0.11360601416060075 cur_rank 12 total_num 132 500\n",
      "152 129\n",
      "Hits@1 0.05223880597014925 Hits@10 0.208955223880597 MRR 0.11297769886616255 cur_rank 33 total_num 133 500\n",
      "0 0\n",
      "Hits@1 0.05185185185185185 Hits@10 0.2074074074074074 MRR 0.11236529391384305 cur_rank 32 total_num 134 500\n",
      "152 944\n",
      "Hits@1 0.051470588235294115 Hits@10 0.20588235294117646 MRR 0.11170619081688297 cur_rank 43 total_num 135 500\n",
      "152 79\n",
      "Hits@1 0.051094890510948905 Hits@10 0.20437956204379562 MRR 0.11098945594605547 cur_rank 73 total_num 136 500\n",
      "152 89\n",
      "Hits@1 0.050724637681159424 Hits@10 0.2028985507246377 MRR 0.11031231394390378 cur_rank 56 total_num 137 500\n",
      "152 369\n",
      "Hits@1 0.050359712230215826 Hits@10 0.2014388489208633 MRR 0.10968600818857706 cur_rank 42 total_num 138 500\n",
      "152 8\n",
      "Hits@1 0.05 Hits@10 0.2 MRR 0.10911262073512924 cur_rank 33 total_num 139 500\n",
      "0 0\n",
      "Hits@1 0.04964539007092199 Hits@10 0.20567375886524822 MRR 0.11070283855497466 cur_rank 2 total_num 140 500\n",
      "152 161\n",
      "Hits@1 0.04929577464788732 Hits@10 0.20422535211267606 MRR 0.11029388602252672 cur_rank 18 total_num 141 500\n",
      "152 229\n",
      "Hits@1 0.04895104895104895 Hits@10 0.20279720279720279 MRR 0.10967800026168543 cur_rank 44 total_num 142 500\n",
      "0 0\n",
      "Hits@1 0.04861111111111111 Hits@10 0.20833333333333334 MRR 0.1112311622969052 cur_rank 2 total_num 143 500\n",
      "0 0\n",
      "Hits@1 0.04827586206896552 Hits@10 0.20689655172413793 MRR 0.11071035625150782 cur_rank 27 total_num 144 500\n",
      "152 240\n",
      "Hits@1 0.04794520547945205 Hits@10 0.2054794520547945 MRR 0.11013718276366892 cur_rank 36 total_num 145 500\n",
      "152 84\n",
      "Hits@1 0.047619047619047616 Hits@10 0.2108843537414966 MRR 0.11278931077207933 cur_rank 1 total_num 146 500\n",
      "152 190\n",
      "Hits@1 0.0472972972972973 Hits@10 0.20945945945945946 MRR 0.11220503022276586 cur_rank 37 total_num 147 500\n",
      "0 0\n",
      "Hits@1 0.04697986577181208 Hits@10 0.2080536912751678 MRR 0.1116617078722775 cur_rank 31 total_num 148 500\n",
      "0 0\n",
      "Hits@1 0.04666666666666667 Hits@10 0.20666666666666667 MRR 0.11103634410550993 cur_rank 55 total_num 149 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 758\n",
      "Hits@1 0.046357615894039736 Hits@10 0.2052980132450331 MRR 0.11047528082980249 cur_rank 37 total_num 150 500\n",
      "0 0\n",
      "Hits@1 0.046052631578947366 Hits@10 0.20394736842105263 MRR 0.10991294345592219 cur_rank 39 total_num 151 500\n",
      "152 127\n",
      "Hits@1 0.0457516339869281 Hits@10 0.20261437908496732 MRR 0.10947872984424667 cur_rank 22 total_num 152 500\n",
      "152 184\n",
      "Hits@1 0.045454545454545456 Hits@10 0.2012987012987013 MRR 0.10886929004006324 cur_rank 63 total_num 153 500\n",
      "152 250\n",
      "Hits@1 0.04516129032258064 Hits@10 0.2 MRR 0.10831027669930297 cur_rank 44 total_num 154 500\n",
      "152 90\n",
      "Hits@1 0.04487179487179487 Hits@10 0.1987179487179487 MRR 0.10807385551167009 cur_rank 13 total_num 155 500\n",
      "0 0\n",
      "Hits@1 0.044585987261146494 Hits@10 0.19745222929936307 MRR 0.10787544290919497 cur_rank 12 total_num 156 500\n",
      "0 0\n",
      "Hits@1 0.04430379746835443 Hits@10 0.20253164556962025 MRR 0.10782559833382033 cur_rank 9 total_num 157 500\n",
      "152 757\n",
      "Hits@1 0.0440251572327044 Hits@10 0.20125786163522014 MRR 0.1072812649842031 cur_rank 46 total_num 158 500\n",
      "152 152\n",
      "Hits@1 0.04375 Hits@10 0.2 MRR 0.10675956660186137 cur_rank 41 total_num 159 500\n",
      "152 72\n",
      "Hits@1 0.043478260869565216 Hits@10 0.19875776397515527 MRR 0.10622322248175853 cur_rank 48 total_num 160 500\n",
      "152 113\n",
      "Hits@1 0.043209876543209874 Hits@10 0.19753086419753085 MRR 0.1058761655528588 cur_rank 19 total_num 161 500\n",
      "152 813\n",
      "Hits@1 0.04294478527607362 Hits@10 0.19631901840490798 MRR 0.10535443038586784 cur_rank 47 total_num 162 500\n",
      "152 465\n",
      "Hits@1 0.042682926829268296 Hits@10 0.1951219512195122 MRR 0.10482707364283389 cur_rank 52 total_num 163 500\n",
      "152 220\n",
      "Hits@1 0.04242424242424243 Hits@10 0.19393939393939394 MRR 0.1043207071101178 cur_rank 46 total_num 164 500\n",
      "0 0\n",
      "Hits@1 0.04216867469879518 Hits@10 0.19879518072289157 MRR 0.10570030124399259 cur_rank 2 total_num 165 500\n",
      "152 68\n",
      "Hits@1 0.041916167664670656 Hits@10 0.19760479041916168 MRR 0.10520345676185655 cur_rank 43 total_num 166 500\n",
      "152 221\n",
      "Hits@1 0.041666666666666664 Hits@10 0.19642857142857142 MRR 0.10474731373691352 cur_rank 34 total_num 167 500\n",
      "152 247\n",
      "Hits@1 0.04142011834319527 Hits@10 0.1952662721893491 MRR 0.10430154125743998 cur_rank 33 total_num 168 500\n",
      "152 766\n",
      "Hits@1 0.041176470588235294 Hits@10 0.19411764705882353 MRR 0.10383506160298445 cur_rank 39 total_num 169 500\n",
      "152 280\n",
      "Hits@1 0.04093567251461988 Hits@10 0.19883040935672514 MRR 0.10381263434214828 cur_rank 9 total_num 170 500\n",
      "0 0\n",
      "Hits@1 0.040697674418604654 Hits@10 0.20348837209302326 MRR 0.1040396372986308 cur_rank 6 total_num 171 500\n",
      "152 253\n",
      "Hits@1 0.04046242774566474 Hits@10 0.2023121387283237 MRR 0.10366057314350312 cur_rank 25 total_num 172 500\n",
      "152 129\n",
      "Hits@1 0.040229885057471264 Hits@10 0.20114942528735633 MRR 0.10347533175433685 cur_rank 13 total_num 173 500\n",
      "152 965\n",
      "Hits@1 0.04 Hits@10 0.2 MRR 0.10300309176335969 cur_rank 47 total_num 174 500\n",
      "152 536\n",
      "Hits@1 0.03977272727272727 Hits@10 0.19886363636363635 MRR 0.10252925512343863 cur_rank 50 total_num 175 500\n",
      "152 244\n",
      "Hits@1 0.03954802259887006 Hits@10 0.1977401129943503 MRR 0.10207839646583318 cur_rank 43 total_num 176 500\n",
      "152 279\n",
      "Hits@1 0.03932584269662921 Hits@10 0.19662921348314608 MRR 0.10162445376515254 cur_rank 46 total_num 177 500\n",
      "152 159\n",
      "Hits@1 0.03910614525139665 Hits@10 0.19553072625698323 MRR 0.101173106723634 cur_rank 47 total_num 178 500\n",
      "152 34\n",
      "Hits@1 0.044444444444444446 Hits@10 0.2 MRR 0.10616658946405824 cur_rank 0 total_num 179 500\n",
      "152 621\n",
      "Hits@1 0.04419889502762431 Hits@10 0.19889502762430938 MRR 0.10574745377808573 cur_rank 32 total_num 180 500\n",
      "152 854\n",
      "Hits@1 0.04395604395604396 Hits@10 0.1978021978021978 MRR 0.10531101606212748 cur_rank 37 total_num 181 500\n",
      "152 156\n",
      "Hits@1 0.04371584699453552 Hits@10 0.19672131147540983 MRR 0.10484938938054936 cur_rank 47 total_num 182 500\n",
      "152 10\n",
      "Hits@1 0.043478260869565216 Hits@10 0.1956521739130435 MRR 0.10443052192618647 cur_rank 35 total_num 183 500\n",
      "152 55\n",
      "Hits@1 0.043243243243243246 Hits@10 0.1945945945945946 MRR 0.1041505276398145 cur_rank 18 total_num 184 500\n",
      "152 778\n",
      "Hits@1 0.043010752688172046 Hits@10 0.1935483870967742 MRR 0.10370745561183045 cur_rank 45 total_num 185 500\n",
      "152 323\n",
      "Hits@1 0.0427807486631016 Hits@10 0.1925133689839572 MRR 0.1032691223221136 cur_rank 45 total_num 186 500\n",
      "152 3\n",
      "Hits@1 0.0425531914893617 Hits@10 0.19680851063829788 MRR 0.10360634330266974 cur_rank 5 total_num 187 500\n",
      "152 226\n",
      "Hits@1 0.042328042328042326 Hits@10 0.19576719576719576 MRR 0.10317318344622589 cur_rank 45 total_num 188 500\n",
      "152 70\n",
      "Hits@1 0.042105263157894736 Hits@10 0.19473684210526315 MRR 0.10278054263109537 cur_rank 34 total_num 189 500\n",
      "0 0\n",
      "Hits@1 0.041884816753926704 Hits@10 0.193717277486911 MRR 0.10250420471156085 cur_rank 19 total_num 190 500\n",
      "0 0\n",
      "Hits@1 0.041666666666666664 Hits@10 0.19270833333333334 MRR 0.10229584947868814 cur_rank 15 total_num 191 500\n",
      "0 0\n",
      "Hits@1 0.04145077720207254 Hits@10 0.19170984455958548 MRR 0.10184553220358931 cur_rank 64 total_num 192 500\n",
      "152 205\n",
      "Hits@1 0.041237113402061855 Hits@10 0.19072164948453607 MRR 0.10144328473764053 cur_rank 41 total_num 193 500\n",
      "152 121\n",
      "Hits@1 0.041025641025641026 Hits@10 0.18974358974358974 MRR 0.10103961288117712 cur_rank 43 total_num 194 500\n",
      "152 189\n",
      "Hits@1 0.04081632653061224 Hits@10 0.18877551020408162 MRR 0.10064006012528985 cur_rank 43 total_num 195 500\n",
      "0 0\n",
      "Hits@1 0.04060913705583756 Hits@10 0.18781725888324874 MRR 0.10031048766635074 cur_rank 27 total_num 196 500\n",
      "152 195\n",
      "Hits@1 0.04040404040404041 Hits@10 0.18686868686868688 MRR 0.09991132659603927 cur_rank 46 total_num 197 500\n",
      "152 53\n",
      "Hits@1 0.04020100502512563 Hits@10 0.19095477386934673 MRR 0.10192182244229032 cur_rank 1 total_num 198 500\n",
      "152 322\n",
      "Hits@1 0.04 Hits@10 0.19 MRR 0.10153416454959106 cur_rank 40 total_num 199 500\n",
      "152 250\n",
      "Hits@1 0.03980099502487562 Hits@10 0.1890547263681592 MRR 0.10115994377806915 cur_rank 37 total_num 200 500\n",
      "152 427\n",
      "Hits@1 0.039603960396039604 Hits@10 0.18811881188118812 MRR 0.10076916297828772 cur_rank 44 total_num 201 500\n",
      "152 140\n",
      "Hits@1 0.03940886699507389 Hits@10 0.18719211822660098 MRR 0.10036072938163183 cur_rank 55 total_num 202 500\n",
      "0 0\n",
      "Hits@1 0.0392156862745098 Hits@10 0.18627450980392157 MRR 0.10024583892840362 cur_rank 12 total_num 203 500\n",
      "152 182\n",
      "Hits@1 0.03902439024390244 Hits@10 0.18536585365853658 MRR 0.09986523592008079 cur_rank 44 total_num 204 500\n",
      "152 177\n",
      "Hits@1 0.038834951456310676 Hits@10 0.18446601941747573 MRR 0.0995232287782643 cur_rank 33 total_num 205 500\n",
      "152 69\n",
      "Hits@1 0.03864734299516908 Hits@10 0.18357487922705315 MRR 0.09917300558139842 cur_rank 36 total_num 206 500\n",
      "152 30\n",
      "Hits@1 0.038461538461538464 Hits@10 0.1875 MRR 0.09949749433661606 cur_rank 5 total_num 207 500\n",
      "152 15\n",
      "Hits@1 0.03827751196172249 Hits@10 0.18660287081339713 MRR 0.09917577457670942 cur_rank 30 total_num 208 500\n",
      "152 171\n",
      "Hits@1 0.0380952380952381 Hits@10 0.18571428571428572 MRR 0.09880482610608071 cur_rank 46 total_num 209 500\n",
      "152 28\n",
      "Hits@1 0.037914691943127965 Hits@10 0.1848341232227488 MRR 0.09841299769921807 cur_rank 61 total_num 210 500\n",
      "152 669\n",
      "Hits@1 0.03773584905660377 Hits@10 0.18396226415094338 MRR 0.09808752018509857 cur_rank 33 total_num 211 500\n",
      "152 253\n",
      "Hits@1 0.03755868544600939 Hits@10 0.18309859154929578 MRR 0.09772690551636422 cur_rank 46 total_num 212 500\n",
      "0 0\n",
      "Hits@1 0.037383177570093455 Hits@10 0.1822429906542056 MRR 0.09750388259339056 cur_rank 19 total_num 213 500\n",
      "152 818\n",
      "Hits@1 0.037209302325581395 Hits@10 0.1813953488372093 MRR 0.09715373533585024 cur_rank 44 total_num 214 500\n",
      "0 0\n",
      "Hits@1 0.037037037037037035 Hits@10 0.18055555555555555 MRR 0.09696115117020074 cur_rank 17 total_num 215 500\n",
      "152 55\n",
      "Hits@1 0.03686635944700461 Hits@10 0.18433179723502305 MRR 0.09881847305420903 cur_rank 1 total_num 216 500\n",
      "152 6\n",
      "Hits@1 0.03669724770642202 Hits@10 0.1834862385321101 MRR 0.09862001930421521 cur_rank 17 total_num 217 500\n",
      "152 66\n",
      "Hits@1 0.0365296803652968 Hits@10 0.182648401826484 MRR 0.09830016272552669 cur_rank 34 total_num 218 500\n",
      "152 205\n",
      "Hits@1 0.03636363636363636 Hits@10 0.18181818181818182 MRR 0.09799997137002943 cur_rank 30 total_num 219 500\n",
      "0 0\n",
      "Hits@1 0.03619909502262444 Hits@10 0.18552036199095023 MRR 0.09800902127333247 cur_rank 9 total_num 220 500\n",
      "152 288\n",
      "Hits@1 0.036036036036036036 Hits@10 0.18468468468468469 MRR 0.09768607878774846 cur_rank 37 total_num 221 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 37\n",
      "Hits@1 0.03587443946188341 Hits@10 0.18834080717488788 MRR 0.09814488560932806 cur_rank 4 total_num 222 500\n",
      "152 479\n",
      "Hits@1 0.03571428571428571 Hits@10 0.1875 MRR 0.09795475467158801 cur_rank 17 total_num 223 500\n",
      "152 1\n",
      "Hits@1 0.04 Hits@10 0.19111111111111112 MRR 0.1019638446508254 cur_rank 0 total_num 224 500\n",
      "152 565\n",
      "Hits@1 0.03982300884955752 Hits@10 0.1902654867256637 MRR 0.10160682142557698 cur_rank 46 total_num 225 500\n",
      "0 0\n",
      "Hits@1 0.039647577092511016 Hits@10 0.1894273127753304 MRR 0.10131654593786203 cur_rank 27 total_num 226 500\n",
      "152 285\n",
      "Hits@1 0.039473684210526314 Hits@10 0.18859649122807018 MRR 0.10099400748101955 cur_rank 35 total_num 227 500\n",
      "152 303\n",
      "Hits@1 0.039301310043668124 Hits@10 0.18777292576419213 MRR 0.10067428595393117 cur_rank 35 total_num 228 500\n",
      "152 460\n",
      "Hits@1 0.0391304347826087 Hits@10 0.18695652173913044 MRR 0.10035734461403485 cur_rank 35 total_num 229 500\n",
      "152 219\n",
      "Hits@1 0.03896103896103896 Hits@10 0.18614718614718614 MRR 0.10009605740791348 cur_rank 24 total_num 230 500\n",
      "0 0\n",
      "Hits@1 0.03879310344827586 Hits@10 0.1853448275862069 MRR 0.09997249065800254 cur_rank 13 total_num 231 500\n",
      "152 276\n",
      "Hits@1 0.03862660944206009 Hits@10 0.18454935622317598 MRR 0.09965636747695396 cur_rank 37 total_num 232 500\n",
      "152 148\n",
      "Hits@1 0.038461538461538464 Hits@10 0.18376068376068377 MRR 0.09932986938497333 cur_rank 42 total_num 233 500\n",
      "152 252\n",
      "Hits@1 0.03829787234042553 Hits@10 0.1829787234042553 MRR 0.09921114045749929 cur_rank 13 total_num 234 500\n",
      "0 0\n",
      "Hits@1 0.038135593220338986 Hits@10 0.18220338983050846 MRR 0.09911669951031954 cur_rank 12 total_num 235 500\n",
      "152 315\n",
      "Hits@1 0.0379746835443038 Hits@10 0.18143459915611815 MRR 0.09880952267472191 cur_rank 37 total_num 236 500\n",
      "152 55\n",
      "Hits@1 0.037815126050420166 Hits@10 0.18487394957983194 MRR 0.10049519694919788 cur_rank 1 total_num 237 500\n",
      "152 101\n",
      "Hits@1 0.03765690376569038 Hits@10 0.18410041841004185 MRR 0.10020546809166986 cur_rank 31 total_num 238 500\n",
      "152 84\n",
      "Hits@1 0.0375 Hits@10 0.18333333333333332 MRR 0.09999627864128789 cur_rank 19 total_num 239 500\n",
      "152 9\n",
      "Hits@1 0.03734439834024896 Hits@10 0.1825726141078838 MRR 0.09995857246812526 cur_rank 10 total_num 240 500\n",
      "152 28\n",
      "Hits@1 0.0371900826446281 Hits@10 0.1859504132231405 MRR 0.10006204944139746 cur_rank 7 total_num 241 500\n",
      "152 618\n",
      "Hits@1 0.037037037037037035 Hits@10 0.18518518518518517 MRR 0.09976784935551282 cur_rank 34 total_num 242 500\n",
      "152 84\n",
      "Hits@1 0.036885245901639344 Hits@10 0.18442622950819673 MRR 0.09947280807855488 cur_rank 35 total_num 243 500\n",
      "152 62\n",
      "Hits@1 0.036734693877551024 Hits@10 0.1836734693877551 MRR 0.09915956099548844 cur_rank 43 total_num 244 500\n",
      "152 54\n",
      "Hits@1 0.036585365853658534 Hits@10 0.18292682926829268 MRR 0.09882537234324 cur_rank 58 total_num 245 500\n",
      "0 0\n",
      "Hits@1 0.03643724696356275 Hits@10 0.18218623481781376 MRR 0.09851942271413168 cur_rank 42 total_num 246 500\n",
      "152 105\n",
      "Hits@1 0.036290322580645164 Hits@10 0.1814516129032258 MRR 0.09820617235372524 cur_rank 47 total_num 247 500\n",
      "152 720\n",
      "Hits@1 0.03614457831325301 Hits@10 0.18072289156626506 MRR 0.09790304424277563 cur_rank 43 total_num 248 500\n",
      "152 250\n",
      "Hits@1 0.036 Hits@10 0.18 MRR 0.09761669522369927 cur_rank 37 total_num 249 500\n",
      "152 355\n",
      "Hits@1 0.035856573705179286 Hits@10 0.17928286852589642 MRR 0.09732993956799141 cur_rank 38 total_num 250 500\n",
      "152 208\n",
      "Hits@1 0.03571428571428571 Hits@10 0.17857142857142858 MRR 0.0970359946250767 cur_rank 42 total_num 251 500\n",
      "152 609\n",
      "Hits@1 0.03557312252964427 Hits@10 0.17786561264822134 MRR 0.09675126737359419 cur_rank 39 total_num 252 500\n",
      "152 38\n",
      "Hits@1 0.03543307086614173 Hits@10 0.17716535433070865 MRR 0.0964861512213591 cur_rank 33 total_num 253 500\n",
      "152 247\n",
      "Hits@1 0.03529411764705882 Hits@10 0.17647058823529413 MRR 0.09619690071746073 cur_rank 43 total_num 254 500\n",
      "152 263\n",
      "Hits@1 0.03515625 Hits@10 0.17578125 MRR 0.09590605005229401 cur_rank 45 total_num 255 500\n",
      "152 202\n",
      "Hits@1 0.03501945525291829 Hits@10 0.17509727626459143 MRR 0.09574904423713161 cur_rank 17 total_num 256 500\n",
      "152 788\n",
      "Hits@1 0.03488372093023256 Hits@10 0.1744186046511628 MRR 0.09546405655490328 cur_rank 44 total_num 257 500\n",
      "152 18\n",
      "Hits@1 0.03474903474903475 Hits@10 0.17374517374517376 MRR 0.09537125545402941 cur_rank 13 total_num 258 500\n",
      "152 233\n",
      "Hits@1 0.03461538461538462 Hits@10 0.17307692307692307 MRR 0.09517166701331994 cur_rank 22 total_num 259 500\n",
      "152 293\n",
      "Hits@1 0.034482758620689655 Hits@10 0.1724137931034483 MRR 0.09489612734642403 cur_rank 42 total_num 260 500\n",
      "0 0\n",
      "Hits@1 0.03435114503816794 Hits@10 0.17557251908396945 MRR 0.09644232533365142 cur_rank 1 total_num 261 500\n",
      "152 305\n",
      "Hits@1 0.034220532319391636 Hits@10 0.17490494296577946 MRR 0.09634721600321386 cur_rank 13 total_num 262 500\n",
      "152 929\n",
      "Hits@1 0.03409090909090909 Hits@10 0.17424242424242425 MRR 0.0960664395116192 cur_rank 44 total_num 263 500\n",
      "152 111\n",
      "Hits@1 0.033962264150943396 Hits@10 0.17735849056603772 MRR 0.09608128313610366 cur_rank 9 total_num 264 500\n",
      "0 0\n",
      "Hits@1 0.03759398496240601 Hits@10 0.18045112781954886 MRR 0.09947947380100552 cur_rank 0 total_num 265 500\n",
      "152 683\n",
      "Hits@1 0.03745318352059925 Hits@10 0.1797752808988764 MRR 0.09921390059789849 cur_rank 34 total_num 266 500\n",
      "152 209\n",
      "Hits@1 0.03731343283582089 Hits@10 0.1828358208955224 MRR 0.10070937111805559 cur_rank 1 total_num 267 500\n",
      "0 0\n",
      "Hits@1 0.03717472118959108 Hits@10 0.18587360594795538 MRR 0.10070673405070223 cur_rank 9 total_num 268 500\n",
      "152 252\n",
      "Hits@1 0.037037037037037035 Hits@10 0.18518518518518517 MRR 0.10041254835327251 cur_rank 46 total_num 269 500\n",
      "152 132\n",
      "Hits@1 0.03690036900369004 Hits@10 0.18450184501845018 MRR 0.10028802480461345 cur_rank 14 total_num 270 500\n",
      "152 204\n",
      "Hits@1 0.03676470588235294 Hits@10 0.18382352941176472 MRR 0.10000685384507269 cur_rank 41 total_num 271 500\n",
      "152 647\n",
      "Hits@1 0.03663003663003663 Hits@10 0.18315018315018314 MRR 0.09972774274604138 cur_rank 41 total_num 272 500\n",
      "152 220\n",
      "Hits@1 0.0364963503649635 Hits@10 0.18248175182481752 MRR 0.09944142469129189 cur_rank 46 total_num 273 500\n",
      "152 265\n",
      "Hits@1 0.03636363636363636 Hits@10 0.18181818181818182 MRR 0.09916062759140436 cur_rank 44 total_num 274 500\n",
      "152 151\n",
      "Hits@1 0.036231884057971016 Hits@10 0.18115942028985507 MRR 0.09887683304699105 cur_rank 47 total_num 275 500\n",
      "152 128\n",
      "Hits@1 0.036101083032490974 Hits@10 0.18050541516245489 MRR 0.09876055085789241 cur_rank 14 total_num 276 500\n",
      "152 71\n",
      "Hits@1 0.03597122302158273 Hits@10 0.17985611510791366 MRR 0.09848023712578967 cur_rank 47 total_num 277 500\n",
      "152 38\n",
      "Hits@1 0.035842293906810034 Hits@10 0.17921146953405018 MRR 0.09825085548240223 cur_rank 28 total_num 278 500\n",
      "152 40\n",
      "Hits@1 0.03571428571428571 Hits@10 0.17857142857142858 MRR 0.09799394453237109 cur_rank 37 total_num 279 500\n",
      "152 217\n",
      "Hits@1 0.03558718861209965 Hits@10 0.17793594306049823 MRR 0.09775642159809218 cur_rank 31 total_num 280 500\n",
      "0 0\n",
      "Hits@1 0.03546099290780142 Hits@10 0.1773049645390071 MRR 0.09768254448931554 cur_rank 12 total_num 281 500\n",
      "152 656\n",
      "Hits@1 0.0353356890459364 Hits@10 0.17667844522968199 MRR 0.09741419320290376 cur_rank 45 total_num 282 500\n",
      "152 7\n",
      "Hits@1 0.035211267605633804 Hits@10 0.1795774647887324 MRR 0.09883174886064001 cur_rank 1 total_num 283 500\n",
      "152 19\n",
      "Hits@1 0.03859649122807018 Hits@10 0.1824561403508772 MRR 0.10199374272428689 cur_rank 0 total_num 284 500\n",
      "152 594\n",
      "Hits@1 0.038461538461538464 Hits@10 0.18181818181818182 MRR 0.10172453383364252 cur_rank 39 total_num 285 500\n",
      "152 4\n",
      "Hits@1 0.03832752613240418 Hits@10 0.18118466898954705 MRR 0.10144268296081914 cur_rank 47 total_num 286 500\n",
      "0 0\n",
      "Hits@1 0.03819444444444445 Hits@10 0.18055555555555555 MRR 0.1011712007767659 cur_rank 42 total_num 287 500\n",
      "152 230\n",
      "Hits@1 0.03806228373702422 Hits@10 0.17993079584775087 MRR 0.10090159736215248 cur_rank 42 total_num 288 500\n",
      "152 249\n",
      "Hits@1 0.03793103448275862 Hits@10 0.1793103448275862 MRR 0.10063028917201479 cur_rank 44 total_num 289 500\n",
      "0 0\n",
      "Hits@1 0.037800687285223365 Hits@10 0.18213058419243985 MRR 0.1011435871473687 cur_rank 3 total_num 290 500\n",
      "152 3\n",
      "Hits@1 0.03767123287671233 Hits@10 0.1815068493150685 MRR 0.10087503812538207 cur_rank 43 total_num 291 500\n",
      "152 28\n",
      "Hits@1 0.03754266211604096 Hits@10 0.18430034129692832 MRR 0.10087205164713844 cur_rank 9 total_num 292 500\n",
      "152 45\n",
      "Hits@1 0.03741496598639456 Hits@10 0.1836734693877551 MRR 0.10057370417465444 cur_rank 75 total_num 293 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "Hits@1 0.03728813559322034 Hits@10 0.18305084745762712 MRR 0.10044464077067257 cur_rank 15 total_num 294 500\n",
      "0 0\n",
      "Hits@1 0.037162162162162164 Hits@10 0.18243243243243243 MRR 0.10020767587044405 cur_rank 32 total_num 295 500\n",
      "152 234\n",
      "Hits@1 0.037037037037037035 Hits@10 0.18181818181818182 MRR 0.09994857869227247 cur_rank 42 total_num 296 500\n",
      "152 436\n",
      "Hits@1 0.03691275167785235 Hits@10 0.18120805369127516 MRR 0.09971187797419734 cur_rank 33 total_num 297 500\n",
      "152 305\n",
      "Hits@1 0.03678929765886288 Hits@10 0.1806020066889632 MRR 0.09946200547261139 cur_rank 39 total_num 298 500\n",
      "152 280\n",
      "Hits@1 0.03666666666666667 Hits@10 0.18 MRR 0.09931565063955454 cur_rank 17 total_num 299 500\n",
      "0 0\n",
      "Hits@1 0.036544850498338874 Hits@10 0.17940199335548174 MRR 0.09907798328785429 cur_rank 35 total_num 300 500\n",
      "152 303\n",
      "Hits@1 0.03642384105960265 Hits@10 0.17880794701986755 MRR 0.09883940396248732 cur_rank 36 total_num 301 500\n",
      "152 131\n",
      "Hits@1 0.036303630363036306 Hits@10 0.1782178217821782 MRR 0.0986452145104659 cur_rank 24 total_num 302 500\n",
      "152 1233\n",
      "Hits@1 0.03618421052631579 Hits@10 0.17763157894736842 MRR 0.0983938230884651 cur_rank 44 total_num 303 500\n",
      "152 36\n",
      "Hits@1 0.036065573770491806 Hits@10 0.17704918032786884 MRR 0.09812166175173118 cur_rank 64 total_num 304 500\n",
      "152 5\n",
      "Hits@1 0.03594771241830065 Hits@10 0.17647058823529413 MRR 0.09787881162773704 cur_rank 41 total_num 305 500\n",
      "152 187\n",
      "Hits@1 0.035830618892508145 Hits@10 0.1758957654723127 MRR 0.09762929300922545 cur_rank 46 total_num 306 500\n",
      "152 201\n",
      "Hits@1 0.03571428571428571 Hits@10 0.17532467532467533 MRR 0.09738610463168665 cur_rank 43 total_num 307 500\n",
      "152 5\n",
      "Hits@1 0.038834951456310676 Hits@10 0.1779935275080906 MRR 0.10030718519922163 cur_rank 0 total_num 308 500\n",
      "152 184\n",
      "Hits@1 0.03870967741935484 Hits@10 0.1774193548387097 MRR 0.10003036445220218 cur_rank 68 total_num 309 500\n",
      "152 360\n",
      "Hits@1 0.03858520900321544 Hits@10 0.17684887459807075 MRR 0.0997801774996942 cur_rank 44 total_num 310 500\n",
      "152 427\n",
      "Hits@1 0.041666666666666664 Hits@10 0.1794871794871795 MRR 0.10266549744360545 cur_rank 0 total_num 311 500\n",
      "152 321\n",
      "Hits@1 0.04153354632587859 Hits@10 0.17891373801916932 MRR 0.10242156866414884 cur_rank 37 total_num 312 500\n",
      "152 42\n",
      "Hits@1 0.041401273885350316 Hits@10 0.17834394904458598 MRR 0.10213901153508144 cur_rank 72 total_num 313 500\n",
      "152 36\n",
      "Hits@1 0.04126984126984127 Hits@10 0.18095238095238095 MRR 0.10221158610163673 cur_rank 7 total_num 314 500\n",
      "152 165\n",
      "Hits@1 0.04113924050632911 Hits@10 0.18037974683544303 MRR 0.10199725436910209 cur_rank 28 total_num 315 500\n",
      "152 575\n",
      "Hits@1 0.04100946372239748 Hits@10 0.17981072555205047 MRR 0.10174407416741654 cur_rank 45 total_num 316 500\n",
      "152 245\n",
      "Hits@1 0.040880503144654086 Hits@10 0.1792452830188679 MRR 0.10149725573907085 cur_rank 42 total_num 317 500\n",
      "152 157\n",
      "Hits@1 0.04075235109717868 Hits@10 0.1786833855799373 MRR 0.10124723026789753 cur_rank 45 total_num 318 500\n",
      "152 327\n",
      "Hits@1 0.040625 Hits@10 0.178125 MRR 0.10100523743521513 cur_rank 41 total_num 319 500\n",
      "152 868\n",
      "Hits@1 0.040498442367601244 Hits@10 0.17757009345794392 MRR 0.10076138084733992 cur_rank 43 total_num 320 500\n",
      "152 97\n",
      "Hits@1 0.040372670807453416 Hits@10 0.17701863354037267 MRR 0.10049623561298364 cur_rank 64 total_num 321 500\n",
      "152 173\n",
      "Hits@1 0.04024767801857585 Hits@10 0.17647058823529413 MRR 0.10024828492460075 cur_rank 48 total_num 322 500\n",
      "152 278\n",
      "Hits@1 0.040123456790123455 Hits@10 0.17592592592592593 MRR 0.10002229338787982 cur_rank 36 total_num 323 500\n",
      "152 20\n",
      "Hits@1 0.04 Hits@10 0.17846153846153845 MRR 0.10125299402360943 cur_rank 1 total_num 324 500\n",
      "0 0\n",
      "Hits@1 0.03987730061349693 Hits@10 0.17791411042944785 MRR 0.10109577625053086 cur_rank 19 total_num 325 500\n",
      "152 187\n",
      "Hits@1 0.039755351681957186 Hits@10 0.17737003058103976 MRR 0.10085032535475963 cur_rank 47 total_num 326 500\n",
      "152 282\n",
      "Hits@1 0.039634146341463415 Hits@10 0.17682926829268292 MRR 0.1006121453162612 cur_rank 43 total_num 327 500\n",
      "152 228\n",
      "Hits@1 0.03951367781155015 Hits@10 0.1762917933130699 MRR 0.10035873873265658 cur_rank 57 total_num 328 500\n",
      "152 106\n",
      "Hits@1 0.03939393939393939 Hits@10 0.17575757575757575 MRR 0.100110738065341 cur_rank 53 total_num 329 500\n",
      "152 889\n",
      "Hits@1 0.03927492447129909 Hits@10 0.17522658610271905 MRR 0.09987695116099639 cur_rank 43 total_num 330 500\n",
      "152 347\n",
      "Hits@1 0.0391566265060241 Hits@10 0.1746987951807229 MRR 0.09965334897569528 cur_rank 38 total_num 331 500\n",
      "0 0\n",
      "Hits@1 0.03903903903903904 Hits@10 0.17417417417417416 MRR 0.09946133977671207 cur_rank 27 total_num 332 500\n",
      "152 108\n",
      "Hits@1 0.038922155688622756 Hits@10 0.17664670658682635 MRR 0.0995912673308451 cur_rank 6 total_num 333 500\n",
      "0 0\n",
      "Hits@1 0.03880597014925373 Hits@10 0.1761194029850746 MRR 0.09945981744494872 cur_rank 17 total_num 334 500\n",
      "152 217\n",
      "Hits@1 0.03869047619047619 Hits@10 0.17559523809523808 MRR 0.09923639609511982 cur_rank 40 total_num 335 500\n",
      "152 714\n",
      "Hits@1 0.03857566765578635 Hits@10 0.17507418397626112 MRR 0.09900643388247787 cur_rank 45 total_num 336 500\n",
      "152 6\n",
      "Hits@1 0.04142011834319527 Hits@10 0.17751479289940827 MRR 0.10167209532069539 cur_rank 0 total_num 337 500\n",
      "152 553\n",
      "Hits@1 0.04129793510324484 Hits@10 0.17699115044247787 MRR 0.10143921973782394 cur_rank 43 total_num 338 500\n",
      "152 168\n",
      "Hits@1 0.041176470588235294 Hits@10 0.17647058823529413 MRR 0.10120480771046204 cur_rank 45 total_num 339 500\n",
      "0 0\n",
      "Hits@1 0.04105571847507331 Hits@10 0.17595307917888564 MRR 0.10107093893581423 cur_rank 17 total_num 340 500\n",
      "152 350\n",
      "Hits@1 0.04093567251461988 Hits@10 0.17543859649122806 MRR 0.10085443626941426 cur_rank 36 total_num 341 500\n",
      "152 46\n",
      "Hits@1 0.04081632653061224 Hits@10 0.1749271137026239 MRR 0.1006032743046432 cur_rank 67 total_num 342 500\n",
      "152 96\n",
      "Hits@1 0.040697674418604654 Hits@10 0.1744186046511628 MRR 0.1003523511650533 cur_rank 69 total_num 343 500\n",
      "152 4\n",
      "Hits@1 0.04057971014492753 Hits@10 0.17681159420289855 MRR 0.10047555345981297 cur_rank 6 total_num 344 500\n",
      "152 683\n",
      "Hits@1 0.04046242774566474 Hits@10 0.17630057803468208 MRR 0.10025926869733094 cur_rank 38 total_num 345 500\n",
      "152 469\n",
      "Hits@1 0.040345821325648415 Hits@10 0.17579250720461095 MRR 0.10003735672400575 cur_rank 42 total_num 346 500\n",
      "152 40\n",
      "Hits@1 0.040229885057471264 Hits@10 0.1752873563218391 MRR 0.09981375001566731 cur_rank 44 total_num 347 500\n",
      "152 100\n",
      "Hits@1 0.04011461318051576 Hits@10 0.17478510028653296 MRR 0.09960734321842407 cur_rank 35 total_num 348 500\n",
      "152 81\n",
      "Hits@1 0.04 Hits@10 0.1742857142857143 MRR 0.09940933089580867 cur_rank 32 total_num 349 500\n",
      "152 906\n",
      "Hits@1 0.039886039886039885 Hits@10 0.1737891737891738 MRR 0.09920108718805333 cur_rank 37 total_num 350 500\n",
      "152 678\n",
      "Hits@1 0.03977272727272727 Hits@10 0.17329545454545456 MRR 0.0989772436541819 cur_rank 48 total_num 351 500\n",
      "152 421\n",
      "Hits@1 0.039660056657223795 Hits@10 0.17280453257790368 MRR 0.09875712850429662 cur_rank 46 total_num 352 500\n",
      "152 451\n",
      "Hits@1 0.03954802259887006 Hits@10 0.17231638418079095 MRR 0.09858277796342865 cur_rank 26 total_num 353 500\n",
      "152 33\n",
      "Hits@1 0.03943661971830986 Hits@10 0.17183098591549295 MRR 0.09834590465542797 cur_rank 68 total_num 354 500\n",
      "152 246\n",
      "Hits@1 0.03932584269662921 Hits@10 0.17134831460674158 MRR 0.09813987683336217 cur_rank 39 total_num 355 500\n",
      "152 201\n",
      "Hits@1 0.0392156862745098 Hits@10 0.17086834733893558 MRR 0.09793500322878691 cur_rank 39 total_num 356 500\n",
      "152 75\n",
      "Hits@1 0.03910614525139665 Hits@10 0.17039106145251395 MRR 0.09772794881700127 cur_rank 41 total_num 357 500\n",
      "152 9\n",
      "Hits@1 0.03899721448467967 Hits@10 0.17270194986072424 MRR 0.0977342776503801 cur_rank 9 total_num 358 500\n",
      "152 188\n",
      "Hits@1 0.03888888888888889 Hits@10 0.17222222222222222 MRR 0.09754449289220095 cur_rank 33 total_num 359 500\n",
      "152 200\n",
      "Hits@1 0.038781163434903045 Hits@10 0.17174515235457063 MRR 0.09733584394297663 cur_rank 44 total_num 360 500\n",
      "152 97\n",
      "Hits@1 0.04143646408839779 Hits@10 0.17403314917127072 MRR 0.09982939133539935 cur_rank 0 total_num 361 500\n",
      "152 221\n",
      "Hits@1 0.04132231404958678 Hits@10 0.17355371900826447 MRR 0.09962156999260882 cur_rank 40 total_num 362 500\n",
      "0 0\n",
      "Hits@1 0.04120879120879121 Hits@10 0.17307692307692307 MRR 0.09945354792796303 cur_rank 25 total_num 363 500\n",
      "0 0\n",
      "Hits@1 0.0410958904109589 Hits@10 0.17534246575342466 MRR 0.09957246188667312 cur_rank 6 total_num 364 500\n",
      "152 163\n",
      "Hits@1 0.040983606557377046 Hits@10 0.17486338797814208 MRR 0.09952809268297548 cur_rank 11 total_num 365 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 93\n",
      "Hits@1 0.04087193460490463 Hits@10 0.1771117166212534 MRR 0.10061929679010634 cur_rank 1 total_num 366 500\n",
      "152 819\n",
      "Hits@1 0.04076086956521739 Hits@10 0.1766304347826087 MRR 0.10039915697039752 cur_rank 50 total_num 367 500\n",
      "152 1\n",
      "Hits@1 0.04065040650406504 Hits@10 0.17886178861788618 MRR 0.10080457930923112 cur_rank 3 total_num 368 500\n",
      "152 34\n",
      "Hits@1 0.04054054054054054 Hits@10 0.1783783783783784 MRR 0.10060518051927922 cur_rank 36 total_num 369 500\n",
      "152 183\n",
      "Hits@1 0.04043126684636118 Hits@10 0.1778975741239892 MRR 0.10039526702118755 cur_rank 43 total_num 370 500\n",
      "152 152\n",
      "Hits@1 0.04032258064516129 Hits@10 0.1774193548387097 MRR 0.1001825824209819 cur_rank 46 total_num 371 500\n",
      "0 0\n",
      "Hits@1 0.040214477211796246 Hits@10 0.1769436997319035 MRR 0.10000974516439556 cur_rank 27 total_num 372 500\n",
      "152 253\n",
      "Hits@1 0.040106951871657755 Hits@10 0.17647058823529413 MRR 0.09980175713513843 cur_rank 44 total_num 373 500\n",
      "152 632\n",
      "Hits@1 0.04 Hits@10 0.176 MRR 0.09975784133833362 cur_rank 11 total_num 374 500\n",
      "152 183\n",
      "Hits@1 0.0398936170212766 Hits@10 0.17553191489361702 MRR 0.09955034476678162 cur_rank 45 total_num 375 500\n",
      "152 19\n",
      "Hits@1 0.03978779840848806 Hits@10 0.17506631299734748 MRR 0.09935996660500708 cur_rank 35 total_num 376 500\n",
      "152 45\n",
      "Hits@1 0.03968253968253968 Hits@10 0.1746031746031746 MRR 0.09913334931276364 cur_rank 72 total_num 377 500\n",
      "152 160\n",
      "Hits@1 0.0395778364116095 Hits@10 0.1741424802110818 MRR 0.09893314473397928 cur_rank 42 total_num 378 500\n",
      "152 85\n",
      "Hits@1 0.039473684210526314 Hits@10 0.1736842105263158 MRR 0.0987667793155064 cur_rank 27 total_num 379 500\n",
      "0 0\n",
      "Hits@1 0.03937007874015748 Hits@10 0.1732283464566929 MRR 0.09867159091835283 cur_rank 15 total_num 380 500\n",
      "152 216\n",
      "Hits@1 0.03926701570680628 Hits@10 0.17277486910994763 MRR 0.09847019704274139 cur_rank 45 total_num 381 500\n",
      "152 38\n",
      "Hits@1 0.04177545691906005 Hits@10 0.17493472584856398 MRR 0.10082406075803449 cur_rank 0 total_num 382 500\n",
      "0 0\n",
      "Hits@1 0.041666666666666664 Hits@10 0.17447916666666666 MRR 0.1006545040521914 cur_rank 27 total_num 383 500\n",
      "152 105\n",
      "Hits@1 0.04155844155844156 Hits@10 0.17662337662337663 MRR 0.10068166407052626 cur_rank 8 total_num 384 500\n",
      "152 168\n",
      "Hits@1 0.04145077720207254 Hits@10 0.17616580310880828 MRR 0.10049933600377109 cur_rank 32 total_num 385 500\n",
      "152 279\n",
      "Hits@1 0.041343669250646 Hits@10 0.17571059431524547 MRR 0.10031142500060315 cur_rank 35 total_num 386 500\n",
      "0 0\n",
      "Hits@1 0.041237113402061855 Hits@10 0.17525773195876287 MRR 0.1001244826108536 cur_rank 35 total_num 387 500\n",
      "152 44\n",
      "Hits@1 0.04113110539845758 Hits@10 0.17480719794344474 MRR 0.09990330015437907 cur_rank 70 total_num 388 500\n",
      "152 96\n",
      "Hits@1 0.041025641025641026 Hits@10 0.17435897435897435 MRR 0.09969946647004811 cur_rank 48 total_num 389 500\n",
      "152 614\n",
      "Hits@1 0.04092071611253197 Hits@10 0.17391304347826086 MRR 0.09950841924122446 cur_rank 39 total_num 390 500\n",
      "152 145\n",
      "Hits@1 0.04081632653061224 Hits@10 0.17346938775510204 MRR 0.09929708823975875 cur_rank 59 total_num 391 500\n",
      "152 700\n",
      "Hits@1 0.04071246819338423 Hits@10 0.17302798982188294 MRR 0.09911138518946339 cur_rank 37 total_num 392 500\n",
      "152 93\n",
      "Hits@1 0.04060913705583756 Hits@10 0.17258883248730963 MRR 0.09894443581927016 cur_rank 29 total_num 393 500\n",
      "152 637\n",
      "Hits@1 0.04050632911392405 Hits@10 0.17215189873417722 MRR 0.09875020236712574 cur_rank 44 total_num 394 500\n",
      "152 146\n",
      "Hits@1 0.04040404040404041 Hits@10 0.17424242424242425 MRR 0.09900588367427947 cur_rank 4 total_num 395 500\n",
      "152 108\n",
      "Hits@1 0.04030226700251889 Hits@10 0.17380352644836272 MRR 0.09881125709181222 cur_rank 45 total_num 396 500\n",
      "152 149\n",
      "Hits@1 0.04271356783919598 Hits@10 0.17587939698492464 MRR 0.10107555041570214 cur_rank 0 total_num 397 500\n",
      "152 212\n",
      "Hits@1 0.042606516290726815 Hits@10 0.17543859649122806 MRR 0.10087918881748553 cur_rank 43 total_num 398 500\n",
      "152 220\n",
      "Hits@1 0.0425 Hits@10 0.175 MRR 0.10068254640099739 cur_rank 44 total_num 399 500\n",
      "152 261\n",
      "Hits@1 0.04239401496259352 Hits@10 0.1770573566084788 MRR 0.10167835052468567 cur_rank 1 total_num 400 500\n",
      "152 699\n",
      "Hits@1 0.04228855721393035 Hits@10 0.17661691542288557 MRR 0.1014794967433675 cur_rank 45 total_num 401 500\n",
      "152 52\n",
      "Hits@1 0.04218362282878412 Hits@10 0.1761786600496278 MRR 0.10129475116094482 cur_rank 36 total_num 402 500\n",
      "0 0\n",
      "Hits@1 0.04207920792079208 Hits@10 0.1782178217821782 MRR 0.1018691040871141 cur_rank 2 total_num 403 500\n",
      "152 119\n",
      "Hits@1 0.04197530864197531 Hits@10 0.17777777777777778 MRR 0.10168255269300686 cur_rank 37 total_num 404 500\n",
      "152 214\n",
      "Hits@1 0.04187192118226601 Hits@10 0.17733990147783252 MRR 0.101495258291401 cur_rank 38 total_num 405 500\n",
      "152 232\n",
      "Hits@1 0.04176904176904177 Hits@10 0.1769041769041769 MRR 0.10129816084042627 cur_rank 46 total_num 406 500\n",
      "152 822\n",
      "Hits@1 0.041666666666666664 Hits@10 0.17647058823529413 MRR 0.10111990904564931 cur_rank 34 total_num 407 500\n",
      "152 773\n",
      "Hits@1 0.04156479217603912 Hits@10 0.17603911980440098 MRR 0.10093536409844976 cur_rank 38 total_num 408 500\n",
      "152 39\n",
      "Hits@1 0.041463414634146344 Hits@10 0.17560975609756097 MRR 0.10072851938664394 cur_rank 61 total_num 409 500\n",
      "152 262\n",
      "Hits@1 0.0413625304136253 Hits@10 0.17761557177615572 MRR 0.10075378116699545 cur_rank 8 total_num 410 500\n",
      "152 268\n",
      "Hits@1 0.0412621359223301 Hits@10 0.17718446601941748 MRR 0.10057146865358291 cur_rank 38 total_num 411 500\n",
      "152 80\n",
      "Hits@1 0.043583535108958835 Hits@10 0.1791767554479419 MRR 0.10274926170769046 cur_rank 0 total_num 412 500\n",
      "152 142\n",
      "Hits@1 0.043478260869565216 Hits@10 0.178743961352657 MRR 0.10262820450295539 cur_rank 18 total_num 413 500\n",
      "152 20\n",
      "Hits@1 0.043373493975903614 Hits@10 0.1783132530120482 MRR 0.10243694573054703 cur_rank 42 total_num 414 500\n",
      "152 138\n",
      "Hits@1 0.04326923076923077 Hits@10 0.1778846153846154 MRR 0.10227973441157225 cur_rank 26 total_num 415 500\n",
      "152 368\n",
      "Hits@1 0.04316546762589928 Hits@10 0.1774580335731415 MRR 0.10209294906262949 cur_rank 40 total_num 416 500\n",
      "152 239\n",
      "Hits@1 0.0430622009569378 Hits@10 0.17703349282296652 MRR 0.10190071504677338 cur_rank 45 total_num 417 500\n",
      "152 66\n",
      "Hits@1 0.04295942720763723 Hits@10 0.1766109785202864 MRR 0.10179790553451801 cur_rank 16 total_num 418 500\n",
      "0 0\n",
      "Hits@1 0.04285714285714286 Hits@10 0.1761904761904762 MRR 0.10168780470123476 cur_rank 17 total_num 419 500\n",
      "152 13\n",
      "Hits@1 0.04275534441805225 Hits@10 0.17814726840855108 MRR 0.10263391442878528 cur_rank 1 total_num 420 500\n",
      "152 58\n",
      "Hits@1 0.04265402843601896 Hits@10 0.18009478672985782 MRR 0.10357554022397772 cur_rank 1 total_num 421 500\n",
      "152 330\n",
      "Hits@1 0.0425531914893617 Hits@10 0.17966903073286053 MRR 0.10338098007154439 cur_rank 46 total_num 422 500\n",
      "0 0\n",
      "Hits@1 0.04245283018867924 Hits@10 0.1792452830188679 MRR 0.1033185793565716 cur_rank 12 total_num 423 500\n",
      "152 500\n",
      "Hits@1 0.042352941176470586 Hits@10 0.1811764705882353 MRR 0.10333691472540582 cur_rank 8 total_num 424 500\n",
      "152 386\n",
      "Hits@1 0.04225352112676056 Hits@10 0.18309859154929578 MRR 0.10335516401269622 cur_rank 8 total_num 425 500\n",
      "152 110\n",
      "Hits@1 0.04215456674473068 Hits@10 0.18266978922716628 MRR 0.10317816779200555 cur_rank 35 total_num 426 500\n",
      "0 0\n",
      "Hits@1 0.04205607476635514 Hits@10 0.1822429906542056 MRR 0.10311682412175105 cur_rank 12 total_num 427 500\n",
      "152 345\n",
      "Hits@1 0.04195804195804196 Hits@10 0.18181818181818182 MRR 0.10293331227974799 cur_rank 40 total_num 428 500\n",
      "152 208\n",
      "Hits@1 0.04186046511627907 Hits@10 0.1813953488372093 MRR 0.10275356277593702 cur_rank 38 total_num 429 500\n",
      "0 0\n",
      "Hits@1 0.04176334106728538 Hits@10 0.18097447795823665 MRR 0.10269363125423665 cur_rank 12 total_num 430 500\n",
      "152 211\n",
      "Hits@1 0.041666666666666664 Hits@10 0.18055555555555555 MRR 0.10250623657641383 cur_rank 45 total_num 431 500\n",
      "152 272\n",
      "Hits@1 0.04157043879907621 Hits@10 0.18013856812933027 MRR 0.10232321019622233 cur_rank 42 total_num 432 500\n",
      "152 232\n",
      "Hits@1 0.041474654377880185 Hits@10 0.17972350230414746 MRR 0.10225202439261022 cur_rank 13 total_num 433 500\n",
      "152 12\n",
      "Hits@1 0.041379310344827586 Hits@10 0.18160919540229886 MRR 0.10316638755492606 cur_rank 1 total_num 434 500\n",
      "0 0\n",
      "Hits@1 0.04128440366972477 Hits@10 0.1811926605504587 MRR 0.1030571883989642 cur_rank 17 total_num 435 500\n",
      "152 214\n",
      "Hits@1 0.041189931350114416 Hits@10 0.18077803203661327 MRR 0.10287221135965817 cur_rank 44 total_num 436 500\n",
      "152 1126\n",
      "Hits@1 0.0410958904109589 Hits@10 0.18036529680365296 MRR 0.10270076288116073 cur_rank 35 total_num 437 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 312\n",
      "Hits@1 0.04100227790432802 Hits@10 0.17995444191343962 MRR 0.10255793654202368 cur_rank 24 total_num 438 500\n",
      "152 23\n",
      "Hits@1 0.04090909090909091 Hits@10 0.18181818181818182 MRR 0.10264952564728533 cur_rank 6 total_num 439 500\n",
      "152 56\n",
      "Hits@1 0.04081632653061224 Hits@10 0.1836734693877551 MRR 0.10298365370704204 cur_rank 3 total_num 440 500\n",
      "0 0\n",
      "Hits@1 0.04072398190045249 Hits@10 0.18552036199095023 MRR 0.10297690335928857 cur_rank 9 total_num 441 500\n",
      "0 0\n",
      "Hits@1 0.040632054176072234 Hits@10 0.18510158013544017 MRR 0.10290568816305669 cur_rank 13 total_num 442 500\n",
      "152 185\n",
      "Hits@1 0.04054054054054054 Hits@10 0.18468468468468469 MRR 0.10273318839123378 cur_rank 37 total_num 443 500\n",
      "152 817\n",
      "Hits@1 0.04044943820224719 Hits@10 0.1842696629213483 MRR 0.10257042399103557 cur_rank 32 total_num 444 500\n",
      "0 0\n",
      "Hits@1 0.04035874439461883 Hits@10 0.18385650224215247 MRR 0.1023711598792552 cur_rank 72 total_num 445 500\n",
      "152 60\n",
      "Hits@1 0.040268456375838924 Hits@10 0.18568232662192394 MRR 0.10288785377959989 cur_rank 2 total_num 446 500\n",
      "152 276\n",
      "Hits@1 0.04017857142857143 Hits@10 0.18526785714285715 MRR 0.1027126359004098 cur_rank 40 total_num 447 500\n",
      "152 56\n",
      "Hits@1 0.0400890868596882 Hits@10 0.1870824053452116 MRR 0.10359746299194564 cur_rank 1 total_num 448 500\n",
      "152 27\n",
      "Hits@1 0.04 Hits@10 0.18666666666666668 MRR 0.103412597881442 cur_rank 48 total_num 449 500\n",
      "152 1023\n",
      "Hits@1 0.03991130820399113 Hits@10 0.18625277161862527 MRR 0.10323257487554573 cur_rank 44 total_num 450 500\n",
      "0 0\n",
      "Hits@1 0.03982300884955752 Hits@10 0.18805309734513273 MRR 0.1032254231612193 cur_rank 9 total_num 451 500\n",
      "152 172\n",
      "Hits@1 0.039735099337748346 Hits@10 0.18763796909492272 MRR 0.10305721478123211 cur_rank 36 total_num 452 500\n",
      "152 790\n",
      "Hits@1 0.039647577092511016 Hits@10 0.18722466960352424 MRR 0.10287610491020151 cur_rank 47 total_num 453 500\n",
      "152 34\n",
      "Hits@1 0.03956043956043956 Hits@10 0.18681318681318682 MRR 0.10284980378052874 cur_rank 10 total_num 454 500\n",
      "152 592\n",
      "Hits@1 0.039473684210526314 Hits@10 0.18640350877192982 MRR 0.10267192949687579 cur_rank 45 total_num 455 500\n",
      "152 6\n",
      "Hits@1 0.04157549234135667 Hits@10 0.18818380743982493 MRR 0.10463544825071194 cur_rank 0 total_num 456 500\n",
      "152 268\n",
      "Hits@1 0.04148471615720524 Hits@10 0.18777292576419213 MRR 0.10445344202253284 cur_rank 46 total_num 457 500\n",
      "152 196\n",
      "Hits@1 0.04139433551198257 Hits@10 0.18736383442265794 MRR 0.10427774721161126 cur_rank 41 total_num 458 500\n",
      "152 529\n",
      "Hits@1 0.041304347826086954 Hits@10 0.18695652173913044 MRR 0.10409831543600945 cur_rank 45 total_num 459 500\n",
      "152 148\n",
      "Hits@1 0.04121475054229935 Hits@10 0.18655097613882862 MRR 0.10391966210628878 cur_rank 45 total_num 460 500\n",
      "152 895\n",
      "Hits@1 0.04112554112554113 Hits@10 0.18614718614718614 MRR 0.10382205142946081 cur_rank 16 total_num 461 500\n",
      "152 28\n",
      "Hits@1 0.04103671706263499 Hits@10 0.1857451403887689 MRR 0.10362866841187172 cur_rank 69 total_num 462 500\n",
      "152 127\n",
      "Hits@1 0.040948275862068964 Hits@10 0.1853448275862069 MRR 0.10345664439333219 cur_rank 41 total_num 463 500\n",
      "152 179\n",
      "Hits@1 0.04086021505376344 Hits@10 0.18494623655913978 MRR 0.1032866091234593 cur_rank 40 total_num 464 500\n",
      "152 200\n",
      "Hits@1 0.0407725321888412 Hits@10 0.18454935622317598 MRR 0.10311161453399861 cur_rank 45 total_num 465 500\n",
      "152 188\n",
      "Hits@1 0.04068522483940043 Hits@10 0.1841541755888651 MRR 0.10294180277655864 cur_rank 41 total_num 466 500\n",
      "152 191\n",
      "Hits@1 0.0405982905982906 Hits@10 0.18376068376068377 MRR 0.10277040420807725 cur_rank 43 total_num 467 500\n",
      "152 186\n",
      "Hits@1 0.04051172707889126 Hits@10 0.18336886993603413 MRR 0.1026139891984777 cur_rank 33 total_num 468 500\n",
      "152 21\n",
      "Hits@1 0.04042553191489362 Hits@10 0.1829787234042553 MRR 0.10246902913341857 cur_rank 28 total_num 469 500\n",
      "152 33\n",
      "Hits@1 0.040339702760084924 Hits@10 0.18471337579617833 MRR 0.10255477884408466 cur_rank 6 total_num 470 500\n",
      "0 0\n",
      "Hits@1 0.04025423728813559 Hits@10 0.1843220338983051 MRR 0.1025004743908622 cur_rank 12 total_num 471 500\n",
      "152 19\n",
      "Hits@1 0.040169133192389 Hits@10 0.18604651162790697 MRR 0.10263613230265035 cur_rank 5 total_num 472 500\n",
      "152 38\n",
      "Hits@1 0.04008438818565401 Hits@10 0.18565400843881857 MRR 0.10245062544621637 cur_rank 67 total_num 473 500\n",
      "152 188\n",
      "Hits@1 0.04 Hits@10 0.18526315789473685 MRR 0.1022807065093502 cur_rank 45 total_num 474 500\n",
      "152 157\n",
      "Hits@1 0.03991596638655462 Hits@10 0.18487394957983194 MRR 0.1021226105440512 cur_rank 36 total_num 475 500\n",
      "152 33\n",
      "Hits@1 0.039832285115303984 Hits@10 0.18448637316561844 MRR 0.10195409171782631 cur_rank 45 total_num 476 500\n",
      "152 49\n",
      "Hits@1 0.0397489539748954 Hits@10 0.18410041841004185 MRR 0.1018155147178189 cur_rank 27 total_num 477 500\n",
      "152 204\n",
      "Hits@1 0.03966597077244259 Hits@10 0.1837160751565762 MRR 0.10167030083430806 cur_rank 30 total_num 478 500\n",
      "152 660\n",
      "Hits@1 0.03958333333333333 Hits@10 0.18333333333333332 MRR 0.10151801151709373 cur_rank 34 total_num 479 500\n",
      "152 59\n",
      "Hits@1 0.0395010395010395 Hits@10 0.18295218295218296 MRR 0.10142924960003484 cur_rank 16 total_num 480 500\n",
      "152 55\n",
      "Hits@1 0.04149377593360996 Hits@10 0.18464730290456433 MRR 0.10329350426891444 cur_rank 0 total_num 481 500\n",
      "152 714\n",
      "Hits@1 0.041407867494824016 Hits@10 0.18426501035196688 MRR 0.1031314059163908 cur_rank 39 total_num 482 500\n",
      "152 46\n",
      "Hits@1 0.04132231404958678 Hits@10 0.18388429752066116 MRR 0.10300096912730736 cur_rank 24 total_num 483 500\n",
      "152 212\n",
      "Hits@1 0.041237113402061855 Hits@10 0.18350515463917524 MRR 0.10285107646993771 cur_rank 32 total_num 484 500\n",
      "0 0\n",
      "Hits@1 0.0411522633744856 Hits@10 0.1831275720164609 MRR 0.10279772667663142 cur_rank 12 total_num 485 500\n",
      "152 199\n",
      "Hits@1 0.04106776180698152 Hits@10 0.18275154004106775 MRR 0.10274459597898553 cur_rank 12 total_num 486 500\n",
      "152 220\n",
      "Hits@1 0.040983606557377046 Hits@10 0.18237704918032788 MRR 0.10257860117254249 cur_rank 45 total_num 487 500\n",
      "152 278\n",
      "Hits@1 0.04294478527607362 Hits@10 0.18404907975460122 MRR 0.10441381875705671 cur_rank 0 total_num 488 500\n",
      "152 258\n",
      "Hits@1 0.04285714285714286 Hits@10 0.1836734693877551 MRR 0.10424324633782463 cur_rank 47 total_num 489 500\n",
      "152 276\n",
      "Hits@1 0.04276985743380855 Hits@10 0.18329938900203666 MRR 0.10408751218597118 cur_rank 35 total_num 490 500\n",
      "152 228\n",
      "Hits@1 0.042682926829268296 Hits@10 0.18292682926829268 MRR 0.1039280681076278 cur_rank 38 total_num 491 500\n",
      "152 883\n",
      "Hits@1 0.04259634888438134 Hits@10 0.18255578093306288 MRR 0.10377872726015397 cur_rank 32 total_num 492 500\n",
      "0 0\n",
      "Hits@1 0.04251012145748988 Hits@10 0.18218623481781376 MRR 0.1036409449898182 cur_rank 27 total_num 493 500\n",
      "152 629\n",
      "Hits@1 0.04242424242424243 Hits@10 0.18181818181818182 MRR 0.1034785507857044 cur_rank 42 total_num 494 500\n",
      "152 855\n",
      "Hits@1 0.04233870967741935 Hits@10 0.1814516129032258 MRR 0.10332592825947876 cur_rank 35 total_num 495 500\n",
      "152 143\n",
      "Hits@1 0.04225352112676056 Hits@10 0.18108651911468812 MRR 0.10321863262917798 cur_rank 19 total_num 496 500\n",
      "152 414\n",
      "Hits@1 0.04216867469879518 Hits@10 0.18072289156626506 MRR 0.1030783007028811 cur_rank 29 total_num 497 500\n",
      "152 552\n",
      "Hits@1 0.04208416833667335 Hits@10 0.18036072144288579 MRR 0.10291529635364643 cur_rank 45 total_num 498 500\n",
      "152 338\n",
      "Hits@1 0.042 Hits@10 0.18 MRR 0.10276351981499318 cur_rank 36 total_num 499 500\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "#obtain the precision-recall area under curve (AUC-PR)##\n",
    "\n",
    "#randomly select 10% of the triples\n",
    "selected = random.sample(list(data_test), min(len(data_test), 500))\n",
    "\n",
    "random.shuffle(selected)\n",
    "\n",
    "###Hit at 1#############################\n",
    "#generate the negative samples by randomly replace relation with all the other relaiton\n",
    "Hits_at_1 = 0\n",
    "Hits_at_10 = 0\n",
    "MRR_raw = 0.\n",
    "\n",
    "for i in range(len(selected)):\n",
    "    \n",
    "    s_true, r_true, t_true = selected[i][0], selected[i][1], selected[i][2]\n",
    "    \n",
    "    score_dict = relation_ranking(s_true, t_true, 2, 2, 5, one_hop_ind, id2relation, model)\n",
    "    \n",
    "    #[... [score, r], ...]\n",
    "    temp_list = list()\n",
    "    \n",
    "    for r in id2relation:\n",
    "        \n",
    "        if r in score_dict:\n",
    "            \n",
    "            temp_list.append([score_dict[r], r])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            temp_list.append([0.0, r])\n",
    "        \n",
    "    sorted_list = sorted(temp_list, key = lambda x: x[0], reverse=True)\n",
    "    \n",
    "    p = 0\n",
    "    inverse_r = 0\n",
    "    exist_tri = 0\n",
    "    \n",
    "    while p < len(sorted_list) and sorted_list[p][1] != r_true:\n",
    "        \n",
    "        #we want to see how many inverse relaiton are ranked above true relation\n",
    "        #then, we remove them from ranking, otherwise it is not fair for us to compare our\n",
    "        #result with other model who does not consider inverse relations\n",
    "        if temp_list[p][1] % 2 != 0:\n",
    "            \n",
    "            inverse_r += 1\n",
    "        \n",
    "        #moreover, we want to remove existing triples\n",
    "        if ((s_true, sorted_list[p][1], t_true) in data_test) or (\n",
    "              (s_true, sorted_list[p][1], t_true) in data_valid) or (\n",
    "              (s_true, sorted_list[p][1], t_true) in data_ind):\n",
    "            \n",
    "            exist_tri += 1\n",
    "            \n",
    "        p += 1\n",
    "    \n",
    "    if p - inverse_r - exist_tri == 0:\n",
    "        \n",
    "        Hits_at_1 += 1\n",
    "        \n",
    "    if p - inverse_r - exist_tri < 10:\n",
    "        \n",
    "        Hits_at_10 += 1\n",
    "        \n",
    "    MRR_raw += 1./float(p - inverse_r - exist_tri + 1.) \n",
    "        \n",
    "    print('Hits@1', Hits_at_1/(i+1),\n",
    "          'Hits@10', Hits_at_10/(i+1),\n",
    "          'MRR', MRR_raw/(i+1),\n",
    "          'cur_rank', p - inverse_r - exist_tri, \n",
    "          'total_num', i, len(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b8c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e2f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223d509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b9b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a0597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75465fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e74af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29574e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce0cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c71be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81402e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e49a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72ed41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf9951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c818158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96440a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc36fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b54ea63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac4ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbc39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b05e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730aa25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af28d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf228418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b73aac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438 66\n",
      "Calculating_hit_at_one 0.0 current ranking: 1 triple number: 0 672\n",
      "438 1171\n",
      "Calculating_hit_at_one 0.0 current ranking: 1 triple number: 1 672\n",
      "438 1044\n",
      "Calculating_hit_at_one 0.0 current ranking: 1 triple number: 2 672\n",
      "438 600\n",
      "Calculating_hit_at_one 0.25 current ranking: 0 triple number: 3 672\n",
      "438 4356\n",
      "Calculating_hit_at_one 0.2 current ranking: 1 triple number: 4 672\n",
      "438 377\n",
      "Calculating_hit_at_one 0.3333333333333333 current ranking: 0 triple number: 5 672\n",
      "438 1864\n",
      "Calculating_hit_at_one 0.42857142857142855 current ranking: 0 triple number: 6 672\n",
      "438 509\n",
      "Calculating_hit_at_one 0.375 current ranking: 2 triple number: 7 672\n",
      "438 1675\n",
      "Calculating_hit_at_one 0.3333333333333333 current ranking: 27 triple number: 8 672\n",
      "438 625\n",
      "Calculating_hit_at_one 0.3 current ranking: 1 triple number: 9 672\n",
      "438 2672\n",
      "Calculating_hit_at_one 0.36363636363636365 current ranking: 0 triple number: 10 672\n",
      "438 1404\n",
      "Calculating_hit_at_one 0.3333333333333333 current ranking: 2 triple number: 11 672\n",
      "438 553\n",
      "Calculating_hit_at_one 0.38461538461538464 current ranking: 0 triple number: 12 672\n",
      "438 736\n",
      "Calculating_hit_at_one 0.42857142857142855 current ranking: 0 triple number: 13 672\n",
      "438 504\n",
      "Calculating_hit_at_one 0.4666666666666667 current ranking: 0 triple number: 14 672\n",
      "438 330\n",
      "Calculating_hit_at_one 0.4375 current ranking: 119 triple number: 15 672\n",
      "438 438\n",
      "Calculating_hit_at_one 0.4117647058823529 current ranking: 9 triple number: 16 672\n",
      "438 721\n",
      "Calculating_hit_at_one 0.4444444444444444 current ranking: 0 triple number: 17 672\n",
      "438 395\n",
      "Calculating_hit_at_one 0.47368421052631576 current ranking: 0 triple number: 18 672\n",
      "438 3735\n",
      "Calculating_hit_at_one 0.5 current ranking: 0 triple number: 19 672\n",
      "438 1589\n",
      "Calculating_hit_at_one 0.47619047619047616 current ranking: 1 triple number: 20 672\n",
      "438 3431\n",
      "Calculating_hit_at_one 0.5 current ranking: 0 triple number: 21 672\n",
      "438 10\n",
      "Calculating_hit_at_one 0.4782608695652174 current ranking: 3 triple number: 22 672\n",
      "438 51\n",
      "Calculating_hit_at_one 0.4583333333333333 current ranking: 104 triple number: 23 672\n",
      "438 191\n",
      "Calculating_hit_at_one 0.48 current ranking: 0 triple number: 24 672\n",
      "438 262\n",
      "Calculating_hit_at_one 0.5 current ranking: 0 triple number: 25 672\n",
      "438 1695\n",
      "Calculating_hit_at_one 0.5185185185185185 current ranking: 0 triple number: 26 672\n",
      "438 401\n",
      "Calculating_hit_at_one 0.5 current ranking: 131 triple number: 27 672\n",
      "438 1442\n",
      "Calculating_hit_at_one 0.4827586206896552 current ranking: 1 triple number: 28 672\n",
      "438 1909\n",
      "Calculating_hit_at_one 0.5 current ranking: 0 triple number: 29 672\n",
      "438 334\n",
      "Calculating_hit_at_one 0.4838709677419355 current ranking: 81 triple number: 30 672\n",
      "438 933\n",
      "Calculating_hit_at_one 0.46875 current ranking: 9 triple number: 31 672\n",
      "438 908\n",
      "Calculating_hit_at_one 0.48484848484848486 current ranking: 0 triple number: 32 672\n",
      "438 180\n",
      "Calculating_hit_at_one 0.47058823529411764 current ranking: 11 triple number: 33 672\n",
      "438 1411\n",
      "Calculating_hit_at_one 0.4857142857142857 current ranking: 0 triple number: 34 672\n",
      "438 1847\n",
      "Calculating_hit_at_one 0.5 current ranking: 0 triple number: 35 672\n",
      "438 2316\n",
      "Calculating_hit_at_one 0.4864864864864865 current ranking: 1 triple number: 36 672\n",
      "438 867\n",
      "Calculating_hit_at_one 0.47368421052631576 current ranking: 1 triple number: 37 672\n",
      "438 457\n",
      "Calculating_hit_at_one 0.48717948717948717 current ranking: 0 triple number: 38 672\n",
      "438 2672\n",
      "Calculating_hit_at_one 0.5 current ranking: 0 triple number: 39 672\n",
      "438 785\n",
      "Calculating_hit_at_one 0.4878048780487805 current ranking: 5 triple number: 40 672\n",
      "438 2050\n",
      "Calculating_hit_at_one 0.5 current ranking: 0 triple number: 41 672\n",
      "438 2840\n",
      "Calculating_hit_at_one 0.5116279069767442 current ranking: 0 triple number: 42 672\n",
      "438 535\n",
      "Calculating_hit_at_one 0.5 current ranking: 1 triple number: 43 672\n",
      "438 3809\n",
      "Calculating_hit_at_one 0.5111111111111111 current ranking: 0 triple number: 44 672\n",
      "438 390\n",
      "Calculating_hit_at_one 0.5217391304347826 current ranking: 0 triple number: 45 672\n",
      "438 421\n",
      "Calculating_hit_at_one 0.5319148936170213 current ranking: 0 triple number: 46 672\n",
      "438 281\n",
      "Calculating_hit_at_one 0.5208333333333334 current ranking: 10 triple number: 47 672\n",
      "438 1173\n",
      "Calculating_hit_at_one 0.5306122448979592 current ranking: 0 triple number: 48 672\n",
      "438 4374\n",
      "Calculating_hit_at_one 0.54 current ranking: 0 triple number: 49 672\n",
      "438 3454\n",
      "Calculating_hit_at_one 0.5490196078431373 current ranking: 0 triple number: 50 672\n",
      "438 246\n",
      "Calculating_hit_at_one 0.5384615384615384 current ranking: 43 triple number: 51 672\n",
      "438 258\n",
      "Calculating_hit_at_one 0.5471698113207547 current ranking: 0 triple number: 52 672\n",
      "438 2096\n",
      "Calculating_hit_at_one 0.5370370370370371 current ranking: 1 triple number: 53 672\n",
      "438 58\n",
      "Calculating_hit_at_one 0.5272727272727272 current ranking: 9 triple number: 54 672\n",
      "438 352\n",
      "Calculating_hit_at_one 0.5357142857142857 current ranking: 0 triple number: 55 672\n",
      "438 753\n",
      "Calculating_hit_at_one 0.543859649122807 current ranking: 0 triple number: 56 672\n",
      "438 4675\n",
      "Calculating_hit_at_one 0.5517241379310345 current ranking: 0 triple number: 57 672\n",
      "438 193\n",
      "Calculating_hit_at_one 0.5423728813559322 current ranking: 116 triple number: 58 672\n",
      "438 1914\n",
      "Calculating_hit_at_one 0.5333333333333333 current ranking: 5 triple number: 59 672\n",
      "438 4307\n",
      "Calculating_hit_at_one 0.5409836065573771 current ranking: 0 triple number: 60 672\n",
      "438 2299\n",
      "Calculating_hit_at_one 0.532258064516129 current ranking: 1 triple number: 61 672\n",
      "438 527\n",
      "Calculating_hit_at_one 0.5238095238095238 current ranking: 1 triple number: 62 672\n",
      "438 1285\n",
      "Calculating_hit_at_one 0.53125 current ranking: 0 triple number: 63 672\n",
      "438 1595\n",
      "Calculating_hit_at_one 0.5384615384615384 current ranking: 0 triple number: 64 672\n",
      "438 1779\n",
      "Calculating_hit_at_one 0.5303030303030303 current ranking: 1 triple number: 65 672\n",
      "438 306\n",
      "Calculating_hit_at_one 0.5223880597014925 current ranking: 35 triple number: 66 672\n",
      "438 2739\n",
      "Calculating_hit_at_one 0.5294117647058824 current ranking: 0 triple number: 67 672\n",
      "438 1305\n",
      "Calculating_hit_at_one 0.5362318840579711 current ranking: 0 triple number: 68 672\n",
      "438 733\n",
      "Calculating_hit_at_one 0.5428571428571428 current ranking: 0 triple number: 69 672\n",
      "438 5028\n",
      "Calculating_hit_at_one 0.5352112676056338 current ranking: 1 triple number: 70 672\n",
      "438 1663\n",
      "Calculating_hit_at_one 0.5277777777777778 current ranking: 1 triple number: 71 672\n",
      "438 1475\n",
      "Calculating_hit_at_one 0.5342465753424658 current ranking: 0 triple number: 72 672\n",
      "438 731\n",
      "Calculating_hit_at_one 0.527027027027027 current ranking: 3 triple number: 73 672\n",
      "438 712\n",
      "Calculating_hit_at_one 0.52 current ranking: 3 triple number: 74 672\n",
      "438 317\n",
      "Calculating_hit_at_one 0.5131578947368421 current ranking: 4 triple number: 75 672\n",
      "438 1267\n",
      "Calculating_hit_at_one 0.5064935064935064 current ranking: 1 triple number: 76 672\n",
      "438 26\n",
      "Calculating_hit_at_one 0.5 current ranking: 9 triple number: 77 672\n",
      "438 1327\n",
      "Calculating_hit_at_one 0.4936708860759494 current ranking: 7 triple number: 78 672\n",
      "438 1658\n",
      "Calculating_hit_at_one 0.5 current ranking: 0 triple number: 79 672\n",
      "438 764\n",
      "Calculating_hit_at_one 0.5061728395061729 current ranking: 0 triple number: 80 672\n",
      "438 1665\n",
      "Calculating_hit_at_one 0.5121951219512195 current ranking: 0 triple number: 81 672\n",
      "438 1394\n",
      "Calculating_hit_at_one 0.5180722891566265 current ranking: 0 triple number: 82 672\n",
      "438 939\n",
      "Calculating_hit_at_one 0.5119047619047619 current ranking: 1 triple number: 83 672\n",
      "438 4662\n",
      "Calculating_hit_at_one 0.5176470588235295 current ranking: 0 triple number: 84 672\n",
      "438 2385\n",
      "Calculating_hit_at_one 0.5116279069767442 current ranking: 1 triple number: 85 672\n",
      "438 1781\n",
      "Calculating_hit_at_one 0.5172413793103449 current ranking: 0 triple number: 86 672\n",
      "438 170\n",
      "Calculating_hit_at_one 0.5227272727272727 current ranking: 0 triple number: 87 672\n",
      "438 1442\n",
      "Calculating_hit_at_one 0.5280898876404494 current ranking: 0 triple number: 88 672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/2855118348.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0ms_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscore_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelation_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2relation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#[... [score, r], ...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/1097907060.py\u001b[0m in \u001b[0;36mrelation_ranking\u001b[0;34m(s, t, diff, lower_bd, upper_bd, one_hop, id2relation, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         result, length_dict = Class_2.obtain_paths('target_specified', \n\u001b[0m\u001b[1;32m      8\u001b[0m                                                    s, t, lower_bd, upper_bd, one_hop)\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/3003381867.py\u001b[0m in \u001b[0;36mobtain_paths\u001b[0;34m(self, mode, s, t_input, lower_bd, upper_bd, one_hop)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mcount_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_bd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_56004/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;31m#The recursion is forced to stop for that length (and hence for longer lengths) once reach the threshold.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             if (len(path) < upper_bd) and (length_dict[len(path) + 1] < self.size_bd) and (\n\u001b[0;32m---> 99\u001b[0;31m                 count_dict[len(path)] <= self.threshold):\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m#we randomly shuffle relation r so that the reading in order is not fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Ranking on transductive setting'''\n",
    "\n",
    "########################################################\n",
    "#obtain the precision-recall area under curve (AUC-PR)##\n",
    "\n",
    "#randomly select 10% of the triples\n",
    "selected = random.sample(list(data_test), int(len(data_test)/5))\n",
    "\n",
    "random.shuffle(selected)\n",
    "\n",
    "###Hit at 1#############################\n",
    "#generate the negative samples by randomly replace relation with all the other relaiton\n",
    "Hits_at_1 = 0\n",
    "\n",
    "for i in range(len(selected)):\n",
    "    \n",
    "    s_true, r_true, t_true = selected[i][0], selected[i][1], selected[i][2]\n",
    "    \n",
    "    score_dict = relation_ranking(s_true, t_true, 2, 2, 10, one_hop, id2relation, model)\n",
    "    \n",
    "    #[... [score, r], ...]\n",
    "    temp_list = list()\n",
    "    \n",
    "    for r in id2relation:\n",
    "        \n",
    "        if r in score_dict:\n",
    "            \n",
    "            temp_list.append([score_dict[r], r])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            temp_list.append([0.0, r])\n",
    "        \n",
    "    sorted_list = sorted(temp_list, key = lambda x: x[0], reverse=True)\n",
    "    \n",
    "    p = 0\n",
    "    inverse_r = 0\n",
    "    exist_tri = 0\n",
    "    \n",
    "    while p < len(sorted_list) and sorted_list[p][1] != r_true:\n",
    "        \n",
    "        #we want to see how many inverse relaiton are ranked above true relation\n",
    "        #then, we remove them from ranking, otherwise it is not fair for us to compare our\n",
    "        #result with other model who does not consider inverse relations\n",
    "        if temp_list[p][1] % 2 != 0:\n",
    "            \n",
    "            inverse_r += 1\n",
    "        \n",
    "        #moreover, we want to remove existing triples\n",
    "        if ((s_true, sorted_list[p][1], t_true) in data_test) or (\n",
    "              (s_true, sorted_list[p][1], t_true) in data_valid) or (\n",
    "              (s_true, sorted_list[p][1], t_true) in data):\n",
    "            \n",
    "            exist_tri += 1\n",
    "            \n",
    "        p += 1\n",
    "    \n",
    "    if p - inverse_r - exist_tri == 0:\n",
    "        \n",
    "        Hits_at_1 += 1\n",
    "        \n",
    "    print('Calculating_hit_at_one', Hits_at_1/(i+1), 'current ranking:', \n",
    "          p - inverse_r - exist_tri, 'triple number:', i, len(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b05742d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438 263\n",
      "Calculating_hit_at_one 1.0 current ranking: 0 0 284\n",
      "438 3646\n",
      "Calculating_hit_at_one 0.5 current ranking: 1 1 284\n",
      "438 1588\n",
      "Calculating_hit_at_one 0.3333333333333333 current ranking: 10 2 284\n",
      "438 707\n",
      "Calculating_hit_at_one 0.25 current ranking: 4 3 284\n",
      "438 3451\n",
      "Calculating_hit_at_one 0.4 current ranking: 0 4 284\n",
      "438 2757\n",
      "Calculating_hit_at_one 0.3333333333333333 current ranking: 7 5 284\n",
      "438 559\n",
      "Calculating_hit_at_one 0.2857142857142857 current ranking: 1 6 284\n",
      "438 2868\n",
      "Calculating_hit_at_one 0.375 current ranking: 0 7 284\n",
      "438 3601\n",
      "Calculating_hit_at_one 0.3333333333333333 current ranking: 1 8 284\n",
      "438 1470\n",
      "Calculating_hit_at_one 0.4 current ranking: 0 9 284\n",
      "438 37\n",
      "Calculating_hit_at_one 0.36363636363636365 current ranking: 1 10 284\n",
      "438 2329\n",
      "Calculating_hit_at_one 0.3333333333333333 current ranking: 7 11 284\n",
      "438 1230\n",
      "Calculating_hit_at_one 0.38461538461538464 current ranking: 0 12 284\n",
      "438 929\n",
      "Calculating_hit_at_one 0.35714285714285715 current ranking: 1 13 284\n",
      "438 691\n",
      "Calculating_hit_at_one 0.3333333333333333 current ranking: 13 14 284\n",
      "438 1319\n",
      "Calculating_hit_at_one 0.3125 current ranking: 1 15 284\n",
      "438 454\n",
      "Calculating_hit_at_one 0.35294117647058826 current ranking: 0 16 284\n",
      "438 956\n",
      "Calculating_hit_at_one 0.3888888888888889 current ranking: 0 17 284\n",
      "438 2784\n",
      "Calculating_hit_at_one 0.3684210526315789 current ranking: 1 18 284\n",
      "438 59\n",
      "Calculating_hit_at_one 0.35 current ranking: 1 19 284\n",
      "438 1409\n",
      "Calculating_hit_at_one 0.3333333333333333 current ranking: 1 20 284\n",
      "438 205\n",
      "Calculating_hit_at_one 0.3181818181818182 current ranking: 4 21 284\n",
      "438 3403\n",
      "Calculating_hit_at_one 0.30434782608695654 current ranking: 1 22 284\n",
      "438 2594\n",
      "Calculating_hit_at_one 0.2916666666666667 current ranking: 3 23 284\n",
      "438 1249\n",
      "Calculating_hit_at_one 0.28 current ranking: 28 24 284\n",
      "438 39\n",
      "Calculating_hit_at_one 0.2692307692307692 current ranking: 1 25 284\n",
      "438 1055\n",
      "Calculating_hit_at_one 0.2962962962962963 current ranking: 0 26 284\n",
      "438 582\n",
      "Calculating_hit_at_one 0.2857142857142857 current ranking: 112 27 284\n",
      "438 302\n",
      "Calculating_hit_at_one 0.27586206896551724 current ranking: 1 28 284\n",
      "438 948\n",
      "Calculating_hit_at_one 0.26666666666666666 current ranking: 1 29 284\n",
      "438 2551\n",
      "Calculating_hit_at_one 0.2903225806451613 current ranking: 0 30 284\n",
      "438 158\n",
      "Calculating_hit_at_one 0.28125 current ranking: 8 31 284\n",
      "0 0\n",
      "Calculating_hit_at_one 0.2727272727272727 current ranking: 186 32 284\n",
      "438 998\n",
      "Calculating_hit_at_one 0.2647058823529412 current ranking: 5 33 284\n",
      "438 2012\n",
      "Calculating_hit_at_one 0.2857142857142857 current ranking: 0 34 284\n",
      "438 212\n",
      "Calculating_hit_at_one 0.2777777777777778 current ranking: 45 35 284\n",
      "438 790\n",
      "Calculating_hit_at_one 0.2972972972972973 current ranking: 0 36 284\n",
      "438 1262\n",
      "Calculating_hit_at_one 0.2894736842105263 current ranking: 1 37 284\n",
      "438 887\n",
      "Calculating_hit_at_one 0.28205128205128205 current ranking: 9 38 284\n",
      "438 241\n",
      "Calculating_hit_at_one 0.275 current ranking: 1 39 284\n",
      "438 907\n",
      "Calculating_hit_at_one 0.2682926829268293 current ranking: 1 40 284\n",
      "0 0\n",
      "Calculating_hit_at_one 0.2619047619047619 current ranking: 108 41 284\n",
      "438 2264\n",
      "Calculating_hit_at_one 0.2558139534883721 current ranking: 3 42 284\n",
      "438 945\n",
      "Calculating_hit_at_one 0.25 current ranking: 1 43 284\n",
      "438 827\n",
      "Calculating_hit_at_one 0.24444444444444444 current ranking: 1 44 284\n",
      "438 198\n",
      "Calculating_hit_at_one 0.2608695652173913 current ranking: 0 45 284\n",
      "438 387\n",
      "Calculating_hit_at_one 0.2553191489361702 current ranking: 65 46 284\n",
      "438 3236\n",
      "Calculating_hit_at_one 0.2708333333333333 current ranking: 0 47 284\n",
      "438 966\n",
      "Calculating_hit_at_one 0.2857142857142857 current ranking: 0 48 284\n",
      "438 1543\n",
      "Calculating_hit_at_one 0.28 current ranking: 2 49 284\n",
      "438 704\n",
      "Calculating_hit_at_one 0.27450980392156865 current ranking: 11 50 284\n",
      "438 1712\n",
      "Calculating_hit_at_one 0.28846153846153844 current ranking: 0 51 284\n",
      "438 1675\n",
      "Calculating_hit_at_one 0.2830188679245283 current ranking: 1 52 284\n",
      "438 572\n",
      "Calculating_hit_at_one 0.2962962962962963 current ranking: 0 53 284\n",
      "438 992\n",
      "Calculating_hit_at_one 0.2909090909090909 current ranking: 3 54 284\n",
      "438 435\n",
      "Calculating_hit_at_one 0.2857142857142857 current ranking: 1 55 284\n",
      "438 579\n",
      "Calculating_hit_at_one 0.2807017543859649 current ranking: 1 56 284\n",
      "438 4667\n",
      "Calculating_hit_at_one 0.29310344827586204 current ranking: 0 57 284\n",
      "438 4013\n",
      "Calculating_hit_at_one 0.288135593220339 current ranking: 1 58 284\n",
      "438 380\n",
      "Calculating_hit_at_one 0.2833333333333333 current ranking: 4 59 284\n",
      "438 2771\n",
      "Calculating_hit_at_one 0.2786885245901639 current ranking: 7 60 284\n",
      "438 2005\n",
      "Calculating_hit_at_one 0.27419354838709675 current ranking: 1 61 284\n",
      "438 769\n",
      "Calculating_hit_at_one 0.2698412698412698 current ranking: 2 62 284\n",
      "438 614\n",
      "Calculating_hit_at_one 0.265625 current ranking: 5 63 284\n",
      "438 1272\n",
      "Calculating_hit_at_one 0.27692307692307694 current ranking: 0 64 284\n",
      "438 42\n",
      "Calculating_hit_at_one 0.2727272727272727 current ranking: 10 65 284\n",
      "438 569\n",
      "Calculating_hit_at_one 0.2835820895522388 current ranking: 0 66 284\n",
      "438 520\n",
      "Calculating_hit_at_one 0.27941176470588236 current ranking: 53 67 284\n",
      "438 344\n",
      "Calculating_hit_at_one 0.2753623188405797 current ranking: 4 68 284\n",
      "438 688\n",
      "Calculating_hit_at_one 0.2714285714285714 current ranking: 98 69 284\n",
      "438 2565\n",
      "Calculating_hit_at_one 0.28169014084507044 current ranking: 0 70 284\n",
      "438 838\n",
      "Calculating_hit_at_one 0.2916666666666667 current ranking: 0 71 284\n",
      "438 3165\n",
      "Calculating_hit_at_one 0.3013698630136986 current ranking: 0 72 284\n",
      "438 461\n",
      "Calculating_hit_at_one 0.3108108108108108 current ranking: 0 73 284\n",
      "0 0\n",
      "Calculating_hit_at_one 0.30666666666666664 current ranking: 116 74 284\n",
      "438 170\n",
      "Calculating_hit_at_one 0.3026315789473684 current ranking: 12 75 284\n",
      "438 322\n",
      "Calculating_hit_at_one 0.2987012987012987 current ranking: 3 76 284\n",
      "438 851\n",
      "Calculating_hit_at_one 0.2948717948717949 current ranking: 1 77 284\n",
      "438 214\n",
      "Calculating_hit_at_one 0.2911392405063291 current ranking: 1 78 284\n",
      "438 151\n",
      "Calculating_hit_at_one 0.2875 current ranking: 11 79 284\n",
      "438 4681\n",
      "Calculating_hit_at_one 0.2839506172839506 current ranking: 4 80 284\n",
      "438 1960\n",
      "Calculating_hit_at_one 0.2926829268292683 current ranking: 0 81 284\n",
      "438 1153\n",
      "Calculating_hit_at_one 0.30120481927710846 current ranking: 0 82 284\n",
      "438 2945\n",
      "Calculating_hit_at_one 0.2976190476190476 current ranking: 1 83 284\n",
      "438 1396\n",
      "Calculating_hit_at_one 0.29411764705882354 current ranking: 1 84 284\n",
      "438 1133\n",
      "Calculating_hit_at_one 0.3023255813953488 current ranking: 0 85 284\n",
      "438 1849\n",
      "Calculating_hit_at_one 0.2988505747126437 current ranking: 1 86 284\n",
      "438 720\n",
      "Calculating_hit_at_one 0.29545454545454547 current ranking: 1 87 284\n",
      "438 882\n",
      "Calculating_hit_at_one 0.29213483146067415 current ranking: 2 88 284\n",
      "438 2509\n",
      "Calculating_hit_at_one 0.28888888888888886 current ranking: 81 89 284\n",
      "438 216\n",
      "Calculating_hit_at_one 0.2857142857142857 current ranking: 10 90 284\n",
      "438 1759\n",
      "Calculating_hit_at_one 0.2826086956521739 current ranking: 1 91 284\n",
      "438 1058\n",
      "Calculating_hit_at_one 0.27956989247311825 current ranking: 11 92 284\n",
      "438 549\n",
      "Calculating_hit_at_one 0.2872340425531915 current ranking: 0 93 284\n",
      "438 2574\n",
      "Calculating_hit_at_one 0.29473684210526313 current ranking: 0 94 284\n",
      "438 4393\n",
      "Calculating_hit_at_one 0.2916666666666667 current ranking: 4 95 284\n",
      "438 875\n",
      "Calculating_hit_at_one 0.28865979381443296 current ranking: 2 96 284\n",
      "438 1604\n",
      "Calculating_hit_at_one 0.2857142857142857 current ranking: 1 97 284\n",
      "438 1107\n",
      "Calculating_hit_at_one 0.2828282828282828 current ranking: 1 98 284\n",
      "438 4145\n",
      "Calculating_hit_at_one 0.29 current ranking: 0 99 284\n",
      "438 2384\n",
      "Calculating_hit_at_one 0.297029702970297 current ranking: 0 100 284\n",
      "438 3015\n",
      "Calculating_hit_at_one 0.30392156862745096 current ranking: 0 101 284\n",
      "438 2248\n",
      "Calculating_hit_at_one 0.3106796116504854 current ranking: 0 102 284\n",
      "438 4661\n",
      "Calculating_hit_at_one 0.3076923076923077 current ranking: 1 103 284\n",
      "438 306\n",
      "Calculating_hit_at_one 0.3142857142857143 current ranking: 0 104 284\n",
      "438 1214\n",
      "Calculating_hit_at_one 0.3113207547169811 current ranking: 9 105 284\n",
      "438 2871\n",
      "Calculating_hit_at_one 0.3177570093457944 current ranking: 0 106 284\n",
      "438 77\n",
      "Calculating_hit_at_one 0.3148148148148148 current ranking: 3 107 284\n",
      "438 3578\n",
      "Calculating_hit_at_one 0.3119266055045872 current ranking: 119 108 284\n",
      "438 536\n",
      "Calculating_hit_at_one 0.3090909090909091 current ranking: 9 109 284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438 660\n",
      "Calculating_hit_at_one 0.3063063063063063 current ranking: 1 110 284\n",
      "438 2095\n",
      "Calculating_hit_at_one 0.30357142857142855 current ranking: 2 111 284\n",
      "438 2160\n",
      "Calculating_hit_at_one 0.30973451327433627 current ranking: 0 112 284\n",
      "438 1207\n",
      "Calculating_hit_at_one 0.3157894736842105 current ranking: 0 113 284\n",
      "438 1671\n",
      "Calculating_hit_at_one 0.3130434782608696 current ranking: 1 114 284\n",
      "438 5113\n",
      "Calculating_hit_at_one 0.3103448275862069 current ranking: 1 115 284\n",
      "438 4248\n",
      "Calculating_hit_at_one 0.3162393162393162 current ranking: 0 116 284\n",
      "438 2935\n",
      "Calculating_hit_at_one 0.3135593220338983 current ranking: 96 117 284\n",
      "438 36\n",
      "Calculating_hit_at_one 0.31092436974789917 current ranking: 1 118 284\n",
      "438 429\n",
      "Calculating_hit_at_one 0.30833333333333335 current ranking: 1 119 284\n",
      "438 4473\n",
      "Calculating_hit_at_one 0.30578512396694213 current ranking: 3 120 284\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_33515/3794481705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0ms_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscore_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelation_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hop_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2relation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#[... [score, r], ...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_33515/1097907060.py\u001b[0m in \u001b[0;36mrelation_ranking\u001b[0;34m(s, t, diff, lower_bd, upper_bd, one_hop, id2relation, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         result, length_dict = Class_2.obtain_paths('target_specified', \n\u001b[0m\u001b[1;32m      8\u001b[0m                                                    s, t, lower_bd, upper_bd, one_hop)\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_33515/3003381867.py\u001b[0m in \u001b[0;36mobtain_paths\u001b[0;34m(self, mode, s, t_input, lower_bd, upper_bd, one_hop)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mcount_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_bd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_33515/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_33515/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_33515/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_33515/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    124\u001b[0m                             \u001b[0mcount_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                             helper(t, path + [r], on_path_en.union({t}), res, direct_nb, \n\u001b[0m\u001b[1;32m    127\u001b[0m                                    lower_bd, upper_bd, one_hop, length_dict, count_dict)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_33515/3003381867.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(node, path, on_path_en, res, direct_nb, lower_bd, upper_bd, one_hop, length_dict, count_dict)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi_1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python39_tensorfl/lib/python3.9/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;34m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;31m# raises IndexError if seq is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "#obtain the precision-recall area under curve (AUC-PR)##\n",
    "\n",
    "#randomly select 10% of the triples\n",
    "selected = random.sample(list(data_test), int(len(data_test)/5))\n",
    "\n",
    "random.shuffle(selected)\n",
    "\n",
    "###Hit at 1#############################\n",
    "#generate the negative samples by randomly replace relation with all the other relaiton\n",
    "Hits_at_1 = 0\n",
    "\n",
    "for i in range(len(selected)):\n",
    "    \n",
    "    s_true, r_true, t_true = selected[i][0], selected[i][1], selected[i][2]\n",
    "    \n",
    "    score_dict = relation_ranking(s_true, t_true, 2, 2, 10, one_hop_ind, id2relation, model)\n",
    "    \n",
    "    #[... [score, r], ...]\n",
    "    temp_list = list()\n",
    "    \n",
    "    for r in id2relation:\n",
    "        \n",
    "        if r in score_dict:\n",
    "            \n",
    "            temp_list.append([score_dict[r], r])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            temp_list.append([0.0, r])\n",
    "        \n",
    "    sorted_list = sorted(temp_list, key = lambda x: x[0], reverse=True)\n",
    "    \n",
    "    p = 0\n",
    "    inverse_r = 0\n",
    "    exist_tri = 0\n",
    "    \n",
    "    while p < len(sorted_list) and sorted_list[p][1] != r_true:\n",
    "        \n",
    "        #we want to see how many inverse relaiton are ranked above true relation\n",
    "        #then, we remove them from ranking, otherwise it is not fair for us to compare our\n",
    "        #result with other model who does not consider inverse relations\n",
    "        if temp_list[p][1] % 2 != 0:\n",
    "            \n",
    "            inverse_r += 1\n",
    "        \n",
    "        #moreover, we want to remove existing triples\n",
    "        if ((s_true, sorted_list[p][1], t_true) in data_test) or (\n",
    "              (s_true, sorted_list[p][1], t_true) in data_valid) or (\n",
    "              (s_true, sorted_list[p][1], t_true) in data_ind):\n",
    "            \n",
    "            exist_tri += 1\n",
    "            \n",
    "        p += 1\n",
    "    \n",
    "    if p - inverse_r - exist_tri == 0:\n",
    "        \n",
    "        Hits_at_1 += 1\n",
    "        \n",
    "    print('Calculating_hit_at_one', Hits_at_1/(i+1), 'current ranking:', \n",
    "          p - inverse_r - exist_tri, 'triple number:', i, len(selected))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
